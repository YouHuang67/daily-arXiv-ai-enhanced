<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 44]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.CL](#cs.CL) [Total: 78]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Randomized-MLP Regularization Improves Domain Adaptation and Interpretability in DINOv2](https://arxiv.org/abs/2511.05509)
*Joel Valdivia Ortega,Lorenz Lamm,Franziska Eckardt,Benedikt Schworm,Marion Jasnin,Tingying Peng*

Main category: cs.CV

TL;DR: 提出RMLP正则化方法，通过对比学习增强ViT模型在医学和自然图像中的语义对齐表示，提升注意力图可解释性同时保持或改进下游性能。


<details>
  <summary>Details</summary>
Motivation: ViT模型（如DINOv2）在处理低信息量补丁标记时会影响注意力图和特征图的可解释性，这在医学成像中尤其明显，领域偏移会降低性能和透明度。

Method: 引入基于对比学习的随机化MLP（RMLP）正则化方法，在微调DINOv2时使用RMLPs来鼓励更语义对齐的表示。

Result: RMLP在医学和自然图像模态中都能保持或改进下游性能，同时产生更可解释的注意力图。

Conclusion: RMLP正则化方法有效增强了ViT模型的可解释性和语义对齐能力，并提供了对比学习机制的理论分析。

Abstract: Vision Transformers (ViTs), such as DINOv2, achieve strong performance across domains but often repurpose low-informative patch tokens in ways that reduce the interpretability of attention and feature maps. This challenge is especially evident in medical imaging, where domain shifts can degrade both performance and transparency. In this paper, we introduce Randomized-MLP (RMLP) regularization, a contrastive learning-based method that encourages more semantically aligned representations. We use RMLPs when fine-tuning DINOv2 to both medical and natural image modalities, showing that it improves or maintains downstream performance while producing more interpretable attention maps. We also provide a mathematical analysis of RMLPs, offering insights into its role in enhancing ViT-based models and advancing our understanding of contrastive learning.

</details>


### [2] [Token Is All You Need: Cognitive Planning through Sparse Intent Alignment](https://arxiv.org/abs/2511.05540)
*Shiyao Sang*

Main category: cs.CV

TL;DR: 本文挑战了端到端自动驾驶需要详尽场景建模的传统假设，提出仅需少量语义丰富的token即可实现高效规划，在nuPlan基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 挑战传统端到端自动驾驶需要详尽场景建模的假设，探索更简洁高效的规划方法。

Method: 使用感知信息的BEV表示，基于稀疏语义token进行规划，无需未来预测，通过预测未来token来改进轨迹解码。

Result: 在nuPlan基准测试中，稀疏表示达到0.548m ADE，使用未来token预测后降至0.479m，比当前状态基线提升12.6%。

Conclusion: "token is all you need"原则标志着从重建世界到理解世界的范式转变，为认知启发系统奠定基础。

Abstract: We challenge the long-standing assumption that exhaustive scene modeling is required for high-performance end-to-end autonomous driving (E2EAD). Unlike world-model approaches that rely on computationally intensive future scene generation or vision-language-action (VLA) systems constrained by Markov assumptions, we show that a minimal set of semantically rich tokens is sufficient for effective planning. Experiments on the nuPlan benchmark (720 scenarios, over 11,000 samples) using perception-informed BEV representations yield three key findings: (1) even without future prediction, our sparse representation achieves 0.548 m ADE, comparable to or surpassing prior methods reporting around 0.75 m on nuScenes; (2) conditioning trajectory decoding on predicted future tokens reduces ADE to 0.479 m, a 12.6% improvement over current-state baselines; and (3) explicit reconstruction loss offers no benefit and may degrade performance under reliable perception inputs. Notably, we observe the emergence of temporal fuzziness, where the model adaptively attends to task-relevant semantics rather than aligning rigidly to fixed timestamps, providing a cognitive advantage for planning under uncertainty. Our "token is all you need" principle marks a paradigm shift from reconstructing the world to understanding it, laying a foundation for cognitively inspired systems that plan through imagination rather than reaction.

</details>


### [3] [Automated Invoice Data Extraction: Using LLM and OCR](https://arxiv.org/abs/2511.05547)
*Advait Thakur,Khushi Khanchandani,Akshita Shetty,Chaitravi Reddy,Ritisa Behera*

Main category: cs.CV

TL;DR: 本文介绍了一个结合OCR、深度学习、LLM和图分析的全方位AI平台，旨在解决传统OCR系统在发票布局变化、手写文本和低质量扫描方面的局限性，实现前所未有的提取质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统OCR系统对模板依赖性强，难以适应不同文档结构和布局的变化，特别是在处理手写文本和低质量扫描时表现不佳。需要更灵活的解决方案来应对多样化的发票布局和复杂上下文关系。

Method: 采用混合架构，结合OCR技术、深度学习模型（如CNN和Transformer）、大型语言模型（LLM）以及图分析技术，构建全方位AI平台。利用视觉命名实体识别（NER）能力从发票图像中提取信息。

Result: 该平台能够以更高的准确率从发票图像中提取信息，具有更强的上下文敏感性，支持复杂上下文关系映射，无需直接编程规范。

Conclusion: 通过整合OCR、深度学习、LLM和图分析技术，构建的混合架构AI平台能够显著提高发票信息提取的质量和一致性，实现最大可扩展性和最小人工干预。

Abstract: Conventional Optical Character Recognition (OCR) systems are challenged by variant invoice layouts, handwritten text, and low- quality scans, which are often caused by strong template dependencies that restrict their flexibility across different document structures and layouts. Newer solutions utilize advanced deep learning models such as Convolutional Neural Networks (CNN) as well as Transformers, and domain-specific models for better layout analysis and accuracy across various sections over varied document types. Large Language Models (LLMs) have revolutionized extraction pipelines at their core with sophisticated entity recognition and semantic comprehension to support complex contextual relationship mapping without direct programming specification. Visual Named Entity Recognition (NER) capabilities permit extraction from invoice images with greater contextual sensitivity and much higher accuracy rates than older approaches. Existing industry best practices utilize hybrid architectures that blend OCR technology and LLM for maximum scalability and minimal human intervention. This work introduces a holistic Artificial Intelligence (AI) platform combining OCR, deep learning, LLMs, and graph analytics to achieve unprecedented extraction quality and consistency.

</details>


### [4] [EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning](https://arxiv.org/abs/2511.05553)
*Xinyan Cai,Shiguang Wu,Dafeng Chi,Yuzheng Zhuang,Xingyue Quan,Jianye Hao,Qiang Guan*

Main category: cs.CV

TL;DR: EVLP是一个创新的多模态统一生成框架，通过联合建模语言推理和视觉生成来解决长时程操作任务中的多模态规划问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法在多模态规划中缺乏统一的生成框架，导致规划不一致。需要整合文本逻辑推理和视觉空间想象来实现高效准确的操作。

Method: 提出统一多模态生成框架、动态感知预训练和强化监督微调三个核心组件，通过可学习的跨模态注意力机制协调语言-视觉建模。

Result: 实现了长时程任务的多模态规划，通过动态预训练和强化对齐训练策略增强了多模态相关性。

Conclusion: EVLP框架能够有效解决复杂具身长时程操作任务中的多模态规划挑战，实现协调的语言-视觉建模。

Abstract: In complex embodied long-horizon manipulation tasks, effective task decomposition and execution require synergistic integration of textual logical reasoning and visual-spatial imagination to ensure efficient and accurate operation. Current methods fail to adopt a unified generation framework for multimodal planning, lead to inconsistent in multimodal planning. To address this challenge, we present \textbf{EVLP (Embodied Vision-Language Planner)}, an innovative multimodal unified generation framework that jointly models linguistic reasoning and visual generation. Our approach achieves multimodal planning for long-horizon tasks through a novel training pipeline incorporating dynamic pretraining and reinforced alignment. Our core innovations consist of three key components: \textbf{1) Unified Multimodal Generation Framework}: For understanding, We integrate semantic information with spatial features to provide comprehensive visual perception. For generation, we directly learn the joint distribution of discrete images for one-step visual synthesis, enabling coordinated language-visual modeling through learnable cross-modal attention mechanisms. \textbf{2) Dynamic Perception Pretraining}: We propose a bidirectional dynamic alignment strategy employing inverse dynamics tasks and forward dynamics tasks, effectively strengthening multimodal correlations within a unified feature space. \textbf{3) Reinforced Supervised Fine-Tuning}: While conducting instruction-based fine-tuning in the unified generation space, we construct a reinforce loss to align the spatial logic between textual actions and generated images, enabling the model to acquire spatio-awared multimodal planning capabilities.

</details>


### [5] [In-Context Adaptation of VLMs for Few-Shot Cell Detection in Optical Microscopy](https://arxiv.org/abs/2511.05565)
*Shreyan Ganguly,Angona Biswas,Jaydeep Rade,Md Hasibul Hasan Hasib,Nabila Masud,Nitish Singla,Abhipsa Dash,Ushashi Bhattacharjee,Aditya Balu,Anwesha Sarkar,Adarsh Krishnamurthy,Soumik Sarkar*

Main category: cs.CV

TL;DR: 本文研究了基础视觉语言模型在生物医学显微镜图像中的少样本目标检测能力，提出了Micro-OD基准数据集，并评估了8个VLM在少样本条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在生物医学显微镜图像中的应用，解决大规模标注数据稀缺的问题，通过上下文学习实现少样本目标检测。

Method: 引入Micro-OD基准数据集（252张图像，11种细胞类型），系统评估8个VLM的少样本性能，比较有无推理token的变体，并实现混合FSOD管道结合检测头和VLM分类器。

Result: 零样本性能因领域差距较弱，但少样本支持持续改善检测性能，6个样本后增益边际；带推理token的模型更适合端到端定位，简单变体更适合预定位裁剪分类。

Conclusion: 上下文适应是显微镜图像检测的实用路径，基准为生物医学成像中的开放词汇检测提供了可复现测试平台。

Abstract: Foundation vision-language models (VLMs) excel on natural images, but their utility for biomedical microscopy remains underexplored. In this paper, we investigate how in-context learning enables state-of-the-art VLMs to perform few-shot object detection when large annotated datasets are unavailable, as is often the case with microscopic images. We introduce the Micro-OD benchmark, a curated collection of 252 images specifically curated for in-context learning, with bounding-box annotations spanning 11 cell types across four sources, including two in-lab expert-annotated sets. We systematically evaluate eight VLMs under few-shot conditions and compare variants with and without implicit test-time reasoning tokens. We further implement a hybrid Few-Shot Object Detection (FSOD) pipeline that combines a detection head with a VLM-based few-shot classifier, which enhances the few-shot performance of recent VLMs on our benchmark. Across datasets, we observe that zero-shot performance is weak due to the domain gap; however, few-shot support consistently improves detection, with marginal gains achieved after six shots. We observe that models with reasoning tokens are more effective for end-to-end localization, whereas simpler variants are more suitable for classifying pre-localized crops. Our results highlight in-context adaptation as a practical path for microscopy, and our benchmark provides a reproducible testbed for advancing open-vocabulary detection in biomedical imaging.

</details>


### [6] [C3-Diff: Super-resolving Spatial Transcriptomics via Cross-modal Cross-content Contrastive Diffusion Modelling](https://arxiv.org/abs/2511.05571)
*Xiaofei Wang,Stephen Price,Chao Li*

Main category: cs.CV

TL;DR: C3-Diff是一个跨模态跨内容对比扩散框架，利用组织学图像指导增强空间转录组学(ST)数据的分辨率，通过改进对比学习、特征增强和动态跨模态插补策略，在多个公共数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前空间转录组学平台分辨率较低，限制了空间基因表达的深入理解。虽然超分辨率方法有望通过整合组织学图像和基因表达来增强ST图谱，但如何有效建模组织学图像与基因表达之间的交互仍然是一个挑战。

Method: 提出C3-Diff框架：1) 改进传统对比学习范式，提取ST图谱和组织学图像的模态不变和内容不变特征；2) 在特征单元超球面上进行基于噪声的信息增强，克服ST图谱测序灵敏度低的问题；3) 提出动态跨模态插补训练策略缓解ST数据稀缺问题。

Result: 在四个公共数据集上的基准测试显示，C3-Diff相比竞争方法有显著改进。在下游任务评估中，包括细胞类型定位、基因表达相关性和单细胞级基因表达预测等方面表现优异。

Conclusion: C3-Diff通过创新的跨模态对比扩散框架有效提升了空间转录组学数据的分辨率，促进了AI增强生物技术在生物医学研究和临床应用中的发展。

Abstract: The rapid advancement of spatial transcriptomics (ST), i.e., spatial gene expressions, has made it possible to measure gene expression within original tissue, enabling us to discover molecular mechanisms. However, current ST platforms frequently suffer from low resolution, limiting the in-depth understanding of spatial gene expression. Super-resolution approaches promise to enhance ST maps by integrating histology images with gene expressions of profiled tissue spots. However, it remains a challenge to model the interactions between histology images and gene expressions for effective ST enhancement. This study presents a cross-modal cross-content contrastive diffusion framework, called C3-Diff, for ST enhancement with histology images as guidance. In C3-Diff, we firstly analyze the deficiency of traditional contrastive learning paradigm, which is then refined to extract both modal-invariant and content-invariant features of ST maps and histology images. Further, to overcome the problem of low sequencing sensitivity in ST maps, we perform nosing-based information augmentation on the surface of feature unit hypersphere. Finally, we propose a dynamic cross-modal imputation-based training strategy to mitigate ST data scarcity. We tested C3-Diff by benchmarking its performance on four public datasets, where it achieves significant improvements over competing methods. Moreover, we evaluate C3-Diff on downstream tasks of cell type localization, gene expression correlation and single-cell-level gene expression prediction, promoting AI-enhanced biotechnology for biomedical research and clinical applications. Codes are available at https://github.com/XiaofeiWang2018/C3-Diff.

</details>


### [7] [Video Text Preservation with Synthetic Text-Rich Videos](https://arxiv.org/abs/2511.05573)
*Ziyang Liu,Kevin Valencia,Justin Cui*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级方法，通过使用合成监督来改进文本到视频(T2V)扩散模型中的文本可读性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的T2V模型在生成包含可读文本的视频时表现不佳，即使是短短语或单词也常常无法正确渲染，而之前的解决方案计算成本高昂且不适合视频生成。

Method: 首先使用文本到图像(T2I)扩散模型生成富含文本的图像，然后使用文本无关的图像到视频(I2V)模型将其动画化为短视频，利用这些合成的视频-提示对来微调预训练的T2V模型Wan2.1，无需架构更改。

Result: 结果显示在短文本可读性和时间一致性方面有所改善，并为长文本提供了新兴的结构先验。

Conclusion: 精心策划的合成数据和弱监督为提高T2V生成中的文本保真度提供了一条实用路径。

Abstract: While Text-To-Video (T2V) models have advanced rapidly, they continue to struggle with generating legible and coherent text within videos. In particular, existing models often fail to render correctly even short phrases or words and previous attempts to address this problem are computationally expensive and not suitable for video generation. In this work, we investigate a lightweight approach to improve T2V diffusion models using synthetic supervision. We first generate text-rich images using a text-to-image (T2I) diffusion model, then animate them into short videos using a text-agnostic image-to-video (I2v) model. These synthetic video-prompt pairs are used to fine-tune Wan2.1, a pre-trained T2V model, without any architectural changes. Our results show improvement in short-text legibility and temporal consistency with emerging structural priors for longer text. These findings suggest that curated synthetic data and weak supervision offer a practical path toward improving textual fidelity in T2V generation.

</details>


### [8] [Walking the Schrödinger Bridge: A Direct Trajectory for Text-to-3D Generation](https://arxiv.org/abs/2511.05609)
*Ziying Li,Xuequan Lu,Xinkui Zhao,Guanjie Cheng,Shuiguang Deng,Jianwei Yin*

Main category: cs.CV

TL;DR: 本文提出TraCe框架，通过将文本到3D生成过程建模为从当前渲染分布到目标分布的最优传输轨迹学习，解决了现有SDS方法中的过饱和和过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 解决基于优化的文本到3D生成方法中，使用SDS技术从预训练文本到图像扩散模型蒸馏知识时引入的过饱和和过平滑伪影问题。

Method: 将SDS理论建立为Schrödinger Bridge框架的简化实例，提出TraCe框架，通过显式构建从当前渲染到文本条件目标的扩散桥，并在该轨迹的分数动态上训练LoRA适应模型。

Result: 综合实验表明，TraCe在质量和保真度方面持续优于现有最先进技术，能够使用更小的CFG值实现高质量生成。

Conclusion: TraCe通过将生成过程重新表述为最优传输轨迹学习，有效解决了SDS方法的局限性，为文本到3D生成提供了更稳健的优化框架。

Abstract: Recent advancements in optimization-based text-to-3D generation heavily rely on distilling knowledge from pre-trained text-to-image diffusion models using techniques like Score Distillation Sampling (SDS), which often introduce artifacts such as over-saturation and over-smoothing into the generated 3D assets. In this paper, we address this essential problem by formulating the generation process as learning an optimal, direct transport trajectory between the distribution of the current rendering and the desired target distribution, thereby enabling high-quality generation with smaller Classifier-free Guidance (CFG) values. At first, we theoretically establish SDS as a simplified instance of the Schrödinger Bridge framework. We prove that SDS employs the reverse process of an Schrödinger Bridge, which, under specific conditions (e.g., a Gaussian noise as one end), collapses to SDS's score function of the pre-trained diffusion model. Based upon this, we introduce Trajectory-Centric Distillation (TraCe), a novel text-to-3D generation framework, which reformulates the mathematically trackable framework of Schrödinger Bridge to explicitly construct a diffusion bridge from the current rendering to its text-conditioned, denoised target, and trains a LoRA-adapted model on this trajectory's score dynamics for robust 3D optimization. Comprehensive experiments demonstrate that TraCe consistently achieves superior quality and fidelity to state-of-the-art techniques.

</details>


### [9] [Grounding Foundational Vision Models with 3D Human Poses for Robust Action Recognition](https://arxiv.org/abs/2511.05622)
*Nicholas Babey,Tiffany Gu,Yiheng Li,Cristian Meo,Kevin Zhu*

Main category: cs.CV

TL;DR: 提出了一种融合V-JEPA 2的世界动态预测和CoMotion人体姿态数据的模型架构，在复杂遮挡场景下的动作识别任务中优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于RGB视频的动作识别模型仅学习模式与动作标签之间的表面相关性，难以捕捉复杂场景中的物理交互动态和人体姿态，需要将动作识别建立在物理空间理解基础上。

Method: 通过融合V-JEPA 2的上下文预测世界动态和CoMotion的显式、抗遮挡人体姿态数据，构建了基于物理空间的动作识别模型。

Result: 在InHARD和UCF-19-Y-OCC基准测试中，该模型优于其他三个基线方法，特别是在复杂遮挡场景下表现更佳。

Conclusion: 动作识别需要基于空间理解而非统计模式识别，物理空间的基础对于理解人类动作至关重要。

Abstract: For embodied agents to effectively understand and interact within the world around them, they require a nuanced comprehension of human actions grounded in physical space. Current action recognition models, often relying on RGB video, learn superficial correlations between patterns and action labels, so they struggle to capture underlying physical interaction dynamics and human poses in complex scenes. We propose a model architecture that grounds action recognition in physical space by fusing two powerful, complementary representations: V-JEPA 2's contextual, predictive world dynamics and CoMotion's explicit, occlusion-tolerant human pose data. Our model is validated on both the InHARD and UCF-19-Y-OCC benchmarks for general action recognition and high-occlusion action recognition, respectively. Our model outperforms three other baselines, especially within complex, occlusive scenes. Our findings emphasize a need for action recognition to be supported by spatial understanding instead of statistical pattern recognition.

</details>


### [10] [Hilbert-Guided Block-Sparse Local Attention](https://arxiv.org/abs/2511.05832)
*Yunge Li,Lanyu Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于希尔伯特曲线构建窗口和邻域的新方法，通过将图像token沿希尔伯特曲线重新排序，在重排后的1D序列上形成窗口和邻域，显著提高了块稀疏性，结合现有块稀疏核可提升2D局部注意力的效率。


<details>
  <summary>Details</summary>
Motivation: 全局自注意力的二次计算和内存成本严重限制了其在高分辨率图像中的应用。局部注意力通过将注意力限制在邻域内来降低复杂度，但传统的局部注意力模式由于窗口内的token在1D序列中不连续，往往无法实现显著加速。

Method: 提出基于希尔伯特曲线的窗口构建方法：首先将图像token沿希尔伯特曲线重新排序，然后在重排后的1D序列上形成窗口和邻域。该方法可与现有块稀疏核结合，提高2D局部注意力的效率。

Result: 实验表明，提出的希尔伯特窗口注意力和希尔伯特滑动注意力分别可将窗口注意力和滑动注意力加速约4倍和18倍。实例化的希尔伯特窗口变换器和希尔伯特邻域变换器均实现了端到端加速，且精度损失最小。

Conclusion: 将希尔伯特引导的局部注意力与块稀疏核相结合，为提升图像2D局部注意力效率提供了一种通用且实用的方法。

Abstract: The quadratic compute and memory costs of global self-attention severely limit its use in high-resolution images. Local attention reduces complexity by restricting attention to neighborhoods. Block-sparse kernels can further improve the efficiency of local attention, but conventional local attention patterns often fail to deliver significant speedups because tokens within a window are not contiguous in the 1D sequence. This work proposes a novel method for constructing windows and neighborhoods based on the Hilbert curve. Image tokens are first reordered along a Hilbert curve, and windows and neighborhoods are then formed on the reordered 1D sequence. From a block-sparse perspective, this strategy significantly increases block sparsity and can be combined with existing block-sparse kernels to improve the efficiency of 2D local attention. Experiments show that the proposed Hilbert Window Attention and Hilbert Slide Attention can accelerate window attention and slide attention by about $4\times$ and $18\times$, respectively. To assess practicality, the strategy is instantiated as the Hilbert Window Transformer and the Hilbert Neighborhood Transformer, both of which achieve end-to-end speedups with minimal accuracy loss. Overall, combining Hilbert-guided local attention with block-sparse kernels offers a general and practical approach to enhancing the efficiency of 2D local attention for images. The code is available at https://github.com/Yunge6666/Hilbert-Local-Attention.

</details>


### [11] [Understanding Cross Task Generalization in Handwriting-Based Alzheimer's Screening via Vision Language Adaptation](https://arxiv.org/abs/2511.05841)
*Changqing Gong,Huafeng Qin,Mounim A. El-Yacoubi*

Main category: cs.CV

TL;DR: 本文提出了一个轻量级的跨层融合适配器框架(CLFA)，利用CLIP模型进行基于笔迹的阿尔茨海默病筛查，通过多级融合适配器对齐笔迹特定的医学特征，实现无需提示词的高效零样本推理，并系统研究了跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测至关重要，笔迹变化提供了非侵入性的检测窗口。现有研究主要依赖在线轨迹和手工特征，未能系统研究任务类型对诊断性能和跨任务泛化的影响，同时大规模视觉语言模型在医疗领域的应用尚未充分探索笔迹检测。

Method: 提出CLFA框架，在CLIP视觉编码器中植入多级融合适配器，逐步对齐笔迹特定的医学特征表示，支持无需提示词的高效零样本推理，并系统评估跨任务泛化能力。

Result: 该框架能够有效识别阿尔茨海默病的特征性笔迹模式，揭示了哪些任务类型和书写模式最能有效区分AD，提供了诊断洞察和笔迹认知评估的基准。

Conclusion: CLFA框架为基于笔迹的阿尔茨海默病筛查提供了有效的解决方案，通过系统研究跨任务泛化揭示了关键的任务类型和书写模式特征，为早期认知评估建立了基准。

Abstract: Alzheimer's disease is a prevalent neurodegenerative disorder for which early detection is critical. Handwriting-often disrupted in prodromal AD-provides a non-invasive and cost-effective window into subtle motor and cognitive decline. Existing handwriting-based AD studies, mostly relying on online trajectories and hand-crafted features, have not systematically examined how task type influences diagnostic performance and cross-task generalization. Meanwhile, large-scale vision language models have demonstrated remarkable zero or few-shot anomaly detection in natural images and strong adaptability across medical modalities such as chest X-ray and brain MRI. However, handwriting-based disease detection remains largely unexplored within this paradigm. To close this gap, we introduce a lightweight Cross-Layer Fusion Adapter framework that repurposes CLIP for handwriting-based AD screening. CLFA implants multi-level fusion adapters within the visual encoder to progressively align representations toward handwriting-specific medical cues, enabling prompt-free and efficient zero-shot inference. Using this framework, we systematically investigate cross-task generalization-training on a specific handwriting task and evaluating on unseen ones-to reveal which task types and writing patterns most effectively discriminate AD. Extensive analyses further highlight characteristic stroke patterns and task-level factors that contribute to early AD identification, offering both diagnostic insights and a benchmark for handwriting-based cognitive assessment.

</details>


### [12] [Adapted Foundation Models for Breast MRI Triaging in Contrast-Enhanced and Non-Contrast Enhanced Protocols](https://arxiv.org/abs/2511.05967)
*Tri-Thien Nguyen,Lorenz A. Kapsner,Tobias Hepp,Shirin Heidarikahkesh,Hannes Schreiter,Luise Brock,Dominika Skwierawska,Dominique Hadler,Julian Hossbach,Evelyn Wenkel,Sabine Ohlmeyer,Frederik B. Laun,Andrzej Liebert,Andreas Maier,Michael Uder,Sebastian Bickelhaupt*

Main category: cs.CV

TL;DR: 本研究评估了基于DINOv2的医学切片变换器(MST)在乳腺MRI中排除BI-RADS≥4显著发现的性能，在97.5%灵敏度下，对比增强和非对比增强MRI分别达到19%和17%的特异性。


<details>
  <summary>Details</summary>
Motivation: MRI对乳腺癌检测具有高灵敏度但解读耗时，人工智能可能有助于预筛查。

Method: 回顾性研究使用1,847例乳腺MRI检查，测试四种简化协议：T1加权早期减影、扩散加权成像、DWI+T2加权、T1减影+T2加权，采用五折交叉验证和AUC分析。

Result: T1sub+T2w组合AUC为0.77±0.04，在97.5%灵敏度下特异性最高(19%±7%)；外部验证AUC为0.77，88%注意力图被评为良好或中等。

Conclusion: MST框架在97.5%灵敏度下能正确分流无BI-RADS≥4的病例，但临床实施前需要进一步研究。

Abstract: Background: Magnetic resonance imaging (MRI) has high sensitivity for breast cancer detection, but interpretation is time-consuming. Artificial intelligence may aid in pre-screening. Purpose: To evaluate the DINOv2-based Medical Slice Transformer (MST) for ruling out significant findings (Breast Imaging Reporting and Data System [BI-RADS] >=4) in contrast-enhanced and non-contrast-enhanced abbreviated breast MRI. Materials and Methods: This institutional review board approved retrospective study included 1,847 single-breast MRI examinations (377 BI-RADS >=4) from an in-house dataset and 924 from an external validation dataset (Duke). Four abbreviated protocols were tested: T1-weighted early subtraction (T1sub), diffusion-weighted imaging with b=1500 s/mm2 (DWI1500), DWI1500+T2-weighted (T2w), and T1sub+T2w. Performance was assessed at 90%, 95%, and 97.5% sensitivity using five-fold cross-validation and area under the receiver operating characteristic curve (AUC) analysis. AUC differences were compared with the DeLong test. False negatives were characterized, and attention maps of true positives were rated in the external dataset. Results: A total of 1,448 female patients (mean age, 49 +/- 12 years) were included. T1sub+T2w achieved an AUC of 0.77 +/- 0.04; DWI1500+T2w, 0.74 +/- 0.04 (p=0.15). At 97.5% sensitivity, T1sub+T2w had the highest specificity (19% +/- 7%), followed by DWI1500+T2w (17% +/- 11%). Missed lesions had a mean diameter <10 mm at 95% and 97.5% thresholds for both T1sub and DWI1500, predominantly non-mass enhancements. External validation yielded an AUC of 0.77, with 88% of attention maps rated good or moderate. Conclusion: At 97.5% sensitivity, the MST framework correctly triaged cases without BI-RADS >=4, achieving 19% specificity for contrast-enhanced and 17% for non-contrast-enhanced MRI. Further research is warranted before clinical implementation.

</details>


### [13] [DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language Variational AutoEncoder for Robust Radiology Reporting with Missing Modalities](https://arxiv.org/abs/2511.05968)
*Nagur Shareef Shaik,Teja Krishna Cherukuri,Adnan Masood,Dong Hye Ye*

Main category: cs.CV

TL;DR: 本文提出DiA-gnostic VLVAE框架，通过解缠对齐方法解决医学影像报告中缺失模态和特征纠缠问题，在IU X-Ray和MIMIC-CXR数据集上取得竞争性BLEU@4分数。


<details>
  <summary>Details</summary>
Motivation: 解决当前自动生成放射学报告方法面临的两个核心挑战：缺失模态（如不完整的临床背景）和特征纠缠（混合模态特定与共享信息导致次优融合和临床不忠实的幻觉发现）。

Method: 使用基于专家混合的视觉语言变分自编码器解缠共享和模态特定特征，通过约束优化目标强制潜在表示的正交性和对齐，然后使用紧凑的LLaMA-X解码器生成报告。

Result: 在IU X-Ray和MIMIC-CXR数据集上分别获得0.266和0.134的BLEU@4分数，实验结果显示该方法显著优于最先进模型。

Conclusion: DiA-gnostic VLVAE框架通过解缠对齐实现了稳健的放射学报告生成，能够有效处理缺失模态问题并防止次优融合。

Abstract: The integration of medical images with clinical context is essential for generating accurate and clinically interpretable radiology reports. However, current automated methods often rely on resource-heavy Large Language Models (LLMs) or static knowledge graphs and struggle with two fundamental challenges in real-world clinical data: (1) missing modalities, such as incomplete clinical context , and (2) feature entanglement, where mixed modality-specific and shared information leads to suboptimal fusion and clinically unfaithful hallucinated findings. To address these challenges, we propose the DiA-gnostic VLVAE, which achieves robust radiology reporting through Disentangled Alignment. Our framework is designed to be resilient to missing modalities by disentangling shared and modality-specific features using a Mixture-of-Experts (MoE) based Vision-Language Variational Autoencoder (VLVAE). A constrained optimization objective enforces orthogonality and alignment between these latent representations to prevent suboptimal fusion. A compact LLaMA-X decoder then uses these disentangled representations to generate reports efficiently. On the IU X-Ray and MIMIC-CXR datasets, DiA has achieved competetive BLEU@4 scores of 0.266 and 0.134, respectively. Experimental results show that the proposed method significantly outperforms state-of-the-art models.

</details>


### [14] [Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds](https://arxiv.org/abs/2511.05996)
*Xianhui Meng,Yukang Huo,Li Zhang,Liu Liu,Haonan Jiang,Yan Zhong,Pingrui Zhang,Cewu Lu,Jun Liu*

Main category: cs.CV

TL;DR: PPF-Tracker是一个基于点对特征的铰接物体姿态跟踪框架，通过SE(3)李群空间的准正则化、点对特征建模和关节轴语义约束，在多帧姿态跟踪中表现出色。


<details>
  <summary>Details</summary>
Motivation: 铰接物体在日常生活中和机器人操作任务中普遍存在，但与刚性物体相比，由于其固有的运动学约束，铰接物体的姿态跟踪仍然是一个未被充分探索的问题。

Method: 该框架首先在SE(3)李群空间中对点云进行准正则化，然后使用点对特征(PPF)建模铰接物体，利用SE(3)的不变性预测姿态投票参数，最后结合关节轴的语义信息对所有部件施加统一的运动学约束。

Result: PPF-Tracker在合成数据集和真实场景中进行了系统评估，展示了在不同挑战性环境中的强大泛化能力。实验结果突显了PPF-Tracker在铰接物体多帧姿态跟踪中的有效性和鲁棒性。

Conclusion: 这项工作可以促进机器人技术、具身智能和增强现实领域的发展。代码已在GitHub上开源。

Abstract: Articulated objects are prevalent in daily life and robotic manipulation tasks. However, compared to rigid objects, pose tracking for articulated objects remains an underexplored problem due to their inherent kinematic constraints. To address these challenges, this work proposes a novel point-pair-based pose tracking framework, termed \textbf{PPF-Tracker}. The proposed framework first performs quasi-canonicalization of point clouds in the SE(3) Lie group space, and then models articulated objects using Point Pair Features (PPF) to predict pose voting parameters by leveraging the invariance properties of SE(3). Finally, semantic information of joint axes is incorporated to impose unified kinematic constraints across all parts of the articulated object. PPF-Tracker is systematically evaluated on both synthetic datasets and real-world scenarios, demonstrating strong generalization across diverse and challenging environments. Experimental results highlight the effectiveness and robustness of PPF-Tracker in multi-frame pose tracking of articulated objects. We believe this work can foster advances in robotics, embodied intelligence, and augmented reality. Codes are available at https://github.com/mengxh20/PPFTracker.

</details>


### [15] [One-Shot Knowledge Transfer for Scalable Person Re-Identification](https://arxiv.org/abs/2511.06016)
*Longhua Li,Lei Qi,Xin Geng*

Main category: cs.CV

TL;DR: 提出了一种名为OSKT（一次性知识转移）的新方法，通过权重链将教师模型知识整合到中间载体中，可在需要时扩展到目标模型大小而无需额外计算。


<details>
  <summary>Details</summary>
Motivation: 解决边缘计算中行人重识别模型压缩时，为适应不同资源条件需要多个模型尺寸而导致的重复计算问题。

Method: 使用权重链作为知识继承的中间载体，将教师模型知识整合其中，在需要特定资源约束的模型时直接扩展权重链到目标尺寸。

Result: OSKT显著优于最先进的压缩方法，且具有一次性知识转移的优势，无需为每个目标模型频繁计算。

Conclusion: OSKT方法有效解决了多尺寸模型压缩中的重复计算问题，在边缘计算行人重识别中具有重要应用价值。

Abstract: Edge computing in person re-identification (ReID) is crucial for reducing the load on central cloud servers and ensuring user privacy. Conventional compression methods for obtaining compact models require computations for each individual student model. When multiple models of varying sizes are needed to accommodate different resource conditions, this leads to repetitive and cumbersome computations. To address this challenge, we propose a novel knowledge inheritance approach named OSKT (One-Shot Knowledge Transfer), which consolidates the knowledge of the teacher model into an intermediate carrier called a weight chain. When a downstream scenario demands a model that meets specific resource constraints, this weight chain can be expanded to the target model size without additional computation. OSKT significantly outperforms state-of-the-art compression methods, with the added advantage of one-time knowledge transfer that eliminates the need for frequent computations for each target model.

</details>


### [16] [HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in Vision-Language Alignment](https://arxiv.org/abs/2511.06653)
*Ruijia Wu,Ping Chen,Fei Shen,Shaoan Zhao,Qiang Hui,Huanlin Gao,Ting Lu,Zhaoxiang Liu,Fang Zhao,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: HiMo-CLIP通过层次分解和单调性感知对比损失增强CLIP模型，解决了传统模型在处理复杂、组合式和长文本描述时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的对比视觉语言模型如CLIP将文本视为扁平序列，无法捕捉语言的语义层次结构和语义单调性，限制了处理复杂、组合式和长文本描述的能力。

Method: 提出HiMo-CLIP框架，包含层次分解模块（HiDe）通过批内PCA提取潜在语义组件，以及单调性感知对比损失（MoLo）联合对齐全局和组件级表示。

Result: 在多个图像-文本检索基准测试中，HiMo-CLIP始终优于强基线模型，特别是在处理长文本或组合式描述时表现更佳。

Conclusion: HiMo-CLIP通过结构化、认知对齐的跨模态表示，有效提升了CLIP风格模型处理复杂语言描述的能力。

Abstract: Contrastive vision-language models like CLIP have achieved impressive results in image-text retrieval by aligning image and text representations in a shared embedding space. However, these models often treat text as flat sequences, limiting their ability to handle complex, compositional, and long-form descriptions. In particular, they fail to capture two essential properties of language: semantic hierarchy, which reflects the multi-level compositional structure of text, and semantic monotonicity, where richer descriptions should result in stronger alignment with visual content.To address these limitations, we propose HiMo-CLIP, a representation-level framework that enhances CLIP-style models without modifying the encoder architecture. HiMo-CLIP introduces two key components: a hierarchical decomposition (HiDe) module that extracts latent semantic components from long-form text via in-batch PCA, enabling flexible, batch-aware alignment across different semantic granularities, and a monotonicity-aware contrastive loss (MoLo) that jointly aligns global and component-level representations, encouraging the model to internalize semantic ordering and alignment strength as a function of textual completeness.These components work in concert to produce structured, cognitively-aligned cross-modal representations. Experiments on multiple image-text retrieval benchmarks show that HiMo-CLIP consistently outperforms strong baselines, particularly under long or compositional descriptions. The code is available at https://github.com/UnicomAI/HiMo-CLIP.

</details>


### [17] [S2ML: Spatio-Spectral Mutual Learning for Depth Completion](https://arxiv.org/abs/2511.06033)
*Zihui Zhao,Yifei Zhang,Zheng Wang,Yang Li,Kui Jiang,Zihan Geng,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 提出S2ML框架，结合空间域和频域优势进行深度补全，通过频谱融合模块和统一嵌入空间中的特征相关性计算，实现更准确的深度补全。


<details>
  <summary>Details</summary>
Motivation: RGB-D相机捕获的原始深度图像常因弱反射、边界阴影和伪影导致深度值不完整，现有方法在图像域进行深度补全但忽略了物理特性。观察到无效深度区域会改变频率分布模式。

Method: 提出时空频谱互学习框架(S2ML)，设计专用频谱融合模块处理振幅和相位谱的不同特性，在统一嵌入空间中计算空间域和频域特征的局部和全局相关性，通过逐步互表示和细化探索互补物理特性。

Result: 在NYU-Depth V2和SUN RGB-D数据集上分别比最先进方法CFormer提升0.828 dB和0.834 dB。

Conclusion: S2ML框架通过结合空间域和频域的优势，有效提升了深度补全的准确性。

Abstract: The raw depth images captured by RGB-D cameras using Time-of-Flight (TOF) or structured light often suffer from incomplete depth values due to weak reflections, boundary shadows, and artifacts, which limit their applications in downstream vision tasks. Existing methods address this problem through depth completion in the image domain, but they overlook the physical characteristics of raw depth images. It has been observed that the presence of invalid depth areas alters the frequency distribution pattern. In this work, we propose a Spatio-Spectral Mutual Learning framework (S2ML) to harmonize the advantages of both spatial and frequency domains for depth completion. Specifically, we consider the distinct properties of amplitude and phase spectra and devise a dedicated spectral fusion module. Meanwhile, the local and global correlations between spatial-domain and frequency-domain features are calculated in a unified embedding space. The gradual mutual representation and refinement encourage the network to fully explore complementary physical characteristics and priors for more accurate depth completion. Extensive experiments demonstrate the effectiveness of our proposed S2ML method, outperforming the state-of-the-art method CFormer by 0.828 dB and 0.834 dB on the NYU-Depth V2 and SUN RGB-D datasets, respectively.

</details>


### [18] [Hybrid CNN-ViT Framework for Motion-Blurred Scene Text Restoration](https://arxiv.org/abs/2511.06087)
*Umar Rashid,Muhammad Arslan Arshad,Ghulam Ahmad,Muhammad Zeeshan Anjum,Rizwan Khan,Muhammad Akmal*

Main category: cs.CV

TL;DR: 提出了一种结合CNN和ViT的混合深度学习框架，用于解决场景文本图像中的运动模糊问题，通过局部特征提取和全局上下文推理来恢复文本清晰度。


<details>
  <summary>Details</summary>
Motivation: 场景文本图像中的运动模糊严重影响了可读性，并阻碍了自动驾驶、文档数字化和视觉信息检索等计算机视觉任务的可靠性。传统去模糊方法在处理空间变化模糊和建模长距离依赖关系方面存在不足。

Method: 采用CNN编码器-解码器结构保留结构细节，同时使用transformer模块通过自注意力增强全局感知。在TextOCR数据集上进行训练，使用合成的多尺寸多方向运动模糊核生成模糊样本。采用包含MAE、MSE、感知相似性和SSIM的复合损失函数进行模型优化。

Result: 定量评估显示，该方法在PSNR上达到32.20 dB，SSIM达到0.934，同时保持轻量化设计（283万参数）和快速推理（平均61毫秒）。

Conclusion: CNN-ViT混合设计在运动模糊场景文本恢复方面表现出有效性和计算效率，证明了其在现实世界应用中的实用性。

Abstract: Motion blur in scene text images severely impairs readability and hinders the reliability of computer vision tasks, including autonomous driving, document digitization, and visual information retrieval. Conventional deblurring approaches are often inadequate in handling spatially varying blur and typically fall short in modeling the long-range dependencies necessary for restoring textual clarity. To overcome these limitations, we introduce a hybrid deep learning framework that combines convolutional neural networks (CNNs) with vision transformers (ViTs), thereby leveraging both local feature extraction and global contextual reasoning. The architecture employs a CNN-based encoder-decoder to preserve structural details, while a transformer module enhances global awareness through self-attention. Training is conducted on a curated dataset derived from TextOCR, where sharp scene-text samples are paired with synthetically blurred versions generated using realistic motion-blur kernels of multiple sizes and orientations. Model optimization is guided by a composite loss that incorporates mean absolute error (MAE), squared error (MSE), perceptual similarity, and structural similarity (SSIM). Quantitative evaluations show that the proposed method attains 32.20 dB in PSNR and 0.934 in SSIM, while remaining lightweight with 2.83 million parameters and an average inference time of 61 ms. These results highlight the effectiveness and computational efficiency of the CNN-ViT hybrid design, establishing its practicality for real-world motion-blurred scene-text restoration.

</details>


### [19] [SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards](https://arxiv.org/abs/2511.07403)
*Hunar Batra,Haoqin Tu,Hardy Chen,Yuanze Lin,Cihang Xie,Ronald Clark*

Main category: cs.CV

TL;DR: SpatialThinker是一个3D感知的多模态大语言模型，通过强化学习结合结构化空间基础和多步推理，解决了现有MLLM在空间理解方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在空间理解方面表现不佳，通常依赖显式3D输入或特定架构修改，且受限于大规模数据集或稀疏监督。

Method: 模型模拟人类空间感知，构建任务相关对象和空间关系的场景图，通过密集空间奖励进行推理。包含两个关键贡献：STVQA-7K高质量空间VQA数据集生成流程，以及使用多目标密集空间奖励的在线强化学习。

Result: SpatialThinker-7B在空间理解和真实世界VQA基准测试中优于监督微调和稀疏RL基线，相比稀疏RL几乎将基础模型增益翻倍，并超过GPT-4o。

Conclusion: 结果表明，将空间监督与奖励对齐推理相结合，能够在有限数据下实现稳健的3D空间理解，推动MLLM向人类级视觉推理发展。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language tasks, but they continue to struggle with spatial understanding. Existing spatial MLLMs often rely on explicit 3D inputs or architecture-specific modifications, and remain constrained by large-scale datasets or sparse supervision. To address these limitations, we introduce SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial grounding with multi-step reasoning. The model simulates human-like spatial perception by constructing a scene graph of task-relevant objects and spatial relations, and reasoning towards an answer via dense spatial rewards. SpatialThinker consists of two key contributions: (1) a data synthesis pipeline that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL with a multi-objective dense spatial reward enforcing spatial grounding. SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline on spatial understanding and real-world VQA benchmarks, nearly doubling the base-model gain compared to sparse RL, and surpassing GPT-4o. These results showcase the effectiveness of combining spatial supervision with reward-aligned reasoning in enabling robust 3D spatial understanding with limited data and advancing MLLMs towards human-level visual reasoning.

</details>


### [20] [LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation](https://arxiv.org/abs/2511.06272)
*Zijie Wang,Weiming Zhang,Wei Zhang,Xiao Tan,Hongxing Liu,Yaowei Wang,Guanbin Li*

Main category: cs.CV

TL;DR: LaneDiffusion是一个用于中心线图学习的生成式方法，使用扩散模型在BEV特征层面生成车道中心线先验，而不是直接预测向量化中心线，显著提升了中心线图学习的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的确定性方法在中心线图学习中缺乏空间推理能力，难以处理被遮挡或不可见的中心线，而生成式方法在这一领域尚未得到充分探索。

Method: 提出LaneDiffusion方法，包含车道先验注入模块(LPIM)和车道先验扩散模块(LPDM)，在BEV特征层面构建扩散目标并管理扩散过程，然后从这些先验注入的BEV特征中解码向量化中心线和拓扑结构。

Result: 在nuScenes和Argoverse2数据集上的广泛评估表明，LaneDiffusion在点级指标(GEO F1、TOPO F1、JTOPO F1、APLS、SDA)和段级指标(IoU、mAP_cf、DET_l、TOP_ll)上均显著优于现有方法，实现了最先进的性能。

Conclusion: LaneDiffusion为中心线图学习建立了新的最先进性能，为这一任务的生成模型提供了新的见解。

Abstract: Centerline graphs, crucial for path planning in autonomous driving, are traditionally learned using deterministic methods. However, these methods often lack spatial reasoning and struggle with occluded or invisible centerlines. Generative approaches, despite their potential, remain underexplored in this domain. We introduce LaneDiffusion, a novel generative paradigm for centerline graph learning. LaneDiffusion innovatively employs diffusion models to generate lane centerline priors at the Bird's Eye View (BEV) feature level, instead of directly predicting vectorized centerlines. Our method integrates a Lane Prior Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively construct diffusion targets and manage the diffusion process. Furthermore, vectorized centerlines and topologies are then decoded from these prior-injected BEV features. Extensive evaluations on the nuScenes and Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and 2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and TOP_ll). These results establish state-of-the-art performance in centerline graph learning, offering new insights into generative models for this task.

</details>


### [21] [CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI Image Detection](https://arxiv.org/abs/2511.06325)
*Minsuk Jang,Hyeonseo Jeong,Minseok Son,Changick Kim*

Main category: cs.CV

TL;DR: CINEMAE是一种基于上下文条件重建不确定性的AIGC图像检测新范式，通过计算掩码补丁的条件负对数似然来量化局部语义异常，在仅使用Stable Diffusion v1.4训练的情况下，在GenImage基准测试中对8个未见生成器达到95%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 基于上下文的文本检测器在AI生成文本检测中表现出良好的泛化能力，而基于图像的检测器仍然难以避免对生成器特定伪影的过拟合。

Method: 利用掩码自编码器(MAE)的重建过程，通过计算条件负对数似然(p(掩码|可见))来量化局部语义异常，并将补丁级统计与全局MAE特征通过学习融合进行聚合。

Result: 在仅使用Stable Diffusion v1.4训练的情况下，在GenImage基准测试中对8个未见生成器达到95%以上的准确率，显著优于现有最先进的检测器。

Conclusion: 上下文条件重建不确定性为AIGC检测提供了鲁棒且可迁移的信号。

Abstract: While context-based detectors have achieved strong generalization for AI-generated text by measuring distributional inconsistencies, image-based detectors still struggle with overfitting to generator-specific artifacts. We introduce CINEMAE, a novel paradigm for AIGC image detection that adapts the core principles of text detection methods to the visual domain. Our key insight is that Masked AutoEncoder (MAE), trained to reconstruct masked patches conditioned on visible context, naturally encodes semantic consistency expectations. We formalize this reconstruction process probabilistically, computing conditional Negative Log-Likelihood (NLL, p(masked | visible)) to quantify local semantic anomalies. By aggregating these patch-level statistics with global MAE features through learned fusion, CINEMAE achieves strong cross-generator generalization. Trained exclusively on Stable Diffusion v1.4, our method achieves over 95% accuracy on all eight unseen generators in the GenImage benchmark, substantially outperforming state-of-the-art detectors. This demonstrates that context-conditional reconstruction uncertainty provides a robust, transferable signal for AIGC detection.

</details>


### [22] [GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding](https://arxiv.org/abs/2511.06348)
*Athul M. Mathew,Haithem Hermassi,Thariq Khalid,Arshad Ali Khan,Riad Souissi*

Main category: cs.CV

TL;DR: GazeVLM是一个新颖的视觉语言模型，用于图像中的多任务注视理解，包括人物检测、注视目标检测和注视物体识别。它首次将VLM应用于这些组合任务，通过融合RGB图像和HHA编码深度图，在GazeFollow和VideoAttentionTarget数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的注视分析研究虽然建模了视觉场景中的注视线索，但仍需要一个统一的系统来同时利用视觉和语言提示进行注视理解。

Method: 提出GazeVLM模型，集成视觉（RGB和深度）和文本模态，通过文本提示引导的RGB图像与HHA编码深度图融合方法，并引入了物体级注视检测指标AP_ob。

Result: 消融研究表明RGB图像与HHA编码深度图的融合在文本提示引导下性能最佳。GazeVLM在GazeFollow和VideoAttentionTarget数据集上取得了最先进的评估分数。

Conclusion: GazeVLM成功地将视觉语言模型应用于多任务注视理解，通过视觉和语言模态的融合显著提升了性能，为注视理解提供了统一的框架。

Abstract: Gaze understanding unifies the detection of people, their gaze targets, and objects of interest into a single framework, offering critical insight into visual attention and intent estimation. Although prior research has modelled gaze cues in visual scenes, a unified system is still needed for gaze understanding using both visual and language prompts. This paper introduces GazeVLM, a novel Vision-Language Model (VLM) for multi-task gaze understanding in images, addressing person detection, gaze target detection, and gaze object identification. While other transformer-based methods exist for gaze analysis, GazeVLM represents, to our knowledge, the first application of a VLM to these combined tasks, allowing for selective execution of each task. Through the integration of visual (RGB and depth) and textual modalities, our ablation study on visual input combinations revealed that a fusion of RGB images with HHA-encoded depth maps, guided by text prompts, yields superior performance. We also introduce an object-level gaze detection metric for gaze object identification ($AP_{ob}$). Through experiments, GazeVLM demonstrates significant improvements, notably achieving state-of-the-art evaluation scores on GazeFollow and VideoAttentionTarget datasets.

</details>


### [23] [On Modality Incomplete Infrared-Visible Object Detection: An Architecture Compatibility Perspective](https://arxiv.org/abs/2511.06406)
*Shuo Yang,Yinghui Xing,Shizhou Zhang,Zhilong Niu*

Main category: cs.CV

TL;DR: 提出Scarf-DETR方法解决红外可见光目标检测中的模态缺失问题，通过模态无关可变形注意力机制和伪模态丢弃策略，使检测器能灵活适应单双模态场景。


<details>
  <summary>Details</summary>
Motivation: 当前IVOD模型在面对不完整模态数据时性能显著下降，特别是当主导模态缺失时。需要从架构兼容性角度解决模态不完整的IVOD问题。

Method: 提出插拔式Scarf Neck模块，引入模态无关可变形注意力机制；设计伪模态丢弃策略充分利用多模态信息；建立模态不完整IVOD基准测试。

Result: Scarf-DETR在模态缺失场景下表现优异，同时在标准IVOD模态完整基准测试中也取得优越性能。

Conclusion: 该方法不仅有效解决了模态缺失问题，还提升了整体检测性能，为全天候应用提供了更鲁棒的解决方案。

Abstract: Infrared and visible object detection (IVOD) is essential for numerous around-the-clock applications. Despite notable advancements, current IVOD models exhibit notable performance declines when confronted with incomplete modality data, particularly if the dominant modality is missing. In this paper, we take a thorough investigation on modality incomplete IVOD problem from an architecture compatibility perspective. Specifically, we propose a plug-and-play Scarf Neck module for DETR variants, which introduces a modality-agnostic deformable attention mechanism to enable the IVOD detector to flexibly adapt to any single or double modalities during training and inference. When training Scarf-DETR, we design a pseudo modality dropout strategy to fully utilize the multi-modality information, making the detector compatible and robust to both working modes of single and double modalities. Moreover, we introduce a comprehensive benchmark for the modality-incomplete IVOD task aimed at thoroughly assessing situations where the absent modality is either dominant or secondary. Our proposed Scarf-DETR not only performs excellently in missing modality scenarios but also achieves superior performances on the standard IVOD modality complete benchmarks. Our code will be available at https://github.com/YinghuiXing/Scarf-DETR.

</details>


### [24] [Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models](https://arxiv.org/abs/2511.06490)
*Yule Chen,Yufan Ren,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: AI4VA-FG是首个针对VLM漫画理解的细粒度基准测试，涵盖从基础识别到高级推理任务。评估显示当前VLMs在漫画理解上存在显著不足，作者提出多种后训练策略，特别是区域感知强化学习(RARL)，在Qwen2.5-VL上显著提升了实体识别和故事排序性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在自然图像上表现出色，但在处理风格化线条艺术、拟声词和密集多面板布局的漫画时存在困难，需要专门的基准测试和改进方法。

Method: 构建AI4VA-FG基准测试，评估主流VLMs性能，研究监督微调(SFT-S、SFT-R)和强化学习(RL)等后训练策略，并提出区域感知强化学习(RARL)方法。

Result: 评估显示GPT-4o、Gemini-2.5、Qwen2.5-VL等模型在漫画理解任务上存在显著性能缺陷。RL和RARL方法在Qwen2.5-VL上显著提升了低层实体识别和高层故事排序性能。

Conclusion: 漫画理解仍是未解决的挑战，提出的后训练策略特别是RARL方法为提升VLMs在漫画领域的应用能力提供了有效途径。

Abstract: Complex visual narratives, such as comics, present a significant challenge to Vision-Language Models (VLMs). Despite excelling on natural images, VLMs often struggle with stylized line art, onomatopoeia, and densely packed multi-panel layouts. To address this gap, we introduce AI4VA-FG, the first fine-grained and comprehensive benchmark for VLM-based comic understanding. It spans tasks from foundational recognition and detection to high-level character reasoning and narrative construction, supported by dense annotations for characters, poses, and depth. Beyond that, we evaluate state-of-the-art proprietary models, including GPT-4o and Gemini-2.5, and open-source models such as Qwen2.5-VL, revealing substantial performance deficits across core tasks of our benchmarks and underscoring that comic understanding remains an unsolved challenge. To enhance VLMs' capabilities in this domain, we systematically investigate post-training strategies, including supervised fine-tuning on solutions (SFT-S), supervised fine-tuning on reasoning trajectories (SFT-R), and reinforcement learning (RL). Beyond that, inspired by the emerging "Thinking with Images" paradigm, we propose Region-Aware Reinforcement Learning (RARL) for VLMs, which trains models to dynamically attend to relevant regions through zoom-in operations. We observe that when applied to the Qwen2.5-VL model, RL and RARL yield significant gains in low-level entity recognition and high-level storyline ordering, paving the way for more accurate and efficient VLM applications in the comics domain.

</details>


### [25] [Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling](https://arxiv.org/abs/2511.06658)
*Depanshu Sani,Mehar Khurana,Saket Anand*

Main category: cs.CV

TL;DR: 提出了一种新颖的主动学习动物重识别框架，通过互补聚类方法挖掘嵌入空间中结构模糊区域，仅需0.033%的标注就能显著超越现有基础模型、无监督学习和主动学习方法。


<details>
  <summary>Details</summary>
Motivation: 动物重识别面临物种间细微差异、新物种处理和开放集特性等挑战，现有基础模型的零样本性能存在显著差距，而无监督和主动学习方法在动物重识别中表现不佳。

Method: 利用互补聚类方法发现嵌入空间中的结构模糊区域，挖掘既具信息性又具广泛代表性的样本对，通过must-link和cannot-link约束进行标注，并集成到无监督学习方法中进行约束聚类优化。

Result: 在13个野生动物数据集上，相比基础模型、无监督学习和主动学习方法，平均mAP分别提升10.49%、11.19%和3.99%，在开放世界设置中对未知个体的性能分别提升11.09%、8.2%和2.06%。

Conclusion: 该方法通过极少量标注就能显著提升动物重识别性能，为处理动物重识别的独特挑战提供了有效解决方案，并在所有数据集上达到了最先进的性能。

Abstract: Animal Re-ID has recently gained substantial attention in the AI research community due to its high impact on biodiversity monitoring and unique research challenges arising from environmental factors. The subtle distinguishing patterns, handling new species and the inherent open-set nature make the problem even harder. To address these complexities, foundation models trained on labeled, large-scale and multi-species animal Re-ID datasets have recently been introduced to enable zero-shot Re-ID. However, our benchmarking reveals significant gaps in their zero-shot Re-ID performance for both known and unknown species. While this highlights the need for collecting labeled data in new domains, exhaustive annotation for Re-ID is laborious and requires domain expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID methods underperform for animal Re-ID. To address these limitations, we introduce a novel AL Re-ID framework that leverages complementary clustering methods to uncover and target structurally ambiguous regions in the embedding space for mining pairs of samples that are both informative and broadly representative. Oracle feedback on these pairs, in the form of must-link and cannot-link constraints, facilitates a simple annotation interface, which naturally integrates with existing USL methods through our proposed constrained clustering refinement algorithm. Through extensive experiments, we demonstrate that, by utilizing only 0.033% of all annotations, our approach consistently outperforms existing foundational, USL and AL baselines. Specifically, we report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife datasets over foundational, USL and AL methods, respectively, while attaining state-of-the-art performance on each dataset. Furthermore, we also show an improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world setting.

</details>


### [26] [Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks](https://arxiv.org/abs/2511.06665)
*Lingran Song,Yucheng Zhou,Jianbing Shen*

Main category: cs.CV

TL;DR: 本文提出了医学诊断分割（MDS）任务，将医学图像分割与诊断任务联合处理，并开发了M3DS数据集和Sim4Seg框架，通过区域感知视觉语言相似性到掩码（RVLS2M）模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割模型很少联合探索医学分割和诊断任务，但为患者提供可解释的诊断结果与分割结果同样重要。

Method: 提出Sim4Seg框架，利用区域感知视觉语言相似性到掩码（RVLS2M）模块，并研究了MDS任务的测试时缩放策略。

Result: 实验结果表明，该方法在分割和诊断方面均优于基线模型。

Conclusion: 联合处理医学分割和诊断任务能够提供更全面的医学图像分析解决方案，所提出的方法在性能上表现出色。

Abstract: Despite significant progress in pixel-level medical image analysis, existing medical image segmentation models rarely explore medical segmentation and diagnosis tasks jointly. However, it is crucial for patients that models can provide explainable diagnoses along with medical segmentation results. In this paper, we introduce a medical vision-language task named Medical Diagnosis Segmentation (MDS), which aims to understand clinical queries for medical images and generate the corresponding segmentation masks as well as diagnostic results. To facilitate this task, we first present the Multimodal Multi-disease Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal multi-disease medical images paired with their corresponding segmentation masks and diagnosis chain-of-thought, created via an automated diagnosis chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel framework that improves the performance of diagnosis segmentation by taking advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M) module. To improve overall performance, we investigate a test-time scaling strategy for MDS tasks. Experimental results demonstrate that our method outperforms the baselines in both segmentation and diagnosis.

</details>


### [27] [MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos](https://arxiv.org/abs/2511.06716)
*Rui Song,Jiaying Lin,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: 本文提出了一种名为MirrorMamba的新型视频镜面检测方法，通过结合深度感知、对应关系和光流等多重线索，并利用Mamba架构的全局感受野和线性复杂度优势，显著提升了镜面检测的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频镜面检测方法性能有限且鲁棒性不足，主要问题包括过度依赖单一不可靠的动态特征，以及CNN感受野有限或Transformer计算复杂度高。

Method: 提出MirrorMamba方法：1）利用深度感知、对应关系和光流等多重线索；2）引入基于Mamba的多方向对应关系提取器；3）设计基于Mamba的逐层边界增强解码器。

Result: 在基准数据集上超越现有最先进方法，在最具挑战性的基于图像的镜面检测数据集上达到最先进性能，证明了方法的鲁棒性和泛化能力。

Conclusion: MirrorMamba是首个在镜面检测领域成功应用Mamba架构的方法，通过多重线索和Mamba架构的优势，显著提升了视频镜面检测的性能和鲁棒性。

Abstract: Video mirror detection has received significant research attention, yet existing methods suffer from limited performance and robustness. These approaches often over-rely on single, unreliable dynamic features, and are typically built on CNNs with limited receptive fields or Transformers with quadratic computational complexity. To address these limitations, we propose a new effective and scalable video mirror detection method, called MirrorMamba. Our approach leverages multiple cues to adapt to diverse conditions, incorporating perceived depth, correspondence and optical. We also introduce an innovative Mamba-based Multidirection Correspondence Extractor, which benefits from the global receptive field and linear complexity of the emerging Mamba spatial state model to effectively capture correspondence properties. Additionally, we design a Mamba-based layer-wise boundary enforcement decoder to resolve the unclear boundary caused by the blurred depth map. Notably, this work marks the first successful application of the Mamba-based architecture in the field of mirror detection. Extensive experiments demonstrate that our method outperforms existing state-of-the-art approaches for video mirror detection on the benchmark datasets. Furthermore, on the most challenging and representative image-based mirror detection dataset, our approach achieves state-of-the-art performance, proving its robustness and generalizability.

</details>


### [28] [TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning](https://arxiv.org/abs/2511.06817)
*Rui Wang,Ying Zhou,Hao Wang,Wenwei Zhang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 提出TiS-TSL框架，通过时间可切换的师生学习解决微创手术中视频立体匹配问题，在最小监督下实现时空一致的视差预测。


<details>
  <summary>Details</summary>
Motivation: 微创手术中的立体匹配对于导航和增强现实至关重要，但由于解剖限制，密集视差监督几乎不可能，现有方法缺乏时空一致性导致预测不稳定和闪烁伪影。

Method: 提出统一模型支持三种模式：图像预测、前向视频预测和后向视频预测，采用两阶段学习策略：图像到视频阶段转移稀疏知识，视频到视频阶段通过双向时空一致性过滤噪声伪标签并强制时间一致性。

Result: 在两个公开数据集上的实验表明，TiS-TSL在TEPE和EPE指标上分别比现有图像方法至少提升2.11%和4.54%。

Conclusion: TiS-TSL框架通过时间可切换的师生学习和双向时空一致性建模，在最小监督下实现了稳定且时空一致的视频立体匹配。

Abstract: Stereo matching in minimally invasive surgery (MIS) is essential for next-generation navigation and augmented reality. Yet, dense disparity supervision is nearly impossible due to anatomical constraints, typically limiting annotations to only a few image-level labels acquired before the endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a promising solution by leveraging a teacher trained on sparse labels to generate pseudo labels and associated confidence maps from abundant unlabeled surgical videos. However, existing TSL methods are confined to image-level supervision, providing only spatial confidence and lacking temporal consistency estimation. This absence of spatio-temporal reliability results in unstable disparity predictions and severe flickering artifacts across video frames. To overcome these challenges, we propose TiS-TSL, a novel time-switchable teacher-student learning framework for video stereo matching under minimal supervision. At its core is a unified model that operates in three distinct modes: Image-Prediction (IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP), enabling flexible temporal modeling within a single architecture. Enabled by this unified model, TiS-TSL adopts a two-stage learning strategy. The Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal disparity predictions by comparing forward and backward predictions to calculate bidirectional spatio-temporal consistency. This consistency identifies unreliable regions across frames, filters noisy video-level pseudo labels, and enforces temporal coherence. Experimental results on two public datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts by improving TEPE and EPE by at least 2.11% and 4.54%, respectively.

</details>


### [29] [NeuroBridge: Bio-Inspired Self-Supervised EEG-to-Image Decoding via Cognitive Priors and Bidirectional Semantic Alignment](https://arxiv.org/abs/2511.06836)
*Wenjiang Zhang,Sifeng Wang,Yuwei Su,Xinyu Li,Chen Zhang,Suyu Zhong*

Main category: cs.CV

TL;DR: 本文提出了一种名为NeuroBridge的自监督架构，通过认知先验增强和共享语义投影器来解决视觉神经解码中的语义不匹配问题，在脑电图信号和图像之间建立有效的跨模态对齐。


<details>
  <summary>Details</summary>
Motivation: 当前视觉神经解码方法受限于高质量刺激-脑响应对的稀缺性以及神经表征与视觉内容之间的语义不匹配。受生物系统的感知变异性和共适应策略启发，需要开发更有效的跨模态对齐方法。

Method: NeuroBridge架构整合了认知先验增强和共享语义投影器。CPA通过应用不对称的模态特定变换来模拟感知变异性，增强语义多样性；SSP通过共适应策略建立双向对齐过程，将两个模态的特征相互对齐到共享语义空间中。

Result: NeuroBridge在受试者内和受试者间设置下均超越了先前的最先进方法。在受试者内场景中，在200路零样本检索任务上，top-1准确率提高了12.3%达到63.2%，top-5准确率提高了10.2%达到89.9%。

Conclusion: 广泛的实验证明了所提出框架在神经视觉解码方面的有效性、鲁棒性和可扩展性，为脑机接口和人工智能应用提供了重要进展。

Abstract: Visual neural decoding seeks to reconstruct or infer perceived visual stimuli from brain activity patterns, providing critical insights into human cognition and enabling transformative applications in brain-computer interfaces and artificial intelligence. Current approaches, however, remain constrained by the scarcity of high-quality stimulus-brain response pairs and the inherent semantic mismatch between neural representations and visual content. Inspired by perceptual variability and co-adaptive strategy of the biological systems, we propose a novel self-supervised architecture, named NeuroBridge, which integrates Cognitive Prior Augmentation (CPA) with Shared Semantic Projector (SSP) to promote effective cross-modality alignment. Specifically, CPA simulates perceptual variability by applying asymmetric, modality-specific transformations to both EEG signals and images, enhancing semantic diversity. Unlike previous approaches, SSP establishes a bidirectional alignment process through a co-adaptive strategy, which mutually aligns features from two modalities into a shared semantic space for effective cross-modal learning. NeuroBridge surpasses previous state-of-the-art methods under both intra-subject and inter-subject settings. In the intra-subject scenario, it achieves the improvements of 12.3% in top-1 accuracy and 10.2% in top-5 accuracy, reaching 63.2% and 89.9% respectively on a 200-way zero-shot retrieval task. Extensive experiments demonstrate the effectiveness, robustness, and scalability of the proposed framework for neural visual decoding.

</details>


### [30] [PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data](https://arxiv.org/abs/2511.06943)
*Ayushi Sharma,Johanna Trost,Daniel Lusk,Johannes Dollinger,Julian Schrader,Christian Rossi,Javier Lopatin,Etienne Laliberté,Simon Haberstroh,Jana Eichel,Daniel Mederer,Jose Miguel Cerda-Paredes,Shyam S. Phartyal,Lisa-Maricia Schwarz,Anja Linstädter,Maria Conceição Caldeira,Teja Kattenborn*

Main category: cs.CV

TL;DR: PlantTraitNet是一个多模态、多任务的不确定性感知深度学习框架，利用公民科学照片通过弱监督预测四种关键植物性状，并生成全球性状分布图，在准确性上优于现有全球性状产品。


<details>
  <summary>Details</summary>
Motivation: 现有植物性状地图受限于野外测量的高成本和稀疏地理覆盖，而全球超过5000万张地理标记植物照片提供了宝贵的视觉信息，公民科学资源尚未充分利用来克服这些限制。

Method: 开发PlantTraitNet多模态多任务不确定性感知深度学习框架，使用弱监督从公民科学照片预测植物高度、叶面积、比叶面积和氮含量四种关键性状，通过空间聚合生成全球性状分布图。

Result: 与独立植被调查数据验证和现有全球性状产品基准测试显示，PlantTraitNet在所有评估性状上持续优于现有性状地图，证明公民科学图像结合计算机视觉和地理空间AI能够实现更准确且可扩展的全球性状制图。

Conclusion: 该方法为生态研究和地球系统建模提供了强大的新途径，表明公民科学资源与先进AI技术结合能够显著提升全球植物性状制图的准确性和可扩展性。

Abstract: Global plant maps of plant traits, such as leaf nitrogen or plant height, are essential for understanding ecosystem processes, including the carbon and energy cycles of the Earth system. However, existing trait maps remain limited by the high cost and sparse geographic coverage of field-based measurements. Citizen science initiatives offer a largely untapped resource to overcome these limitations, with over 50 million geotagged plant photographs worldwide capturing valuable visual information on plant morphology and physiology. In this study, we introduce PlantTraitNet, a multi-modal, multi-task uncertainty-aware deep learning framework that predictsfour key plant traits (plant height, leaf area, specific leaf area, and nitrogen content) from citizen science photos using weak supervision. By aggregating individual trait predictions across space, we generate global maps of trait distributions. We validate these maps against independent vegetation survey data (sPlotOpen) and benchmark them against leading global trait products. Our results show that PlantTraitNet consistently outperforms existing trait maps across all evaluated traits, demonstrating that citizen science imagery, when integrated with computer vision and geospatial AI, enables not only scalable but also more accurate global trait mapping. This approach offers a powerful new pathway for ecological research and Earth system modeling.

</details>


### [31] [From Attribution to Action: Jointly ALIGNing Predictions and Explanations](https://arxiv.org/abs/2511.06944)
*Dongsheng Hong,Chao Chen,Yanhui Chen,Shanshan Lin,Zhihao Chen,Xiangwen Liao*

Main category: cs.CV

TL;DR: ALIGN框架通过联合训练分类器和掩码器，使用高质量掩码作为指导，提升模型的可解释性和泛化能力，在领域泛化基准测试中优于多个基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有解释引导学习方法依赖外部标注或启发式分割，这些监督信号质量低、噪声大且难以扩展，可能降低模型性能而非提升。

Method: 提出ALIGN框架，以迭代方式联合训练分类器和掩码器。掩码器学习生成软性的任务相关掩码，分类器同时优化预测准确性和其显著性图与学习掩码的对齐度。

Result: 在VLCS和Terra Incognita两个领域泛化基准测试中，ALIGN在分布内和分布外设置下均一致优于六个强基线方法，并产生更高质量的解释。

Conclusion: ALIGN通过利用高质量掩码作为指导，有效提升了模型的可解释性和泛化能力，证明了其在生成准确且可解释模型方面的有效性。

Abstract: Explanation-guided learning (EGL) has shown promise in aligning model predictions with interpretable reasoning, particularly in computer vision tasks. However, most approaches rely on external annotations or heuristic-based segmentation to supervise model explanations, which can be noisy, imprecise and difficult to scale. In this work, we provide both empirical and theoretical evidence that low-quality supervision signals can degrade model performance rather than improve it. In response, we propose ALIGN, a novel framework that jointly trains a classifier and a masker in an iterative manner. The masker learns to produce soft, task-relevant masks that highlight informative regions, while the classifier is optimized for both prediction accuracy and alignment between its saliency maps and the learned masks. By leveraging high-quality masks as guidance, ALIGN improves both interpretability and generalizability, showing its superiority across various settings. Experiments on the two domain generalization benchmarks, VLCS and Terra Incognita, show that ALIGN consistently outperforms six strong baselines in both in-distribution and out-of-distribution settings. Besides, ALIGN also yields superior explanation quality concerning sufficiency and comprehensiveness, highlighting its effectiveness in producing accurate and interpretable models.

</details>


### [32] [FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection](https://arxiv.org/abs/2511.06947)
*Yulin Chen,Zeyuan Wang,Tianyuan Yu,Yingmei Wei,Liang Bai*

Main category: cs.CV

TL;DR: FoCLIP是一个针对CLIP-based图像质量评估指标的欺骗框架，通过特征空间错位技术生成欺骗样本，能够在保持高视觉保真度的同时显著提升CLIPscore评分，并提出了基于颜色通道敏感性的篡改检测机制。


<details>
  <summary>Details</summary>
Motivation: CLIP-based模型虽然具有良好的多模态对齐特性，但其图像质量评估指标CLIPscore容易受到精心设计的欺骗攻击。本研究旨在探索如何通过特征空间错位来欺骗CLIP-based指标，同时研究相应的防御方法。

Method: 基于随机梯度下降技术，FoCLIP整合了三个关键组件：特征对齐作为核心模块以减少图像-文本模态差距、分数分布平衡模块和像素保护正则化，共同优化CLIPscore性能与图像质量之间的多模态输出平衡。

Result: 在十个艺术杰作提示和ImageNet子集上的实验表明，优化后的图像在保持高视觉保真度的同时，CLIPscore显著提升。此外，灰度转换会导致欺骗图像特征显著退化，CLIPscore明显降低但统计特性与原始图像一致。基于此现象提出的颜色通道敏感性驱动的篡改检测机制在标准基准上达到91%的准确率。

Conclusion: 本研究为CLIP-based多模态系统中的特征错位建立了实用路径，并提出了相应的防御方法，揭示了多模态系统在对抗性攻击下的脆弱性及其防御策略。

Abstract: The well-aligned attribute of CLIP-based models enables its effective application like CLIPscore as a widely adopted image quality assessment metric. However, such a CLIP-based metric is vulnerable for its delicate multimodal alignment. In this work, we propose \textbf{FoCLIP}, a feature-space misalignment framework for fooling CLIP-based image quality metric. Based on the stochastic gradient descent technique, FoCLIP integrates three key components to construct fooling examples: feature alignment as the core module to reduce image-text modality gaps, the score distribution balance module and pixel-guard regularization, which collectively optimize multimodal output equilibrium between CLIPscore performance and image quality. Such a design can be engineered to maximize the CLIPscore predictions across diverse input prompts, despite exhibiting either visual unrecognizability or semantic incongruence with the corresponding adversarial prompts from human perceptual perspectives. Experiments on ten artistic masterpiece prompts and ImageNet subsets demonstrate that optimized images can achieve significant improvement in CLIPscore while preserving high visual fidelity. In addition, we found that grayscale conversion induces significant feature degradation in fooling images, exhibiting noticeable CLIPscore reduction while preserving statistical consistency with original images. Inspired by this phenomenon, we propose a color channel sensitivity-driven tampering detection mechanism that achieves 91% accuracy on standard benchmarks. In conclusion, this work establishes a practical pathway for feature misalignment in CLIP-based multimodal systems and the corresponding defense method.

</details>


### [33] [TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding](https://arxiv.org/abs/2511.07007)
*Duc Nguyen,Yan-Ling Lai,Qilin Zhang,Prabin Gyawali,Benedikt Schwab,Olaf Wysocki,Thomas H. Kolbe*

Main category: cs.CV

TL;DR: TrueCity是首个城市语义分割基准数据集，提供厘米级精度的真实世界点云标注、语义3D城市模型和模拟点云，用于量化合成到真实的域偏移。


<details>
  <summary>Details</summary>
Motivation: 解决3D语义场景理解中真实世界标注数据有限的问题，以及现有合成数据集无法捕捉真实世界复杂性和传感器噪声导致的域偏移问题。

Method: 创建TrueCity基准数据集，包含同步的真实和模拟点云数据，采用与国际3D城市建模标准对齐的分割类别。

Result: 通过广泛的实验量化了域偏移，并展示了利用合成数据增强真实世界3D场景理解的策略。

Conclusion: TrueCity数据集将促进sim-to-real域偏移量化方法的进一步发展，并支持可泛化的数据驱动模型开发。

Abstract: 3D semantic scene understanding remains a long-standing challenge in the 3D computer vision community. One of the key issues pertains to limited real-world annotated data to facilitate generalizable models. The common practice to tackle this issue is to simulate new data. Although synthetic datasets offer scalability and perfect labels, their designer-crafted scenes fail to capture real-world complexity and sensor noise, resulting in a synthetic-to-real domain gap. Moreover, no benchmark provides synchronized real and simulated point clouds for segmentation-oriented domain shift analysis. We introduce TrueCity, the first urban semantic segmentation benchmark with cm-accurate annotated real-world point clouds, semantic 3D city models, and annotated simulated point clouds representing the same city. TrueCity proposes segmentation classes aligned with international 3D city modeling standards, enabling consistent evaluation of synthetic-to-real gap. Our extensive experiments on common baselines quantify domain shift and highlight strategies for exploiting synthetic data to enhance real-world 3D scene understanding. We are convinced that the TrueCity dataset will foster further development of sim-to-real gap quantification and enable generalizable data-driven models. The data, code, and 3D models are available online: https://tum-gis.github.io/TrueCity/

</details>


### [34] [Pandar128 dataset for lane line detection](https://arxiv.org/abs/2511.07084)
*Filip Beránek,Václav Diviš,Ivan Gruber*

Main category: cs.CV

TL;DR: Pandar128是最大的公开128线激光雷达车道线检测数据集，包含5.2万相机帧和3.4万激光雷达扫描，提供完整传感器标定和同步里程计。提出了轻量级基线方法SimpleLidarLane和新的评估指标IAM-F1。


<details>
  <summary>Details</summary>
Motivation: 解决激光雷达车道线检测领域缺乏大规模公开数据集和标准化评估方法的问题，为研究提供高质量数据和可靠评估基准。

Method: 使用128线激光雷达采集多样化真实场景数据；提出SimpleLidarLane方法，结合BEV分割、聚类和折线拟合；设计IAM-F1评估指标，采用插值感知的横向匹配策略。

Result: 构建了包含5.2万相机帧和3.4万激光雷达扫描的大规模数据集；轻量级方法在挑战性条件下表现良好；新评估指标提供了更可靠的性能度量。

Conclusion: 高质量数据与模块化方法结合可以匹敌复杂方法，标准化评估对领域发展至关重要，公开数据代码支持可复现性研究。

Abstract: We present Pandar128, the largest public dataset for lane line detection using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR scans, captured in diverse real-world conditions in Germany. The dataset includes full sensor calibration (intrinsics, extrinsics) and synchronized odometry, supporting tasks such as projection, fusion, and temporal modeling.
  To complement the dataset, we also introduce SimpleLidarLane, a light-weight baseline method for lane line reconstruction that combines BEV segmentation, clustering, and polyline fitting. Despite its simplicity, our method achieves strong performance under challenging various conditions (e.g., rain, sparse returns), showing that modular pipelines paired with high-quality data and principled evaluation can compete with more complex approaches.
  Furthermore, to address the lack of standardized evaluation, we propose a novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that employs interpolation-aware lateral matching in BEV space.
  All data and code are publicly released to support reproducibility in LiDAR-based lane detection.

</details>


### [35] [How Bias Binds: Measuring Hidden Associations for Bias Control in Text-to-Image Compositions](https://arxiv.org/abs/2511.07091)
*Jeng-Lin Li,Ming-Ching Chang,Wei-Chao Chen*

Main category: cs.CV

TL;DR: 本文研究了文本到图像生成模型中语义绑定下的偏见问题，发现当前去偏见方法在处理对象-属性语义关联时存在显著失败，提出了偏见依从性评分和无需训练的上下文偏见控制框架，在组合生成任务中实现了超过10%的去偏见改进。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型存在偏见问题，但现有研究主要关注单一对象提示，忽略了对象与属性之间的语义绑定对偏见的联合影响。现实中的提示往往包含多个对象和属性，这些语义关联会放大偏见分布。

Method: 提出了偏见依从性评分来量化特定对象-属性绑定激活偏见的方式，并开发了无需训练的上下文偏见控制框架，通过标记解耦来促进语义绑定的去偏见。

Result: 该框架在组合生成任务中实现了超过10%的去偏见改进，分析显示偏见评分在不同属性-对象绑定和标记去相关方面存在根本性挑战。

Conclusion: 研究揭示了当前去偏见方法在语义绑定上下文中的关键局限性，强调了需要重新评估主流偏见缓解策略的必要性，表明减少偏见而不破坏基本语义关系是一个根本性挑战。

Abstract: Text-to-image generative models often exhibit bias related to sensitive attributes. However, current research tends to focus narrowly on single-object prompts with limited contextual diversity. In reality, each object or attribute within a prompt can contribute to bias. For example, the prompt "an assistant wearing a pink hat" may reflect female-inclined biases associated with a pink hat. The neglected joint effects of the semantic binding in the prompts cause significant failures in current debiasing approaches. This work initiates a preliminary investigation on how bias manifests under semantic binding, where contextual associations between objects and attributes influence generative outcomes. We demonstrate that the underlying bias distribution can be amplified based on these associations. Therefore, we introduce a bias adherence score that quantifies how specific object-attribute bindings activate bias. To delve deeper, we develop a training-free context-bias control framework to explore how token decoupling can facilitate the debiasing of semantic bindings. This framework achieves over 10% debiasing improvement in compositional generation tasks. Our analysis of bias scores across various attribute-object bindings and token decorrelation highlights a fundamental challenge: reducing bias without disrupting essential semantic relationships. These findings expose critical limitations in current debiasing approaches when applied to semantically bound contexts, underscoring the need to reassess prevailing bias mitigation strategies.

</details>


### [36] [GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for Hyperspectral Image Super-resolution](https://arxiv.org/abs/2511.07103)
*Sirui Wang,Jiang He,Natàlia Blasco Andreo,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出GEWDiff框架，通过小波编码器和几何增强扩散过程实现高光谱图像的4倍超分辨率重建，解决了传统扩散模型在高光谱图像生成中的内存限制和几何结构理解不足问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像生成面临三大挑战：高光谱维度导致内存密集、传统生成模型缺乏对遥感图像几何结构的理解、扩散模型在噪声层面的损失函数优化导致收敛行为不直观。

Method: 采用小波编码器-解码器压缩高光谱图像到潜在空间，引入几何增强扩散过程保持几何特征，设计多层次损失函数指导扩散过程。

Result: 在保真度、光谱精度、视觉真实性和清晰度等多个维度上达到最先进水平。

Conclusion: GEWDiff框架有效解决了高光谱图像超分辨率重建中的关键挑战，实现了高质量的重建效果。

Abstract: Improving the quality of hyperspectral images (HSIs), such as through super-resolution, is a crucial research area. However, generative modeling for HSIs presents several challenges. Due to their high spectral dimensionality, HSIs are too memory-intensive for direct input into conventional diffusion models. Furthermore, general generative models lack an understanding of the topological and geometric structures of ground objects in remote sensing imagery. In addition, most diffusion models optimize loss functions at the noise level, leading to a non-intuitive convergence behavior and suboptimal generation quality for complex data. To address these challenges, we propose a Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework for reconstructing hyperspectral images at 4-times super-resolution. A wavelet-based encoder-decoder is introduced that efficiently compresses HSIs into a latent space while preserving spectral-spatial information. To avoid distortion during generation, we incorporate a geometry-enhanced diffusion process that preserves the geometric features. Furthermore, a multi-level loss function was designed to guide the diffusion process, promoting stable convergence and improved reconstruction fidelity. Our model demonstrated state-of-the-art results across multiple dimensions, including fidelity, spectral accuracy, visual realism, and clarity.

</details>


### [37] [Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use](https://arxiv.org/abs/2511.07171)
*Sébastien Thuau,Siba Haidar,Rachid Chelouah*

Main category: cs.CV

TL;DR: 本文比较了三种联邦学习暴力检测方法：预训练VLM的零样本推理、LoRA微调LLaVA-NeXT-Video-7B和个性化联邦学习3D CNN。3D CNN在能耗减半的情况下达到92.59% ROC AUC，而VLM提供更丰富的多模态推理。分层类别分组将VLM多类准确率从65.31%提升到81%。


<details>
  <summary>Details</summary>
Motivation: 深度学习视频监控需要隐私保护架构，但部署大型视觉语言模型会带来能源和可持续性挑战。联邦学习能保护隐私，但需要解决计算和环境开销问题。

Method: 比较三种联邦暴力检测策略：1) 预训练VLM零样本推理 2) LoRA微调LLaVA-NeXT-Video-7B 3) 个性化联邦学习65.8M参数3D CNN。使用RWF-2000和RLVS数据集，在非IID数据分布下进行实验。

Result: 所有方法在二元暴力检测中准确率均超过90%。3D CNN达到92.59% ROC AUC，能耗仅为联邦LoRA的一半（240 Wh vs 570 Wh）。分层类别分组将VLM在UCF-Crime数据集上的多类准确率从65.31%提升到81%。

Conclusion: 建议采用混合部署策略：默认使用高效CNN进行常规推理，有选择性地使用VLM进行复杂上下文推理。这是首个对LoRA调优VLM和个性化CNN在联邦暴力检测中的比较研究，包含明确的能源和CO2e量化。

Abstract: Deep learning-based video surveillance increasingly demands privacy-preserving architectures with low computational and environmental overhead. Federated learning preserves privacy but deploying large vision-language models (VLMs) introduces major energy and sustainability challenges. We compare three strategies for federated violence detection under realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed 90% accuracy in binary violence detection. The 3D CNN achieves superior calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570 Wh) of federated LoRA, while VLMs provide richer multimodal reasoning. Hierarchical category grouping (based on semantic similarity and class exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime dataset. To our knowledge, this is the first comparative simulation study of LoRA-tuned VLMs and personalized CNNs for federated violence detection, with explicit energy and CO2e quantification. Our results inform hybrid deployment strategies that default to efficient CNNs for routine inference and selectively engage VLMs for complex contextual reasoning.

</details>


### [38] [Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation](https://arxiv.org/abs/2511.07238)
*Seungheon Song,Jaekoo Lee*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉-语言空间的新颖OOD分割方法，通过结合视觉语言模型编码器和transformer解码器，利用距离基OOD提示和OOD语义增强，在自动驾驶场景中实现鲁棒的异常物体分割。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和机器人领域，确保道路安全和可靠决策严重依赖于OOD分割。虽然已有许多方法用于检测道路上的异常物体，但利用提供丰富语言知识的视觉-语言空间仍是一个未被充分探索的领域。作者假设在现实世界自动驾驶的复杂场景中，融入这些语言线索尤其有益。

Method: 提出训练文本驱动的OOD分割模型，在视觉-语言空间中学习语义多样化的物体集合。具体方法包括：结合视觉语言模型编码器与transformer解码器；使用距离基OOD提示（位于与ID类不同语义距离的位置）；应用OOD语义增强来增强OOD表示。通过对齐视觉和文本信息，有效泛化到未见物体。

Result: 在Fishyscapes、Segment-Me-If-You-Can和Road Anomaly等公开OOD分割数据集上进行广泛实验，结果显示该方法在像素级和物体级评估中均达到最先进的性能水平。

Conclusion: 这一结果强调了基于视觉-语言的OOD分割在增强未来自动驾驶系统安全性和可靠性方面的潜力。

Abstract: In autonomous driving and robotics, ensuring road safety and reliable decision-making critically depends on out-of-distribution (OOD) segmentation. While numerous methods have been proposed to detect anomalous objects on the road, leveraging the vision-language space-which provides rich linguistic knowledge-remains an underexplored field. We hypothesize that incorporating these linguistic cues can be especially beneficial in the complex contexts found in real-world autonomous driving scenarios.
  To this end, we present a novel approach that trains a Text-Driven OOD Segmentation model to learn a semantically diverse set of objects in the vision-language space. Concretely, our approach combines a vision-language model's encoder with a transformer decoder, employs Distance-Based OOD prompts located at varying semantic distances from in-distribution (ID) classes, and utilizes OOD Semantic Augmentation for OOD representations. By aligning visual and textual information, our approach effectively generalizes to unseen objects and provides robust OOD segmentation in diverse driving environments.
  We conduct extensive experiments on publicly available OOD segmentation datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets, demonstrating that our approach achieves state-of-the-art performance across both pixel-level and object-level evaluations. This result underscores the potential of vision-language-based OOD segmentation to bolster the safety and reliability of future autonomous driving systems.

</details>


### [39] [MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs](https://arxiv.org/abs/2511.07250)
*Tianhao Peng,Haochen Wang,Yuanxing Zhang,Zekun Wang,Zili Wang,Ge Zhang,Jian Yang,Shihao Li,Yanghai Wang,Xintao Wang,Houyi Li,Wei Ji,Pengfei Wan,Wenhao Huang,Zhaoxiang Zhang,Jiaheng Liu*

Main category: cs.CV

TL;DR: MVU-Eval是首个针对多模态大语言模型的多视频理解评估基准，包含1,824个精心设计的问答对，覆盖4,959个视频，评估8个核心能力，填补了现有基准仅限于单视频理解的空白。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准仅限于单视频理解，忽视了现实场景中多视频理解的关键需求，如体育分析和自动驾驶中的多传感器融合。

Method: 构建MVU-Eval基准，包含1,824个问答对，覆盖4,959个来自不同领域的视频，评估8个核心能力，包括基础感知任务和高级推理任务。

Result: 通过对开源和闭源模型的广泛评估，揭示了当前MLLMs在多视频理解能力上存在显著的性能差距和局限性。

Conclusion: MVU-Eval基准将公开提供，以促进未来研究，填补多视频理解评估的空白。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has expanded AI capabilities to visual modalities, yet existing evaluation benchmarks remain limited to single-video understanding, overlooking the critical need for multi-video understanding in real-world scenarios (e.g., sports analytics and autonomous driving). To address this significant gap, we introduce MVU-Eval, the first comprehensive benchmark for evaluating Multi-Video Understanding for MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies through 1,824 meticulously curated question-answer pairs spanning 4,959 videos from diverse domains, addressing both fundamental perception tasks and high-order reasoning tasks. These capabilities are rigorously aligned with real-world applications such as multi-sensor synthesis in autonomous systems and cross-angle sports analytics. Through extensive evaluation of state-of-the-art open-source and closed-source models, we reveal significant performance discrepancies and limitations in current MLLMs' ability to perform understanding across multiple videos. The benchmark will be made publicly available to foster future research.

</details>


### [40] [Glioma C6: A Novel Dataset for Training and Benchmarking Cell Segmentation](https://arxiv.org/abs/2511.07286)
*Roman Malashin,Svetlana Pashkevich,Daniil Ilyukhin,Arseniy Volkov,Valeria Yachnaya,Andrey Denisov,Maria Mikhalkova*

Main category: cs.CV

TL;DR: Glioma C6是一个用于胶质瘤C6细胞实例分割的新开放数据集，包含75张高分辨率相差显微镜图像和超过12,000个标注细胞，旨在作为深度学习模型的基准和训练资源。


<details>
  <summary>Details</summary>
Motivation: 为生物医学图像分析提供真实的测试平台，通过包含生物学家提供的细胞形态分类来增强癌细胞研究中的图像数据利用。

Method: 数据集分为两部分：第一部分用于基准测试，参数受控；第二部分用于在不同条件下的泛化测试。评估了多个通用分割模型在数据集上的性能。

Result: 实验表明，在Glioma C6上训练显著提高了分割性能，证明了该数据集对于开发稳健和可泛化模型的价值。

Conclusion: Glioma C6数据集为研究人员开发细胞分割模型提供了有价值的资源，公开可用。

Abstract: We present Glioma C6, a new open dataset for instance segmentation of glioma C6 cells, designed as both a benchmark and a training resource for deep learning models. The dataset comprises 75 high-resolution phase-contrast microscopy images with over 12,000 annotated cells, providing a realistic testbed for biomedical image analysis. It includes soma annotations and morphological cell categorization provided by biologists. Additional categorization of cells, based on morphology, aims to enhance the utilization of image data for cancer cell research. Glioma C6 consists of two parts: the first is curated with controlled parameters for benchmarking, while the second supports generalization testing under varying conditions. We evaluate the performance of several generalist segmentation models, highlighting their limitations on our dataset. Our experiments demonstrate that training on Glioma C6 significantly enhances segmentation performance, reinforcing its value for developing robust and generalizable models. The dataset is publicly available for researchers.

</details>


### [41] [LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging](https://arxiv.org/abs/2511.07298)
*Kagan Celik,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出基于LLM的低剂量CT图像质量评估系统，生成数值评分和文本描述，评估噪声、模糊和对比度损失等退化问题，并系统研究多种推理策略。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT虽能降低辐射剂量，但会增加噪声、模糊和对比度损失，影响诊断质量，因此需要一致且鲁棒的图像质量评估方法。

Method: 开发LLM基础的图像质量评估系统，采用从零样本到元数据集成和错误反馈等多种推理策略。

Result: 评估结果不仅产生高度相关的评分，还提供可解释的输出，为临床工作流程增加价值。

Conclusion: 该系统通过渐进式方法改进性能，为低剂量CT图像质量评估提供了有效的解决方案。

Abstract: Low-dose computed tomography (CT) represents a significant improvement in patient safety through lower radiation doses, but increased noise, blur, and contrast loss can diminish diagnostic quality. Therefore, consistency and robustness in image quality assessment become essential for clinical applications. In this study, we propose an LLM-based quality assessment system that generates both numerical scores and textual descriptions of degradations such as noise, blur, and contrast loss. Furthermore, various inference strategies - from the zero-shot approach to metadata integration and error feedback - are systematically examined, demonstrating the progressive contribution of each method to overall performance. The resultant assessments yield not only highly correlated scores but also interpretable output, thereby adding value to clinical workflows. The source codes of our study are available at https://github.com/itu-biai/lmms_ldct_iqa.

</details>


### [42] [Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection](https://arxiv.org/abs/2511.07301)
*Huizai Yao,Sicheng Zhao,Pengteng Li,Yi Cui,Shuo Lu,Weiyu Guo,Yunfan Lu,Yijie Xu,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种利用视觉基础模型作为外部知识源的无源目标检测框架，通过三个模块提升特征对齐和标签质量，在六个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有无源目标检测方法主要依赖源模型的内部知识，限制了跨域泛化能力并导致伪标签偏差。视觉基础模型具有强大的感知能力和广泛泛化性，但在无源目标检测中尚未充分利用。

Method: 设计了三个视觉基础模型模块：基于补丁相似性加权的全局特征对齐、基于动量更新原型的实例特征对齐、以及通过熵感知策略融合检测视觉基础模型和教师模型预测的双源增强伪标签融合。

Result: 在六个基准测试上的广泛实验表明，该方法实现了最先进的无源目标检测性能。

Conclusion: 验证了整合视觉基础模型能同时提高可迁移性和判别性的有效性。

Abstract: Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object detector to a target domain without access to source data. However, existing SFOD methods predominantly rely on internal knowledge from the source model, which limits their capacity to generalize across domains and often results in biased pseudo-labels, thereby hindering both transferability and discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on massive and diverse data, exhibit strong perception capabilities and broad generalization, yet their potential remains largely untapped in the SFOD setting. In this paper, we propose a novel SFOD framework that leverages VFMs as external knowledge sources to jointly enhance feature alignment and label quality. Specifically, we design three VFM-based modules: (1) Patch-weighted Global Feature Alignment (PGFA) distills global features from VFMs using patch-similarity-based weighting to enhance global feature transferability; (2) Prototype-based Instance Feature Alignment (PIFA) performs instance-level contrastive learning guided by momentum-updated VFM prototypes; and (3) Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from detection VFMs and teacher models via an entropy-aware strategy to yield more reliable supervision. Extensive experiments on six benchmarks demonstrate that our method achieves state-of-the-art SFOD performance, validating the effectiveness of integrating VFMs to simultaneously improve transferability and discriminability.

</details>


### [43] [Inference-Time Scaling of Diffusion Models for Infrared Data Generation](https://arxiv.org/abs/2511.07362)
*Kai A. Horstmann,Maxim Clouser,Kia Khezeli*

Main category: cs.CV

TL;DR: 本文提出了一种在红外图像生成中使用领域自适应CLIP验证器进行推理时引导的方法，以解决红外领域高质量标注数据稀缺的问题。该方法在FLUX.1-dev扩散模型基础上，通过参数高效微调技术适应红外领域，并使用验证器在推理时引导生成更高质量的红外图像。


<details>
  <summary>Details</summary>
Motivation: 红外图像在低能见度条件下具有优势，但高质量标注数据稀缺限制了下游视觉模型的发展。虽然合成红外图像生成有潜力提供大规模训练数据，但由于数据集有限，在红外领域训练基础级生成扩散模型仍然困难。

Method: 采用推理时缩放方法，使用领域自适应CLIP验证器提升红外图像生成质量。首先在少量红外图像样本上使用参数高效技术微调FLUX.1-dev扩散模型，然后在推理时使用训练好的验证器引导扩散采样过程，生成更符合输入文本提示的高质量红外图像。

Result: 实验结果表明，该方法在KAIST多光谱行人检测基准数据集上，相比无引导基线样本，FID分数降低了10%，生成质量得到一致改善。

Conclusion: 推理时引导为在低数据红外设置中弥合领域差距提供了一个有前景的方向。

Abstract: Infrared imagery enables temperature-based scene understanding using passive sensors, particularly under conditions of low visibility where traditional RGB imaging fails. Yet, developing downstream vision models for infrared applications is hindered by the scarcity of high-quality annotated data, due to the specialized expertise required for infrared annotation. While synthetic infrared image generation has the potential to accelerate model development by providing large-scale, diverse training data, training foundation-level generative diffusion models in the infrared domain has remained elusive due to limited datasets. In light of such data constraints, we explore an inference-time scaling approach using a domain-adapted CLIP-based verifier for enhanced infrared image generation quality. We adapt FLUX.1-dev, a state-of-the-art text-to-image diffusion model, to the infrared domain by finetuning it on a small sample of infrared images using parameter-efficient techniques. The trained verifier is then employed during inference to guide the diffusion sampling process toward higher quality infrared generations that better align with input text prompts. Empirically, we find that our approach leads to consistent improvements in generation quality, reducing FID scores on the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared to unguided baseline samples. Our results suggest that inference-time guidance offers a promising direction for bridging the domain gap in low-data infrared settings.

</details>


### [44] [Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion](https://arxiv.org/abs/2511.07377)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: FLASH是一个新颖的LiDAR超分辨率框架，通过双域处理（空间域和频域）结合频率感知窗口注意力和自适应多尺度融合，在KITTI数据集上实现了最先进的性能，超越了基于transformer的方法，同时保持单次推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决低成本低分辨率LiDAR传感器实现高质量3D感知的挑战，克服现有transformer方法仅局限于空间域处理且感受野受限的问题。

Method: 提出FLASH框架，包含两个关键创新：1) 频率感知窗口注意力，结合局部空间注意力和通过FFT的全局频域分析；2) 自适应多尺度融合，用学习的位置特定特征聚合替换传统跳跃连接，并通过CBAM注意力增强动态特征选择。

Result: 在KITTI数据集上的广泛实验表明，FLASH在所有评估指标上都达到了最先进的性能，甚至超越了需要多次前向传播的不确定性增强基线方法。FLASH在保持单次推理效率的同时，性能优于使用蒙特卡洛Dropout的TULIP。

Conclusion: FLASH的双域方法通过架构设计而非计算昂贵的随机推理有效处理不确定性，在所有距离范围内的一致优越性验证了其有效性，使其适用于自动驾驶系统的实时部署。

Abstract: LiDAR super-resolution addresses the challenge of achieving high-quality 3D perception from cost-effective, low-resolution sensors. While recent transformer-based approaches like TULIP show promise, they remain limited to spatial-domain processing with restricted receptive fields. We introduce FLASH (Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a novel framework that overcomes these limitations through dual-domain processing. FLASH integrates two key innovations: (i) Frequency-Aware Window Attention that combines local spatial attention with global frequency-domain analysis via FFT, capturing both fine-grained geometry and periodic scanning patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that replaces conventional skip connections with learned position-specific feature aggregation, enhanced by CBAM attention for dynamic feature selection. Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art performance across all evaluation metrics, surpassing even uncertainty-enhanced baselines that require multiple forward passes. Notably, FLASH outperforms TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which enables real-time deployment. The consistent superiority across all distance ranges validates that our dual-domain approach effectively handles uncertainty through architectural design rather than computationally expensive stochastic inference, making it practical for autonomous systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [45] [From Prompts to Power: Measuring the Energy Footprint of LLM Inference](https://arxiv.org/abs/2511.05597)
*Francisco Caravaca,Ángel Cuevas,Rubén Cuevas*

Main category: cs.AI

TL;DR: 本文通过大规模测量研究分析了大型语言模型推理阶段的能耗问题，涵盖32,500多次测量、21种GPU配置和155种模型架构，开发了预测模型来估算推理能耗并实现为浏览器扩展。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速扩张带来了前所未有的能源需求，特别是在大规模推理工作负载方面，但系统性的推理能耗分析仍然有限。

Method: 使用vLLM推理引擎进行大规模测量研究，在21种GPU配置和155种模型架构上进行32,500多次测量，量化提示级别的能耗使用情况。

Result: 识别了架构和操作因素如何影响能源需求，开发了能够准确估算未见架构和硬件上推理能耗的预测模型。

Conclusion: 研究揭示了生成式AI的环境影响，并将预测模型实现为浏览器扩展以提高公众意识。

Abstract: The rapid expansion of Large Language Models (LLMs) has introduced unprecedented energy demands, extending beyond training to large-scale inference workloads that often dominate total lifecycle consumption. Deploying these models requires energy-intensive GPU infrastructure, and in some cases has even prompted plans to power data centers with nuclear energy. Despite this growing relevance, systematic analyses of inference energy consumption remain limited. In this work, we present a large-scale measurement-based study comprising over 32,500 measurements across 21 GPU configurations and 155 model architectures, from small open-source models to frontier systems. Using the vLLM inference engine, we quantify energy usage at the prompt level and identify how architectural and operational factors shape energy demand. Building on these insights, we develop a predictive model that accurately estimates inference energy consumption across unseen architectures and hardware, and implement it as a browser extension to raise awareness of the environmental impact of generative AI.

</details>


### [46] [CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer and Optimization](https://arxiv.org/abs/2511.05747)
*Ziqian Bi,Kaijie Chen,Tianyang Wang,Junfeng Hao,Xinyuan Song*

Main category: cs.AI

TL;DR: 提出自适应推理摘要框架，通过语义分割、重要性评分、预算感知动态压缩和连贯性重建来压缩推理轨迹，在保持关键推理步骤的同时显著减少token使用。在医疗考试问题上比截断方法准确率高40%，在64个模型对中验证了强跨模型可迁移性，并通过贝叶斯优化将评估成本降低84%。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought推理增强了大型语言模型的问题解决能力，但导致大量推理开销，限制了在资源受限环境中的部署。需要研究高效的CoT跨模型迁移方法。

Method: 自适应推理摘要框架，包括语义分割与重要性评分、预算感知动态压缩、连贯性重建，以及高斯过程贝叶斯优化模块。

Result: 在7,501个医疗考试问题上的实验显示，在相同token预算下比截断方法准确率高40%。在8个LLM的64个模型对中验证了强跨模型可迁移性。贝叶斯优化将评估成本降低84%，并揭示了模型大小与跨域鲁棒性之间的幂律关系。

Conclusion: 推理摘要为高效CoT迁移提供了实用路径，使在严格计算约束下实现高级推理成为可能。

Abstract: Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of large language models (LLMs) but leads to substantial inference overhead, limiting deployment in resource-constrained settings. This paper investigates efficient CoT transfer across models of different scales and architectures through an adaptive reasoning summarization framework. The proposed method compresses reasoning traces via semantic segmentation with importance scoring, budget-aware dynamic compression, and coherence reconstruction, preserving critical reasoning steps while significantly reducing token usage. Experiments on 7{,}501 medical examination questions across 10 specialties show up to 40% higher accuracy than truncation under the same token budgets. Evaluations on 64 model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian Process-based Bayesian optimization module reduces evaluation cost by 84% and reveals a power-law relationship between model size and cross-domain robustness. These results demonstrate that reasoning summarization provides a practical path toward efficient CoT transfer, enabling advanced reasoning under tight computational constraints. Code will be released upon publication.

</details>


### [47] [Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs](https://arxiv.org/abs/2511.05766)
*Felipe Valencia-Clavijo*

Main category: cs.AI

TL;DR: 本研究通过概率分析和归因方法系统研究了大语言模型中的锚定偏见，发现锚点会改变整个输出分布，并开发了统一的锚定偏见敏感度评分框架。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明大语言模型表现出锚定偏见，但大多数证据依赖于表面输出，内部机制和归因贡献仍未探索。本研究旨在深入理解LLM中锚定偏见的内部机制。

Method: 采用三种方法：(1)基于对数概率的行为分析，控制训练数据污染；(2)结构化提示字段的精确Shapley值归因；(3)统一的锚定偏见敏感度评分，整合行为和归因证据。

Result: 在Gemma-2B、Phi-2和Llama-2-7B中观察到稳健的锚定效应，归因显示锚点影响重新加权。较小模型如GPT-2、Falcon-RW-1B和GPT-Neo-125M表现出变异性，表明规模可能调节敏感性。

Conclusion: LLM中的锚定偏见是稳健、可测量和可解释的，但归因效应随提示设计变化，强调了将LLM视为人类替代品的脆弱性。该框架为评估LLM中其他认知偏见提供了可复现路径。

Abstract: Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs.

</details>


### [48] [Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection](https://arxiv.org/abs/2511.05854)
*Zepeng Bao,Shen Zhou,Qiankun Pi,Jianhao Chen,Mayi Xu,Ming Zhong,Yuanyuan Zhu,Tieyun Qian*

Main category: cs.AI

TL;DR: 本文提出了LEAP框架，通过动态策略学习和主动修正机制，赋予高效学生模型动态学习和主动修正能力，以解决LLM幻觉检测中固定策略缺乏适应性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强的幻觉检测方法需要预定义的固定验证策略，在面对动态变化的执行环境时缺乏适应性，可能导致检测失败。直接使用GPT-4等闭源大模型作为检测器成本过高，而教师-学生架构的方法又受限于固定策略。

Method: 提出LEAP框架，将幻觉检测问题建模为动态策略学习问题。首先使用教师模型在动态学习循环中生成轨迹并根据执行失败动态调整策略，然后通过智能体调优将这种动态规划能力蒸馏到高效学生模型中。学生在策略执行时采用主动修正机制，在执行前提出、审查和优化验证策略。

Result: 在三个具有挑战性的基准测试上的实验表明，LEAP调优的模型优于现有的最先进方法。

Conclusion: LEAP框架成功解决了幻觉检测中策略适应性问题，赋予学生模型动态学习和主动修正能力，在保持高效性的同时提升了检测性能。

Abstract: Hallucination in large language models (LLMs) remains a critical barrier to their safe deployment. Existing tool-augmented hallucination detection methods require pre-defined fixed verification strategies, which are crucial to the quality and effectiveness of tool calls. Some methods directly employ powerful closed-source LLMs such as GPT-4 as detectors, which are effective but too costly. To mitigate the cost issue, some methods adopt the teacher-student architecture and finetune open-source small models as detectors via agent tuning. However, these methods are limited by fixed strategies. When faced with a dynamically changing execution environment, they may lack adaptability and inappropriately call tools, ultimately leading to detection failure. To address the problem of insufficient strategy adaptability, we propose the innovative ``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an efficient student model with the dynamic learning and proactive correction capabilities of the teacher model. Specifically, our method formulates the hallucination detection problem as a dynamic strategy learning problem. We first employ a teacher model to generate trajectories within the dynamic learning loop and dynamically adjust the strategy based on execution failures. We then distill this dynamic planning capability into an efficient student model via agent tuning. Finally, during strategy execution, the student model adopts a proactive correction mechanism, enabling it to propose, review, and optimize its own verification strategies before execution. We demonstrate through experiments on three challenging benchmarks that our LEAP-tuned model outperforms existing state-of-the-art methods.

</details>


### [49] [An Empirical Study of Reasoning Steps in Thinking Code LLMs](https://arxiv.org/abs/2511.05874)
*Haoran Xue,Gias Uddin,Song Wang*

Main category: cs.AI

TL;DR: 本文对6种思考型大语言模型在代码生成任务中的推理过程和质量进行了实证研究，发现推理链质量与任务复杂度相关，完整性是主要失败模式，模型能在不同计算量下保持逻辑结构一致性并自我纠错。


<details>
  <summary>Details</summary>
Motivation: 虽然思考型LLMs在生成最终答案前会输出显式中间推理过程，可能提高代码生成的透明度和准确性，但这些推理链的质量尚未得到充分研究。

Method: 评估6种最先进的推理LLMs在100个不同难度代码生成任务上的表现，通过步骤计数和冗长度量化推理链结构，进行受控步骤预算调整，并组织21人参与的人类评估，从效率、逻辑正确性和完整性三个维度分析。

Result: 步骤干预显示针对性增加步骤可提高某些模型/任务的解决率，适度减少步骤在标准任务上通常能保持成功但在困难任务上很少。任务复杂度显著影响推理质量，困难问题比标准任务更容易出现不完整性。

Conclusion: 思考型LLMs在不同计算量水平下保持一致的逻辑结构并能自我纠正先前错误，本研究为当前思考型LLMs在软件工程中的优势和局限性提供了新见解。

Abstract: Thinking Large Language Models (LLMs) generate explicit intermediate reasoning traces before final answers, potentially improving transparency, interpretability, and solution accuracy for code generation. However, the quality of these reasoning chains remains underexplored. We present a comprehensive empirical study examining the reasoning process and quality of thinking LLMs for code generation. We evaluate six state-of-the-art reasoning LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code generation tasks of varying difficulty from BigCodeBench. We quantify reasoning-chain structure through step counts and verbosity, conduct controlled step-budget adjustments, and perform a 21-participant human evaluation across three dimensions: efficiency, logical correctness, and completeness. Our step-count interventions reveal that targeted step increases can improve resolution rates for certain models/tasks, while modest reductions often preserve success on standard tasks, rarely on hard ones. Through systematic analysis, we develop a reasoning-problematic taxonomy, identifying completeness as the dominant failure mode. Task complexity significantly impacts reasoning quality; hard problems are substantially more prone to incompleteness than standard tasks. Our stability analysis demonstrates that thinking LLMs maintain consistent logical structures across computational effort levels and can self-correct previous errors. This study provides new insights into the strengths and limitations of current thinking LLMs in software engineering.

</details>


### [50] [Unveiling Modality Bias: Automated Sample-Specific Analysis for Multimodal Misinformation Benchmarks](https://arxiv.org/abs/2511.05883)
*Hehai Lin,Hui Liu,Shilei Cao,Jing Li,Haoliang Li,Wenya Wang*

Main category: cs.AI

TL;DR: 本文提出了三种基于不同粒度理论的样本级模态偏差量化方法，并在两个流行基准上通过人工评估验证了有效性，发现了三个重要发现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态虚假信息基准存在对特定模态的偏差，使得检测器仅基于单一模态就能做出预测。之前的研究在数据集层面量化偏差或手动识别模态与标签之间的伪相关，但这些方法在样本层面缺乏有意义的洞察，难以扩展到海量在线信息。

Method: 提出了三种基于不同粒度理论的偏差量化方法：1）粗粒度的模态效益评估；2）中粒度的信息流量化；3）细粒度的因果分析。在两个流行基准上进行了人工评估验证。

Result: 实验揭示了三个重要发现：1）集成多个视图对于可靠的自动化分析至关重要；2）自动化分析容易受到检测器引起的波动影响；3）不同视图在模态平衡样本上产生更高的一致性，但在有偏差样本上出现分歧。

Conclusion: 本文的研究为样本级模态偏差的自动识别提供了设计思路，实验结果指出了未来研究的潜在方向，特别是集成多视图分析的重要性。

Abstract: Numerous multimodal misinformation benchmarks exhibit bias toward specific modalities, allowing detectors to make predictions based solely on one modality. While previous research has quantified bias at the dataset level or manually identified spurious correlations between modalities and labels, these approaches lack meaningful insights at the sample level and struggle to scale to the vast amount of online information. In this paper, we investigate the design for automated recognition of modality bias at the sample level. Specifically, we propose three bias quantification methods based on theories/views of different levels of granularity: 1) a coarse-grained evaluation of modality benefit; 2) a medium-grained quantification of information flow; and 3) a fine-grained causality analysis. To verify the effectiveness, we conduct a human evaluation on two popular benchmarks. Experimental results reveal three interesting findings that provide potential direction toward future research: 1)~Ensembling multiple views is crucial for reliable automated analysis; 2)~Automated analysis is prone to detector-induced fluctuations; and 3)~Different views produce a higher agreement on modality-balanced samples but diverge on biased ones.

</details>


### [51] [Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement](https://arxiv.org/abs/2511.05931)
*Hiroaki Hayashi,Bo Pang,Wenting Zhao,Ye Liu,Akash Gokul,Srijan Bansal,Caiming Xiong,Semih Yavuz,Yingbo Zhou*

Main category: cs.AI

TL;DR: SAGE框架让LLM智能体能够从自身任务执行中学习，通过自我抽象提炼关键步骤、依赖关系和约束，从而改进后续执行性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体通常在静态执行框架中运行，缺乏从自身经验和历史执行中学习改进的机制，导致性能受限于初始框架设计和基础LLM能力。

Method: 提出SAGE框架，智能体在初始执行后从实际经验中归纳出简洁的计划抽象，包括关键步骤、依赖关系和约束，然后将学习到的抽象作为上下文指导反馈给智能体，优化其策略并支持更结构化、信息化的后续执行。

Result: SAGE在不同LLM骨干和智能体架构上均带来一致性能提升，与GPT-5（高）骨干配对时相比Mini-SWE-Agent基线获得7.2%相对性能改进，在SWE-Bench Verified基准测试中分别达到73.2%和74%的Pass@1解决率。

Conclusion: SAGE框架通过自我抽象机制有效提升了LLM智能体的学习能力和执行性能，为软件工程任务中的多步推理和代码修改提供了更强大的解决方案。

Abstract: Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively.

</details>


### [52] [An Epistemic Perspective on Agent Awareness](https://arxiv.org/abs/2511.05977)
*Pavel Naumov,Alexandra Pavlova*

Main category: cs.AI

TL;DR: 该论文将智能体意识视为一种知识形式，打破了现有文献传统。它区分了这种知识的de re和de dicto形式，引入了两种模态来捕捉这些形式，并使用2D语义学版本正式指定其含义。主要技术结果是描述两种提议模态与标准"事实知识"模态之间相互作用的一个健全且完备的逻辑系统。


<details>
  <summary>Details</summary>
Motivation: 打破现有文献中将智能体意识视为传统知识的传统，提出将意识视为一种特殊的知识形式，并区分其de re和de dicto形式。

Method: 引入两种模态来捕捉de re和de dicto形式的意识知识，使用2D语义学版本正式指定这些模态的含义，构建描述这些模态与标准知识模态相互作用的逻辑系统。

Result: 开发了一个健全且完备的逻辑系统，能够描述两种提议的意识模态与标准"事实知识"模态之间的相互作用。

Conclusion: 通过将智能体意识形式化为特殊的知识形式，并区分其de re和de dicto变体，成功构建了一个能够捕捉意识知识本质及其与标准知识关系的逻辑框架。

Abstract: The paper proposes to treat agent awareness as a form of knowledge, breaking the tradition in the existing literature on awareness. It distinguishes the de re and de dicto forms of such knowledge. The work introduces two modalities capturing these forms and formally specifies their meaning using a version of 2D-semantics. The main technical result is a sound and complete logical system describing the interplay between the two proposed modalities and the standard "knowledge of the fact" modality.

</details>


### [53] [When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks](https://arxiv.org/abs/2511.06136)
*Stefano Ferraro,Akihiro Nakano,Masahiro Suzuki,Yutaka Matsuo*

Main category: cs.AI

TL;DR: DLPWM是一种无监督解耦的对象中心世界模型，在视觉重建和预测方面表现优异，但在下游控制任务中表现不如DreamerV3，主要原因是多对象交互时的表示漂移问题。


<details>
  <summary>Details</summary>
Motivation: 验证显式解耦的对象级表示能否通过定位任务相关信息来增强策略在新型特征组合上的性能。

Method: 引入DLPWM，一种完全无监督的解耦对象中心世界模型，直接从像素学习对象级潜在表示。

Result: DLPWM在重建和预测方面表现强劲，但对OOD视觉变化具有鲁棒性；在下游控制中，基于DLPWM潜在表示的策略训练效果不如DreamerV3；通过潜在轨迹分析发现多对象交互时的表示漂移是策略学习不稳定的关键原因。

Conclusion: 虽然对象中心感知支持鲁棒的视觉建模，但要实现稳定控制需要减轻潜在漂移问题。

Abstract: Object-centric world models (OCWM) aim to decompose visual scenes into object-level representations, providing structured abstractions that could improve compositional generalization and data efficiency in reinforcement learning. We hypothesize that explicitly disentangled object-level representations, by localizing task-relevant information, can enhance policy performance across novel feature combinations. To test this hypothesis, we introduce DLPWM, a fully unsupervised, disentangled object-centric world model that learns object-level latents directly from pixels. DLPWM achieves strong reconstruction and prediction performance, including robustness to several out-of-distribution (OOD) visual variations. However, when used for downstream model-based control, policies trained on DLPWM latents underperform compared to DreamerV3. Through latent-trajectory analyses, we identify representation shift during multi-object interactions as a key driver of unstable policy learning. Our results suggest that, although object-centric perception supports robust visual modeling, achieving stable control requires mitigating latent drift.

</details>


### [54] [Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles](https://arxiv.org/abs/2511.06160)
*Fatima Jahara,Mark Dredze,Sharon Levy*

Main category: cs.AI

TL;DR: PRIME是一个新的评估框架，使用逻辑网格谜题来系统性地探测LLMs在逻辑推理和决策中受社会刻板印象影响的程度。该框架通过自动生成和验证刻板印象、反刻板印象和中立谜题变体，实现对模型推理偏差的精细量化评估。


<details>
  <summary>Details</summary>
Motivation: 当前的安全防护措施能有效抑制明显的偏见输出，但在复杂逻辑推理任务中，更微妙的社会偏见形式会逃避现有评估基准。需要新的评估方法来填补这一空白。

Method: 使用逻辑网格谜题构建PRIME评估框架，包含刻板印象、反刻板印象和中立三种谜题变体，从共享的谜题结构中生成，允许受控和细粒度的比较。评估多个模型家族在不同谜题大小下的表现，并测试基于提示的缓解策略。

Result: 模型在解决方案符合刻板印象关联时推理准确率更高，这突显了PRIME在诊断和量化LLMs演绎推理中持续存在的社会偏见方面的重要性。

Conclusion: PRIME框架对于在公平性至关重要的场景中，诊断和量化LLMs演绎推理中持续存在的社会偏见具有重要意义。

Abstract: While recent safety guardrails effectively suppress overtly biased outputs, subtler forms of social bias emerge during complex logical reasoning tasks that evade current evaluation benchmarks. To fill this gap, we introduce a new evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model Evaluation), that uses logic grid puzzles to systematically probe the influence of social stereotypes on logical reasoning and decision making in LLMs. Our use of logic puzzles enables automatic generation and verification, as well as variability in complexity and biased settings. PRIME includes stereotypical, anti-stereotypical, and neutral puzzle variants generated from a shared puzzle structure, allowing for controlled and fine-grained comparisons. We evaluate multiple model families across puzzle sizes and test the effectiveness of prompt-based mitigation strategies. Focusing our experiments on gender stereotypes, our findings highlight that models consistently reason more accurately when solutions align with stereotypical associations. This demonstrates the significance of PRIME for diagnosing and quantifying social biases perpetuated in the deductive reasoning of LLMs, where fairness is critical.

</details>


### [55] [Chasing Consistency: Quantifying and Optimizing Human-Model Alignment in Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.06168)
*Boxuan Wang,Zhuoyun Li,Xinmiao Huang,Xiaowei Huang,Yi Dong*

Main category: cs.AI

TL;DR: 本文提出了一个评估和优化大语言模型推理一致性的框架，通过新的对齐分数指标量化模型生成推理链与人类参考链的语义对齐程度。研究发现2跳推理链对齐分数最高，定义了四种关键错误类型来解释这一现象，并提出了语义一致性优化采样方法显著提升对齐分数。


<details>
  <summary>Details</summary>
Motivation: 评估和优化大语言模型在链式思维推理中的一致性，解决模型生成推理链与人类参考链之间的语义对齐问题。

Method: 提出对齐分数指标量化语义对齐，定义四种错误类型（逻辑断开、主题偏移、冗余推理、因果反转），并开发语义一致性优化采样方法选择对齐错误最少的推理链。

Result: 实证发现2跳推理链对齐分数最高，语义一致性优化采样方法平均提升对齐分数29.84%，在3跳任务等较长推理链中效果显著。

Conclusion: 该框架有效评估和优化大语言模型的推理一致性，语义一致性优化采样方法能显著提升模型生成推理链与人类参考链的语义对齐质量。

Abstract: This paper presents a framework for evaluating and optimizing reasoning consistency in Large Language Models (LLMs) via a new metric, the Alignment Score, which quantifies the semantic alignment between model-generated reasoning chains and human-written reference chains in Chain-of-Thought (CoT) reasoning. Empirically, we find that 2-hop reasoning chains achieve the highest Alignment Score. To explain this phenomenon, we define four key error types: logical disconnection, thematic shift, redundant reasoning, and causal reversal, and show how each contributes to the degradation of the Alignment Score. Building on this analysis, we further propose Semantic Consistency Optimization Sampling (SCOS), a method that samples and favors chains with minimal alignment errors, significantly improving Alignment Scores by an average of 29.84% with longer reasoning chains, such as in 3-hop tasks.

</details>


### [56] [CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference](https://arxiv.org/abs/2511.06175)
*Kaijie Xu,Fandi Meng,Clark Verbrugge,Simon Lucas*

Main category: cs.AI

TL;DR: CSP4SDG是一个用于社交推理游戏的约束满足框架，通过概率推理和信息论方法进行角色推断，优于LLM基准模型，并能作为推理工具增强LLM性能。


<details>
  <summary>Details</summary>
Motivation: 社交推理游戏中玩家隐藏身份并故意误导他人，准确的角色识别是游戏表现的关键，但现有方法存在局限性。

Method: 提出CSP4SDG框架，将游戏事件和对话映射到四个约束类别：证据、现象、断言和假设。硬约束修剪不可能的角色分配，加权软约束对剩余分配评分，信息增益权重将每个假设与其在熵减少下的期望值联系起来。

Result: 在三个公共数据集上的实验表明，CSP4SDG在所有推理场景中都优于基于LLM的基准模型，并且当作为辅助"推理工具"提供时能提升LLM性能。

Conclusion: 基于信息论的原则性概率推理是用于社交推理游戏的重型神经模型的可扩展替代或补充方案。

Abstract: In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary "reasoning tool." Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.

</details>


### [57] [Dataforge: A Data Agent Platform for Autonomous Data Engineering](https://arxiv.org/abs/2511.06185)
*Xinyuan Wang,Yanjie Fu*

Main category: cs.AI

TL;DR: Data Agent是一个完全自主的表格数据处理系统，利用LLM推理和验证机制自动执行数据清洗、分层路由和特征级优化，实现从原始数据到AI就绪数据的端到端自动化处理。


<details>
  <summary>Details</summary>
Motivation: AI应用在材料发现、分子建模和气候科学等领域的需求增长，使数据准备成为重要但劳动密集的步骤。原始数据需要清洗、归一化和转换才能用于AI，而有效的特征转换和选择对高效训练和推理至关重要。

Method: 利用大型语言模型推理和基础验证，通过双反馈循环自动执行数据清洗、分层路由和特征级优化。系统基于三个核心原则：自动化、安全性和非专家友好性。

Result: 展示了首个实用的自主Data Agent实现，能够将原始数据转化为更好的数据，确保端到端可靠性而无需人工监督。

Conclusion: Data Agent系统成功解决了数据准备的可扩展性和专业知识依赖问题，为AI应用提供了完全自主的数据处理解决方案。

Abstract: The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed "From Data to Better Data."

</details>


### [58] [Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads](https://arxiv.org/abs/2511.06209)
*Jingwei Ni,Ekaterina Fadeeva,Tianyi Wu,Mubashara Akhtar,Jiaheng Zhang,Elliott Ash,Markus Leippold,Timothy Baldwin,See-Kiong Ng,Artem Shelmanov,Mrinmaya Sachan*

Main category: cs.AI

TL;DR: 提出了一种基于数据驱动不确定性分数的轻量级推理步骤验证方法，使用transformer不确定性量化头来估计LLM推理步骤的不确定性，无需大规模人工标注，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有推理验证方法如过程奖励模型计算成本高、领域受限或需要大规模标注，需要更轻量、通用的验证方案。

Method: 训练基于transformer的不确定性量化头，利用冻结LLM的内部状态来估计推理步骤的不确定性，标签由更大LLM或自监督方式自动生成。

Result: 在数学、规划和常识问答等多个领域，UHeads性能匹配甚至超越比其大810倍的过程奖励模型，参数少于1000万。

Conclusion: LLM内部状态编码了其不确定性，可作为推理验证的可靠信号，为可扩展和泛化的自省LLM提供了有前景的方向。

Abstract: Solving complex tasks usually requires LLMs to generate long multi-step reasoning chains. Previous work has shown that verifying the correctness of individual reasoning steps can further improve the performance and efficiency of LLMs on such tasks and enhance solution interpretability. However, existing verification approaches, such as Process Reward Models (PRMs), are either computationally expensive, limited to specific domains, or require large-scale human or model-generated annotations. Thus, we propose a lightweight alternative for step-level reasoning verification based on data-driven uncertainty scores. We train transformer-based uncertainty quantification heads (UHeads) that use the internal states of a frozen LLM to estimate the uncertainty of its reasoning steps during generation. The approach is fully automatic: target labels are generated either by another larger LLM (e.g., DeepSeek R1) or in a self-supervised manner by the original model itself. UHeads are both effective and lightweight, containing less than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, they match or even surpass the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their uncertainty and can serve as reliable signals for reasoning verification, offering a promising direction toward scalable and generalizable introspective LLMs.

</details>


### [59] [Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B](https://arxiv.org/abs/2511.06221)
*Sen Xu,Yi Zhou,Wei Wang,Jixin Min,Zhibin Yin,Yingwei Dai,Shixi Liu,Lianyu Pang,Yirong Chen,Junlin Zhang*

Main category: cs.AI

TL;DR: VibeThinker-1.5B是一个仅1.5B参数的密集模型，通过Spectrum-to-Signal Principle (SSP)框架开发，挑战了通过扩大模型参数来提升能力的传统方法。该模型在仅7800美元的训练成本下，在数学推理基准上超越了DeepSeek R1等大型模型，证明了小模型也能具备强大的推理能力。


<details>
  <summary>Details</summary>
Motivation: 挑战当前共识，即小模型天生缺乏强大的推理能力，探索通过更高效的训练方法而非单纯扩大参数规模来提升模型能力。

Method: 采用Spectrum-to-Signal Principle (SSP)框架：1）Two-Stage Diversity-Exploring Distillation (SFT)生成广泛解决方案谱；2）MaxEnt-Guided Policy Optimization (RL)放大正确信号。

Result: 在AIME24、AIME25和HMMT25三个数学基准上分别获得80.3、74.4和50.4分，超越了400倍大的DeepSeek R1模型（79.8、70.0、41.7）。在LiveCodeBench V6上获得51.1分，优于Magistral Medium的50.3分。

Conclusion: 小模型能够达到与大模型相当的推理能力，大幅降低训练和推理成本，从而民主化先进AI研究。

Abstract: Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research.

</details>


### [60] [ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving](https://arxiv.org/abs/2511.06226)
*Xingcheng Liu,Yanchen Guan,Haicheng Liao,Zhengbing He,Zhenning Li*

Main category: cs.AI

TL;DR: 本文提出ROAR方法，通过结合离散小波变换、自适应目标感知模块和动态焦点损失，在噪声和不完整数据条件下提升事故预测准确性，并在三个数据集上优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有事故预测方法假设理想条件，忽略了传感器故障、环境干扰和数据缺陷等现实挑战，且未充分考虑不同车型间驾驶员行为和事故率的显著差异。

Method: ROAR方法结合离散小波变换(DWT)从噪声和不完整数据中提取特征，使用自适应目标感知模块关注高风险车辆并建模交通参与者间的时空关系，采用动态焦点损失缓解正负样本类别不平衡问题。

Result: 在Dashcam Accident Dataset(DAD)、Car Crash Dataset(CCD)和AnAn Accident Detection(A3D)三个数据集上的评估显示，ROAR在平均精度(AP)和平均事故时间(mTTA)等关键指标上持续优于现有基线方法。

Conclusion: ROAR在复杂交通环境中提供了可靠准确的事故预测解决方案，特别是在处理传感器退化、环境噪声和不平衡数据分布方面表现出鲁棒性。

Abstract: Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments.

</details>


### [61] [Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents](https://arxiv.org/abs/2511.06292)
*Yaoning Yu,Kaimin Chang,Ye Yu,Kai Wei,Haojing Luo,Haohan Wang*

Main category: cs.AI

TL;DR: 提出了一种基于数据增强优化的自改进提示框架，通过生成合成财务表格和文档片段、验证其正确性和鲁棒性，然后根据结果更新提示，在无需外部标签的情况下持续提升金融推理任务的提示准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在固定数据集上调整提示，限制了适应新问题类型或文档结构的能力，或者需要昂贵的手动标注数据集来构建提示。

Method: 结合合成数据生成器、验证器和提示优化器的闭环框架，生成器产生暴露当前提示弱点的示例，验证器检查生成示例的有效性和鲁棒性，优化器根据结果逐步优化提示。

Result: 在DocMath-Eval基准测试中，该系统在准确性和鲁棒性方面均优于标准提示方法。

Conclusion: 将合成数据生成融入提示学习对金融应用具有重要价值，能够在不依赖外部标签的情况下持续改进提示性能。

Abstract: Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications.

</details>


### [62] [The Station: An Open-World Environment for AI-Driven Discovery](https://arxiv.org/abs/2511.06309)
*Stephen Chung,Wenyu Du*

Main category: cs.AI

TL;DR: STATION是一个开放世界的多智能体环境，模拟微型科学生态系统，智能体可以进行长期科学研究活动，包括阅读论文、提出假设、提交代码、执行分析和发表结果，无需中央协调系统。


<details>
  <summary>Details</summary>
Motivation: 创建自主科学发现的新范式，通过开放世界环境中的涌现行为推动科学研究，超越传统的刚性优化方法。

Method: 利用扩展上下文窗口，智能体在STATION环境中自由选择行动，进行长期科学探索，包括阅读同行论文、制定假设、编码、分析和发表成果。

Result: 实验显示STATION中的AI智能体在数学、计算生物学和机器学习等广泛基准测试中达到新的最先进性能，特别是在圆包装问题上超越AlphaEvolve，并涌现出新的方法如scRNA-seq批量整合的密度自适应算法。

Conclusion: STATION代表了通过开放世界环境中涌现行为驱动自主科学发现的第一步，展示了一种超越刚性优化的新研究范式。

Abstract: We introduce the STATION, an open-world multi-agent environment that models a miniature scientific ecosystem. Leveraging their extended context windows, agents in the Station can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, submitting code, performing analyses, and publishing results. Importantly, there is no centralized system coordinating their activities - agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning from mathematics to computational biology to machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of narratives emerges as agents pursue independent research, interact with peers, and build upon a cumulative history. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid optimization.

</details>


### [63] [ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning](https://arxiv.org/abs/2511.06316)
*MD Thamed Bin Zaman Chowdhury,Moazzem Hossain*

Main category: cs.AI

TL;DR: ALIGN是一个视觉语言框架，通过模拟人类空间推理直接从文本和地图线索推断交通事故坐标，解决了多语言和非结构化新闻环境中地理编码的挑战。


<details>
  <summary>Details</summary>
Motivation: 低收入和中等收入国家缺乏准确的位置特定交通事故数据，现有基于文本的地理编码工具在多语言和非结构化新闻环境中表现不佳，不完整的地点描述和混合的孟加拉语-英语脚本模糊了空间背景。

Method: ALIGN将大型语言和视觉语言模型集成到多阶段管道中，执行光学字符识别、语言推理和基于网格的空间扫描进行地图级验证，系统评估每个预测位置与上下文和视觉证据的一致性。

Result: 应用于孟加拉语新闻数据时，ALIGN相比传统地理解析方法表现出持续改进，准确识别了地区和分区级别的碰撞地点。

Conclusion: 该框架为数据稀缺地区的自动碰撞映射建立了高精度基础，支持基于证据的道路安全政策制定，并促进了多模态人工智能在交通分析中的更广泛集成。

Abstract: Reliable geospatial information on road accidents is vital for safety analysis and infrastructure planning, yet most low- and middle-income countries continue to face a critical shortage of accurate, location-specific crash data. Existing text-based geocoding tools perform poorly in multilingual and unstructured news environments, where incomplete place descriptions and mixed Bangla-English scripts obscure spatial context. To address these limitations, this study introduces ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning)- a vision-language framework that emulates human spatial reasoning to infer accident coordinates directly from textual and map-based cues. ALIGN integrates large language and vision-language models within a multi-stage pipeline that performs optical character recognition, linguistic reasoning, and map-level verification through grid-based spatial scanning. The framework systematically evaluates each predicted location against contextual and visual evidence, ensuring interpretable, fine-grained geolocation outcomes without requiring model retraining. Applied to Bangla-language news data, ALIGN demonstrates consistent improvements over traditional geoparsing methods, accurately identifying district and sub-district-level crash sites. Beyond its technical contribution, the framework establishes a high accuracy foundation for automated crash mapping in data-scarce regions, supporting evidence-driven road-safety policymaking and the broader integration of multimodal artificial intelligence in transportation analytics. The code for this paper is open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN

</details>


### [64] [LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation](https://arxiv.org/abs/2511.06346)
*Liya Zhu,Peizhuang Cong,Aowei Ji,Wenya Wu,Jiani Hou,Chunjie Wu,Xiang Gao,Jingkai Liu,Zhou Huan,Xuelei Sun,Yang Yang,Jianpeng Jiao,Liang Hu,Xinjie Chen,Jiashuo Liu,Jingzhe Ding,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang*

Main category: cs.AI

TL;DR: 提出了LPFQA基准，基于20个学术和工业领域的专业论坛构建，包含502个任务，专注于长尾知识和真实专业场景的评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准数据集过于简化，忽视了长尾知识和真实应用的复杂性，难以准确评估LLMs的真实能力。

Method: 从真实专业论坛收集数据，构建包含502个任务的基准，采用细粒度评估维度（知识深度、推理、术语理解、上下文分析），分层难度结构，真实用户角色建模，以及跨学科知识整合。

Result: 评估了12个主流LLM，发现在专业推理任务中存在显著性能差异。

Conclusion: LPFQA为LLM评估提供了稳健、真实和具有区分度的基准，有助于指导未来模型开发。

Abstract: Large Language Models (LLMs) have made rapid progress in reasoning, question answering, and professional applications; however, their true capabilities remain difficult to evaluate using existing benchmarks. Current datasets often focus on simplified tasks or artificial scenarios, overlooking long-tail knowledge and the complexities of real-world applications. To bridge this gap, we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic professional forums across 20 academic and industrial fields, covering 502 tasks grounded in practical expertise. LPFQA introduces four key innovations: fine-grained evaluation dimensions that target knowledge depth, reasoning, terminology comprehension, and contextual analysis; a hierarchical difficulty structure that ensures semantic clarity and unique answers; authentic professional scenario modeling with realistic user personas; and interdisciplinary knowledge integration across diverse domains. We evaluated 12 mainstream LLMs on LPFQA and observed significant performance disparities, especially in specialized reasoning tasks. LPFQA provides a robust, authentic, and discriminative benchmark for advancing LLM evaluation and guiding future model development.

</details>


### [65] [What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models](https://arxiv.org/abs/2511.06380)
*Chen He,Xun Jiang,Lei Wang,Hao Yang,Chong Peng,Peng Yan,Fumin Shen,Xing Xu*

Main category: cs.AI

TL;DR: 论文发现LLMs在复杂领域推理中存在"回响反思"问题，即反思阶段机械重复早期推理而非产生新见解，并提出AEPO强化学习方法来解决信息流控制和知识探索不足的问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在数学推理中表现优异，但在涉及复杂领域知识的任务中，反思阶段无法产生新颖见解，而是机械重复早期推理步骤，这种现象被称为"回响反思"。

Method: 提出AEPO强化学习方法，包含两个主要组件：反思感知信息过滤（量化认知信息流，防止早期错误认知影响最终答案）和自适应熵优化（动态平衡不同推理阶段的探索与利用）。

Result: 大量实验表明，AEPO在多样化基准测试中始终优于主流强化学习基线方法，达到最先进的性能。

Conclusion: AEPO方法有效解决了LLMs在复杂领域推理中的回响反思问题，通过控制信息流和促进知识探索，显著提升了模型的反思能力和推理性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as "Echo Reflection". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks.

</details>


### [66] [SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization](https://arxiv.org/abs/2511.06411)
*Zhi Zheng,Wee Sun Lee*

Main category: cs.AI

TL;DR: 本文提出了SofT-GRPO算法，通过将Gumbel噪声注入logits、使用Gumbel-Softmax技术和重参数化技巧，成功将强化学习应用于软思维推理模式，使LLM在软思维模式下性能优于离散token的GRPO。


<details>
  <summary>Details</summary>
Motivation: 软思维推理模式在某些场景下优于传统的离散token链式思维推理，但将强化学习应用于软思维模式存在挑战，因为难以在软思维token中注入随机性并相应更新策略。

Method: 提出SofT-GRPO算法：注入Gumbel噪声到logits，使用Gumbel-Softmax避免软思维token超出预训练嵌入空间，在策略梯度中利用重参数化技巧。

Result: 在1.5B到7B参数的LLM上进行实验，SofT-GRPO使软思维LLM在Pass@1上略优于离散token GRPO（平均准确率+0.13%），在Pass@32上显著提升（平均准确率+2.19%）。

Conclusion: SofT-GRPO成功解决了将强化学习应用于软思维推理的挑战，完全释放了软思维模式的潜力，为LLM推理提供了新的优化方法。

Abstract: The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master

</details>


### [67] [FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis](https://arxiv.org/abs/2511.06522)
*Jan Ondras,Marek Šuppa*

Main category: cs.AI

TL;DR: FractalBench是一个评估从图像合成分形程序能力的基准测试，测试多模态AI系统是否能从有限视觉模式中抽象出无限数学规则。


<details>
  <summary>Details</summary>
Motivation: 研究多模态AI系统是否具备从视觉模式中抽象符号规则的能力，即从有限推断无限的能力。

Method: 使用FractalBench基准测试，评估4个领先的MLLM模型在12个经典分形上的表现，要求模型生成可执行的Python代码来重现分形。

Result: 76%的模型能生成语法有效的代码，但只有4%能捕捉数学结构。模型在几何变换（科赫曲线：17-21%）上表现较好，但在分支递归（树形分形：<2%）上失败。

Conclusion: 多模态AI系统在数学抽象方面存在根本性差距，FractalBench提供了一个抗污染的诊断工具来评估视觉-数学推理能力。

Abstract: Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench

</details>


### [68] [GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization](https://arxiv.org/abs/2511.06618)
*Moriya Dechtiar,Daniel Martin Katz,Mari Sundaresan,Sylvain Jaume,Hongming Wang*

Main category: cs.AI

TL;DR: 本文提出了一种将法律合同转化为结构化语义图的新框架，使用基于强化学习的大语言模型自动提取合同中的实体和关系，实现合同审查和分析的自动化。


<details>
  <summary>Details</summary>
Motivation: 合同是复杂的文档，具有详细的形式结构、显性和隐性依赖关系以及丰富的语义内容。合同起草和人工审查既费力又容易出错，因此需要简化和自动化合同审查任务。

Method: 引入详细的ontology将核心法律合同元素映射到图的节点和边，提出基于强化学习的LLM框架GRAPH-GRPO-LEX，结合大语言模型和分组相对策略优化(GRPO)进行实体和关系提取，采用精心设计的图度量奖励函数。

Result: 能够自动识别条款间的直接关系，甚至发现隐藏的依赖关系，门控GRPO方法显示出强大的学习信号，将合同分析从线性手动阅读过程转变为易于可视化的图。

Conclusion: 该方法为合同分析提供了更动态的方法，为类似软件工程中实践的合同检查奠定了基础，实现了合同审查的自动化和可视化。

Abstract: Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering.

</details>


### [69] [MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning](https://arxiv.org/abs/2511.06805)
*Jinhao Chen,Zhen Yang,Jianxin Shi,Tianyu Wo,Jie Tang*

Main category: cs.AI

TL;DR: 本文提出了一种数学自我进化框架MathSE，通过迭代推理、反思和基于奖励的反馈来增强多模态大语言模型在数学推理任务中的能力，超越了传统一次性微调方法的限制。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在复杂数学推理任务中存在困难，传统方法依赖于从教师模型直接提取的静态数据集，这些数据集无法适应新颖或更复杂的问题，且缺乏迭代深度以实现稳健的泛化。

Method: 提出MathSE框架，通过迭代微调结合先前阶段推理得出的正确推理路径，并整合来自专门结果奖励模型的反思反馈，实现模型的持续进化。

Result: 在多个具有挑战性的基准测试中验证了MathSE的有效性，实验结果显示在MathVL-test上超越了领先的开源多模态数学推理模型QVQ。

Conclusion: MathSE框架通过迭代推理、反思和奖励反馈机制，显著提升了多模态大语言模型的数学推理能力，为解决复杂数学问题提供了更有效的解决方案。

Abstract: Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \textbf{\method}, a \textbf{Math}ematical \textbf{S}elf-\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \texttt{https://zheny2751\allowbreak-dotcom.github.io/\allowbreak MathSE.github.io/}.

</details>


### [70] [Proceedings of the 2025 XCSP3 Competition](https://arxiv.org/abs/2511.06918)
*Gilles Audemard,Christophe Lecoutre,Emmanuel Lonca*

Main category: cs.AI

TL;DR: 2025年XCSP3约束求解器竞赛论文集，包含在CP'25会议上展示的竞赛结果


<details>
  <summary>Details</summary>
Motivation: 组织约束求解器竞赛以推动约束编程领域的发展，评估和比较不同求解器的性能

Method: 通过XCSP3竞赛平台组织约束求解器比赛，在CP'25国际会议上展示结果

Result: 记录了2025年XCSP3竞赛的完整结果和排名

Conclusion: 该论文集总结了2025年约束求解器竞赛的重要成果，为约束编程社区提供了有价值的参考

Abstract: This document represents the proceedings of the 2025 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'25 (31st International Conference on Principles and Practice of Constraint Programming).

</details>


### [71] [Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning](https://arxiv.org/abs/2511.07061)
*Xinran Li,Xiujuan Xu,Jiaqi Qiao,Yu Liu*

Main category: cs.AI

TL;DR: PRC-Emo是一个创新的对话情感识别框架，结合提示工程、演示检索和课程学习，旨在提升大语言模型在对话中感知显性和隐性情感的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在对话情感识别领域展现出潜力，但其捕捉显性和隐性情感内在联系的能力仍然有限，需要更有效的方法来理解说话者的心理状态。

Method: 设计了基于显性和隐性情感线索的情感敏感提示模板；构建了首个专门的ERC演示检索库，包含训练样本和LLM生成的高质量对话示例；在LoRA微调过程中引入课程学习策略，根据同说话者和不同说话者话语间的加权情感变化分配难度级别。

Result: 在IEMOCAP和MELD两个基准数据集上的实验结果表明，该方法达到了新的最先进性能，证明了该方法在提升基于LLM的情感理解方面的有效性和泛化能力。

Conclusion: PRC-Emo框架通过整合提示工程、演示检索和课程学习，显著提升了大语言模型在对话情感识别任务中的表现，为改进基于LLM的情感理解提供了有效方法。

Abstract: Emotion Recognition in Conversation (ERC) is a crucial task for understanding human emotions and enabling natural human-computer interaction. Although Large Language Models (LLMs) have recently shown great potential in this field, their ability to capture the intrinsic connections between explicit and implicit emotions remains limited. We propose a novel ERC training framework, PRC-Emo, which integrates Prompt engineering, demonstration Retrieval, and Curriculum learning, with the goal of exploring whether LLMs can effectively perceive emotions in conversational contexts. Specifically, we design emotion-sensitive prompt templates based on both explicit and implicit emotional cues to better guide the model in understanding the speaker's psychological states. We construct the first dedicated demonstration retrieval repository for ERC, which includes training samples from widely used datasets, as well as high-quality dialogue examples generated by LLMs and manually verified. Moreover, we introduce a curriculum learning strategy into the LoRA fine-tuning process, incorporating weighted emotional shifts between same-speaker and different-speaker utterances to assign difficulty levels to dialogue samples, which are then organized in an easy-to-hard training sequence. Experimental results on two benchmark datasets -- IEMOCAP and MELD -- show that our method achieves new state-of-the-art (SOTA) performance, demonstrating the effectiveness and generalizability of our approach in improving LLM-based emotional understanding.

</details>


### [72] [Increasing AI Explainability by LLM Driven Standard Processes](https://arxiv.org/abs/2511.07083)
*Marc Jansen,Marcel Pehlke*

Main category: cs.AI

TL;DR: 提出了一种通过将大语言模型嵌入标准化分析流程来增强AI系统可解释性的方法，将LLM推理转化为透明可审计的决策轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统可解释AI方法主要关注特征归因或事后解释，需要将LLM的不透明推理转化为透明可审计的决策过程。

Method: 将LLM嵌入定义好的决策模型（如QOC、敏感性分析、博弈论和风险管理），采用分层架构分离LLM推理空间和可解释过程空间。

Result: 实证评估显示系统能够在去中心化治理、系统分析和战略推理场景中复现人类水平的决策逻辑。

Conclusion: LLM驱动的标准流程为可靠、可解释和可验证的AI支持决策提供了基础。

Abstract: This paper introduces an approach to increasing the explainability of artificial intelligence (AI) systems by embedding Large Language Models (LLMs) within standardized analytical processes. While traditional explainable AI (XAI) methods focus on feature attribution or post-hoc interpretation, the proposed framework integrates LLMs into defined decision models such as Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk Management. By situating LLM reasoning within these formal structures, the approach transforms opaque inference into transparent and auditable decision traces. A layered architecture is presented that separates the reasoning space of the LLM from the explainable process space above it. Empirical evaluations show that the system can reproduce human-level decision logic in decentralized governance, systems analysis, and strategic reasoning contexts. The results suggest that LLM-driven standard processes provide a foundation for reliable, interpretable, and verifiable AI-supported decision making.

</details>


### [73] [Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts](https://arxiv.org/abs/2511.07090)
*Marcel Rojahn,Marcus Grum*

Main category: cs.AI

TL;DR: 本文提出了绿色AI的统一操作定义，建立了五阶段生命周期评估框架，涵盖能源、碳、水等环境影响，并制定了硬件策略和校准测量方法，为研究人员、从业者和政策制定者提供可操作的指导。


<details>
  <summary>Details</summary>
Motivation: 当前AI生命周期中的环境负担（能源、碳、水等）缺乏统一透明的评估标准，云提供商工具存在异构性且往往忽略水足迹和价值链影响，限制了可比性和可重复性。

Method: 建立绿色AI的统一定义，制定五阶段生命周期映射到LCA阶段，通过PDCA循环进行治理，系统化硬件和系统级策略，定义结合估计模型和直接计量的校准测量框架。

Result: 提出了一个综合性的绿色AI框架，包括定义、生命周期流程、硬件策略和校准测量，能够实现可重复、提供商无关的比较。

Conclusion: 通过结合定义、生命周期流程、硬件策略和校准测量，本文为减少AI环境负担提供了可操作、基于证据的指导，支持研究人员、从业者和政策制定者实现绿色AI目标。

Abstract: Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water, and embodied impacts first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles with decision gateways; (iv) systematizes hardware and system level strategies across the edge cloud continuum to reduce embodied burdens; and (v) defines a calibrated measurement framework combining estimator models with direct metering to enable reproducible, provider agnostic comparisons. Combining definition, lifecycle processes, hardware strategies, and calibrated measurement, this article offers actionable, evidence based guidance for researchers, practitioners, and policymakers.

</details>


### [74] [Data Complexity of Querying Description Logic Knowledge Bases under Cost-Based Semantics](https://arxiv.org/abs/2511.07095)
*Meghyn Bienvenu,Quentin Manière*

Main category: cs.AI

TL;DR: 本文研究了不一致加权描述逻辑知识库在基于成本语义下的数据复杂性，重点关注包含逆角色和角色包含的DL-Lite方言，改进了现有下界并确定了最优成本确定答案语义的精确复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注EL⊥到ALCO之间的描述逻辑，而本文旨在扩展研究范围，涵盖包含逆角色和角色包含的DL-Lite方言，以提供更全面的数据复杂性分析。

Method: 通过为每个解释分配基于违反公理和断言权重的成本，考虑所有（或某些）具有最优或有界成本的解释来确定确定和可能查询答案。

Result: 改进了多个下界，确定了最优成本确定答案语义的精确复杂度；对于DL-Lite^H_bool本体和固定成本边界，实例查询的确定答案和联合查询的可能答案可通过一阶重写计算，达到最低数据复杂度TC0。

Conclusion: 本文显著扩展了基于成本语义的数据复杂性分析范围，首次为DL-Lite^H_bool提供了高效计算的可能性，突破了现有关于基于成本语义不可处理性的结论。

Abstract: In this paper, we study the data complexity of querying inconsistent weighted description logic (DL) knowledge bases under recently-introduced cost-based semantics. In a nutshell, the idea is to assign each interpretation a cost based upon the weights of the violated axioms and assertions, and certain and possible query answers are determined by considering all (resp. some) interpretations having optimal or bounded cost. Whereas the initial study of cost-based semantics focused on DLs between $\mathcal{EL}_\bot$ and $\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role inclusions, thus covering prominent DL-Lite dialects. Our data complexity analysis goes significantly beyond existing results by sharpening several lower bounds and pinpointing the precise complexity of optimal-cost certain answer semantics (no non-trivial upper bound was known). Moreover, while all existing results show the intractability of cost-based semantics, our most challenging and surprising result establishes that if we consider $\text{DL-Lite}^\mathcal{H}_\mathsf{bool}$ ontologies and a fixed cost bound, certain answers for instance queries and possible answers for conjunctive queries can be computed using first-order rewriting and thus enjoy the lowest possible data complexity ($\mathsf{TC}_0$).

</details>


### [75] [Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization](https://arxiv.org/abs/2511.07098)
*Yuanshao Zhu,Xiangyu Zhao,Zijian Zhang,Xuetao Wei,James Jianqiao Yu*

Main category: cs.AI

TL;DR: 提出了PLGF模型，通过渐进式局部-全局融合策略和DualFocal损失函数，在细粒度城市流量推断任务中实现了高精度和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临两个关键挑战：过参数化模型的高计算成本和传统损失函数在城市流量高度偏斜分布上的次优性能。

Method: 采用渐进式局部-全局融合策略（PLGF）构建轻量级架构，并设计DualFocal损失函数，结合双空间监督和难度感知聚焦机制。

Result: 在4个真实场景实验中，PLGF在达到最先进性能的同时，模型尺寸比当前高性能方法减少高达97%；在可比参数预算下，准确率比强基线提高超过10%。

Conclusion: 该方法有效解决了细粒度城市流量推断中的计算效率和性能优化问题，为城市规划和智能交通系统提供了实用解决方案。

Abstract: Fine-grained urban flow inference is crucial for urban planning and intelligent transportation systems, enabling precise traffic management and resource allocation. However, the practical deployment of existing methods is hindered by two key challenges: the prohibitive computational cost of over-parameterized models and the suboptimal performance of conventional loss functions on the highly skewed distribution of urban flows. To address these challenges, we propose a unified solution that synergizes architectural efficiency with adaptive optimization. Specifically, we first introduce PLGF, a lightweight yet powerful architecture that employs a Progressive Local-Global Fusion strategy to effectively capture both fine-grained details and global contextual dependencies. Second, we propose DualFocal Loss, a novel function that integrates dual-space supervision with a difficulty-aware focusing mechanism, enabling the model to adaptively concentrate on hard-to-predict regions. Extensive experiments on 4 real-world scenarios validate the effectiveness and scalability of our method. Notably, while achieving state-of-the-art performance, PLGF reduces the model size by up to 97% compared to current high-performing methods. Furthermore, under comparable parameter budgets, our model yields an accuracy improvement of over 10% against strong baselines. The implementation is included in the https://github.com/Yasoz/PLGF.

</details>


### [76] [Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture](https://arxiv.org/abs/2511.07110)
*Tianhao Fu,Xinxin Xu,Weichen Xu,Jue Chen,Ruilong Ren,Bowen Deng,Xinyu Zhao,Jian Cao,Xixin Cao*

Main category: cs.AI

TL;DR: 本文提出了一种用于市场做市任务的新型LLM知识蒸馏框架CMM，通过将LLM特征在层、任务和数据三个正交维度上进行解耦，让多个学生模型协作学习不同的LLM特征，并使用Hájek-MoE集成方法，在真实市场数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM直接应用于市场做市任务虽然表现良好，但推理速度慢，且缺乏针对该特定任务的LLM蒸馏研究，需要解决这一瓶颈问题。

Method: 提出CMM框架：1）使用归一化荧光探针研究LLM特征机制；2）在层、任务、数据三个维度解耦LLM特征；3）多个学生模型协作学习不同维度的简单LLM特征；4）引入Hájek-MoE在核函数生成的共同特征空间中集成学生模型输出。

Result: 在四个真实世界市场数据集上的广泛实验表明，CMM在蒸馏方法和基于RL的市场做市策略方面均表现出优越性。

Conclusion: CMM框架通过多维度特征解耦和协作学习，成功实现了LLM知识的高效蒸馏，为市场做市任务提供了快速且高性能的解决方案。

Abstract: Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an Hájek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies.

</details>


### [77] [PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork](https://arxiv.org/abs/2511.07260)
*Hohei Chan,Xinzhi Zhang,Antao Xiang,Weinan Zhang,Mengchen Zhao*

Main category: cs.AI

TL;DR: PADiff是一种基于扩散模型的ad hoc teamwork方法，通过整合队友预测信息到去噪过程中，解决了传统RL方法在捕捉多模态合作模式方面的不足。


<details>
  <summary>Details</summary>
Motivation: ad hoc teamwork需要智能体与未知队友实时协作，传统RL方法往往只能优化单一期望回报，导致策略收敛到单一主导行为，无法捕捉AHT中固有的多模态合作模式。

Method: 提出PADiff扩散模型方法，将队友的关键预测信息整合到去噪过程中，从而能够捕捉智能体的多模态行为并解锁多样化的合作模式。

Result: 在三个合作环境中的大量实验表明，PADiff显著优于现有的AHT方法。

Conclusion: PADiff通过扩散模型成功解决了AHT中多模态合作模式捕捉的挑战，为ad hoc teamwork提供了有效的解决方案。

Abstract: Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly.

</details>


### [78] [DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas](https://arxiv.org/abs/2511.07338)
*Zhen Wang,Yufan Zhou,Zhongyan Luo,Lyumanshan Ye,Adam Wood,Man Yao,Luoshang Pan*

Main category: cs.AI

TL;DR: DEEPPERSONA是一个可扩展的生成引擎，通过两阶段、分类学指导的方法合成叙事完整的合成人物角色，显著提升了人物属性的多样性和独特性，并在个性化问答和社会调查中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数合成人物角色过于浅显和简单，无法反映真实人类身份的丰富复杂性和多样性。

Method: 采用两阶段方法：首先通过挖掘数千个真实用户与ChatGPT的对话，算法构建了迄今为止最大的人类属性分类学；然后从该分类学中逐步采样属性，条件生成连贯且真实的人物角色。

Result: 内在评估显示属性多样性提高了32%，配置文件独特性提高了44%；外在评估中，人物角色使GPT-4.1-mini的个性化问答准确率平均提高了11.6%，并在社会调查中将模拟LLM公民与真实人类反应之间的差距缩小了31.7%。

Conclusion: DEEPPERSONA为高保真人类模拟和个性化AI研究提供了一个严谨、可扩展且无需隐私的平台。

Abstract: Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.

</details>


### [79] [MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models](https://arxiv.org/abs/2511.06419)
*Jingyu Hu,Shu Yang,Xilin Gong,Hongming Wang,Weiru Liu,Di Wang*

Main category: cs.AI

TL;DR: MONICA框架通过实时监控推理步骤中的谄媚行为，在模型推理过程中动态抑制谄媚倾向，无需等待完整答案生成即可有效减少大型推理模型的谄媚行为。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在谄媚行为，倾向于同意用户的错误信念和错误信息，这损害了模型可靠性并带来社会风险。现有方法主要基于最终答案进行判断和修正，无法理解谄媚在推理过程中的发展。

Method: 提出MONICA框架，包含谄媚监控器和校准器。监控器在响应生成过程中实时监控谄媚漂移分数，校准器在分数超过预定阈值时动态抑制谄媚行为。

Result: 在12个数据集和3个大型推理模型上的广泛实验表明，该方法有效减少了中间推理步骤和最终答案中的谄媚行为，带来了稳健的性能提升。

Conclusion: MONICA框架能够在推理步骤层面监控和缓解谄媚行为，为大型推理模型的可靠性提供了有效解决方案。

Abstract: Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements.

</details>


### [80] [MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks](https://arxiv.org/abs/2511.07107)
*Liang Shan,Kaicheng Shen,Wen Wu,Zhenyu Ying,Chaochao Lu,Guangze Ye,Liang He*

Main category: cs.AI

TL;DR: MENTOR是一个基于元认知的自我进化框架，用于发现和缓解LLMs在领域任务中的隐式风险。它通过元认知自评估工具、动态规则知识图谱和推理时激活引导，实现了持续自我进化，显著降低了语义攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs对齐主要针对显式风险，但忽视了领域特定的隐式风险，且缺乏灵活通用的跨领域框架。需要一种能够持续自我进化、降低维护成本的方法来应对这些挑战。

Method: 1. 引入元认知自评估工具，让LLMs通过换位思考和后果思维反思价值偏差；2. 基于反思结果动态生成补充规则知识图谱；3. 在推理时使用激活引导来强化规则遵循。

Result: 在三个垂直领域的防御测试中，MENTOR显著降低了语义攻击成功率，实现了LLMs隐式风险缓解的新水平。元认知评估与人类评估者高度一致，且提供更全面深入的价值对齐分析。

Conclusion: MENTOR框架通过元认知驱动的自我进化机制，有效解决了LLMs在领域任务中的隐式风险问题，提供了一种成本效益高、可泛化的对齐解决方案。

Abstract: Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [81] [Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation](https://arxiv.org/abs/2511.05516)
*Canxiang Yan,Chunxiang Jin,Dawei Huang,Haibing Yu,Han Peng,Hui Zhan,Jie Gao,Jing Peng,Jingdong Chen,Jun Zhou,Kaimeng Ren,Ming Yang,Mingxue Yang,Qiang Xu,Qin Zhao,Ruijie Xiong,Shaoxiong Lin,Xuezhi Wang,Yi Yuan,Yifei Wu,Yongjie Lyu,Zhengyu He,Zhihao Qiu,Zhiqiang Fang,Ziyuan Huang*

Main category: cs.CL

TL;DR: 提出了一个统一语音理解、生成和编辑的新框架，核心是统一的连续语音分词器MingTok-Audio，基于此开发了语音语言模型Ming-UniAudio，并在ContextASR基准测试中取得了8/12指标的SOTA成绩。


<details>
  <summary>Details</summary>
Motivation: 解决现有语音模型在理解和生成任务上表征需求冲突的问题，使语音语言模型能够执行基于指令的自由形式编辑。

Method: 开发了统一的连续语音分词器MingTok-Audio，整合语义和声学特征；基于此构建语音语言模型Ming-UniAudio；进一步训练专门的语音编辑模型Ming-UniAudio-Edit。

Result: 在ContextASR基准测试中8/12指标达到SOTA；中文语音克隆的Seed-TTS-WER达到0.95；建立了首个指令自由形式语音编辑基准Ming-Freeform-Audio-Edit。

Conclusion: 成功开发了统一的语音理解、生成和编辑框架，实现了语音语言模型在基于自然语言指令的自由形式编辑能力，为统一音频处理奠定了基础。

Abstract: Existing speech models suffer from competing requirements on token representations by understanding and generation tasks. This discrepancy in representation prevents speech language models from performing instruction-based free-form editing. To solve this challenge, we introduce a novel framework that unifies speech understanding, generation, and editing. The core of our unified model is a unified continuous speech tokenizer MingTok-Audio, the first continuous tokenizer to effectively integrate semantic and acoustic features, which makes it suitable for both understanding and generation tasks. Based on this unified continuous audio tokenizer, we developed the speech language model Ming-UniAudio, which achieved a balance between generation and understanding capabilities. Ming-UniAudio sets new state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a dedicated speech editing model Ming-UniAudio-Edit, the first speech language model that enables universal, free-form speech editing guided solely by natural language instructions, handling both semantic and acoustic modifications without timestamp condition. To rigorously assess the editing capability and establish a foundation for future research, we introduce Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for instruction-based free-form speech editing, featuring diverse scenarios and evaluation dimensions spanning semantic correctness, acoustic quality, and instruction alignment. We open-sourced the continuous audio tokenizer, the unified foundational model, and the free-form instruction-based editing model to facilitate the development of unified audio understanding, generation, and manipulation.

</details>


### [82] [Retracing the Past: LLMs Emit Training Data When They Get Lost](https://arxiv.org/abs/2511.05518)
*Myeongseob Ko,Nikhil Reddy Billa,Adam Nguyen,Charles Fleming,Ming Jin,Ruoxi Jia*

Main category: cs.CL

TL;DR: 本文提出了混淆诱导攻击(CIA)框架，通过系统性地最大化模型不确定性来提取记忆的训练数据，并针对对齐LLMs提出了不匹配监督微调(SFT)方法以增强攻击效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型记忆训练数据引发隐私和版权担忧，现有数据提取方法成功率有限且对记忆泄露的根本驱动因素洞察不足。

Method: 利用模型在发散前会出现持续高熵状态的观察，优化输入片段来故意诱导这种连续高熵状态；对于对齐LLMs，使用不匹配SFT同时削弱对齐性并诱导目标混淆。

Result: 在各种未对齐和对齐LLMs上的实验表明，所提出的攻击在提取逐字和近似逐字训练数据方面优于现有基线方法，且无需训练数据的先验知识。

Conclusion: 研究结果突显了各种LLMs中持续存在的记忆风险，并提供了更系统的方法来评估这些漏洞。

Abstract: The memorization of training data in large language models (LLMs) poses significant privacy and copyright concerns. Existing data extraction methods, particularly heuristic-based divergence attacks, often exhibit limited success and offer limited insight into the fundamental drivers of memorization leakage. This paper introduces Confusion-Inducing Attacks (CIA), a principled framework for extracting memorized data by systematically maximizing model uncertainty. We empirically demonstrate that the emission of memorized text during divergence is preceded by a sustained spike in token-level prediction entropy. CIA leverages this insight by optimizing input snippets to deliberately induce this consecutive high-entropy state. For aligned LLMs, we further propose Mismatched Supervised Fine-tuning (SFT) to simultaneously weaken their alignment and induce targeted confusion, thereby increasing susceptibility to our attacks. Experiments on various unaligned and aligned LLMs demonstrate that our proposed attacks outperform existing baselines in extracting verbatim and near-verbatim training data without requiring prior knowledge of the training data. Our findings highlight persistent memorization risks across various LLMs and offer a more systematic method for assessing these vulnerabilities.

</details>


### [83] [MCP4IFC: IFC-Based Building Design Using Large Language Models](https://arxiv.org/abs/2511.05533)
*Bharathi Kannan Nithyanantham,Tobias Sesterhenn,Ashwin Nedungadi,Sergio Peral Garijo,Janis Zenkner,Christian Bartelt,Stefan Lüdtke*

Main category: cs.CL

TL;DR: MCP4IFC是一个开源框架，通过模型上下文协议让大型语言模型能够直接操作建筑行业标准IFC数据，实现自然语言指令到建筑信息模型操作的转换。


<details>
  <summary>Details</summary>
Motivation: 将生成式AI引入建筑、工程和施工领域需要能够将自然语言指令转换为标准化数据模型操作的系统。

Method: 提供BIM工具集，包括场景查询工具、预定义函数用于创建和修改建筑元素，以及结合上下文学习和检索增强生成的动态代码生成系统。

Result: 实验表明，使用该框架的LLM能够成功执行复杂任务，从构建简单房屋到查询和编辑现有IFC数据。

Conclusion: 该开源框架为LLM驱动的BIM设计研究提供了基础，并为AI辅助建模工作流程奠定了基础。

Abstract: Bringing generative AI into the architecture, engineering and construction (AEC) field requires systems that can translate natural language instructions into actions on standardized data models. We present MCP4IFC, a comprehensive open-source framework that enables Large Language Models (LLMs) to directly manipulate Industry Foundation Classes (IFC) data through the Model Context Protocol (MCP). The framework provides a set of BIM tools, including scene querying tools for information retrieval, predefined functions for creating and modifying common building elements, and a dynamic code-generation system that combines in-context learning with retrieval-augmented generation (RAG) to handle tasks beyond the predefined toolset. Experiments demonstrate that an LLM using our framework can successfully perform complex tasks, from building a simple house to querying and editing existing IFC data. Our framework is released as open-source to encourage research in LLM-driven BIM design and provide a foundation for AI-assisted modeling workflows. Our code is available at https://show2instruct.github.io/mcp4ifc/.

</details>


### [84] [FlowMM: Cross-Modal Information Flow Guided KV Cache Merging for Efficient Multimodal Context Inference](https://arxiv.org/abs/2511.05534)
*Kunxi Li,Yufan Xiong,Zhonghua Jiang,Yiyun Zhou,Zhaode Wang,Chengfei Lv,Shengyu Zhang*

Main category: cs.CL

TL;DR: FlowMM是一个自适应跨模态信息流引导的多模态KV缓存合并框架，通过层特定合并策略和敏感度自适应令牌匹配机制，在减少80-95% KV缓存内存和降低1.3-1.8倍解码延迟的同时保持竞争性任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统KV缓存淘汰策略基于注意力分数丢弃不重要的KV对，会降低生成质量，导致上下文丢失或幻觉。在多模态场景中，模态令牌间的分布偏差和跨模态交互中的注意力偏差限制了现有合并方法的有效性。

Method: FlowMM利用跨模态信息流动态应用层特定合并策略，捕捉模态特定模式同时保持上下文完整性。引入敏感度自适应令牌匹配机制，联合评估令牌相似性和任务关键敏感度，合并低风险令牌同时保护高敏感度令牌。

Result: 在多种领先MLLM上的广泛实验表明，FlowMM能够减少80%到95%的KV缓存内存，降低1.3-1.8倍的解码延迟，同时保持竞争性的任务性能。

Conclusion: FlowMM通过跨模态信息流引导的自适应KV缓存合并，有效解决了多模态场景中的KV缓存效率问题，在显著减少内存占用和延迟的同时维持了模型性能。

Abstract: Traditional KV cache eviction strategies, which discard less critical KV-pairs based on attention scores, often degrade generation quality, causing context loss or hallucinations. Recent efforts shift toward KV merging, merging eviction tokens with retention tokens based on similarity. However, in multimodal scenarios, distributional biases across modality tokens and attentional biases in cross-modal interactions limit its effectiveness. This work introduces FlowMM, an adaptive framework for cross-modal information flow-guided multimodal KV cache merging. FlowMM leverages cross-modal information flow to dynamically apply layer-specific merging strategies, capturing modality-specific patterns while preserving contextual integrity. Furthermore, we introduce a sensitivity-adaptive token matching mechanism that jointly evaluates token similarity and task-critical sensitivity, merging low-risk tokens while safeguarding high-sensitivity ones. Extensive experiments across diverse leading MLLMs show that FlowMM reduces KV cache memory by 80% to 95% and decoding latency by 1.3-1.8x, while maintaining competitive task performance.

</details>


### [85] [Temporal Sparse Autoencoders: Leveraging the Sequential Nature of Language for Interpretability](https://arxiv.org/abs/2511.05541)
*Usha Bhalla,Alex Oesterling,Claudio Mayrink Verdun,Himabindu Lakkaraju,Flavio P. Calmon*

Main category: cs.CL

TL;DR: 本文提出时间稀疏自编码器（T-SAEs），通过引入对比损失来鼓励相邻token间高级特征的一致性激活，从而在无监督条件下分离语义和句法特征，解决了传统字典学习方法偏向浅层、token特定或噪声特征的问题。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器等字典学习方法在发现人类可解释特征时存在系统性缺陷，倾向于捕获浅层、token特定或噪声特征，而忽略了语言丰富的概念信息。这源于训练方法忽视了语言本身的结构特性。

Method: 基于语义内容具有长程依赖性和序列平滑性、而句法信息更局部的语言学洞察，提出T-SAEs，引入新颖的对比损失来鼓励相邻token间高级特征的一致性激活，以自监督方式分离语义和句法特征。

Result: 在多个数据集和模型上，T-SAEs恢复了更平滑、更连贯的语义概念，且不牺牲重构质量。尽管没有显式语义信号训练，它们仍展现出清晰的语义结构。

Conclusion: T-SAEs为语言模型的无监督可解释性提供了新途径，通过利用语言结构特性显著改善了特征发现质量。

Abstract: Translating the internal representations and computations of models into concepts that humans can understand is a key goal of interpretability. While recent dictionary learning methods such as Sparse Autoencoders (SAEs) provide a promising route to discover human-interpretable features, they suffer from a variety of problems, including a systematic failure to capture the rich conceptual information that drives linguistic understanding. Instead, they exhibit a bias towards shallow, token-specific, or noisy features, such as "the phrase 'The' at the start of sentences". In this work, we propose that this is due to a fundamental issue with how dictionary learning methods for LLMs are trained. Language itself has a rich, well-studied structure spanning syntax, semantics, and pragmatics; however, current unsupervised methods largely ignore this linguistic knowledge, leading to poor feature discovery that favors superficial patterns over meaningful concepts. We focus on a simple but important aspect of language: semantic content has long-range dependencies and tends to be smooth over a sequence, whereas syntactic information is much more local. Building on this insight, we introduce Temporal Sparse Autoencoders (T-SAEs), which incorporate a novel contrastive loss encouraging consistent activations of high-level features over adjacent tokens. This simple yet powerful modification enables SAEs to disentangle semantic from syntactic features in a self-supervised manner. Across multiple datasets and models, T-SAEs recover smoother, more coherent semantic concepts without sacrificing reconstruction quality. Strikingly, they exhibit clear semantic structure despite being trained without explicit semantic signal, offering a new pathway for unsupervised interpretability in language models.

</details>


### [86] [UTF-8 Plumbing: Byte-level Tokenizers Unavoidably Enable LLMs to Generate Ill-formed UTF-8](https://arxiv.org/abs/2511.05578)
*Preston Firestone,Shubham Ugare,Gagandeep Singh,Sasa Misailovic*

Main category: cs.CL

TL;DR: 本文通过幺半群理论形式化分析了子词分词，证明了包含无效UTF-8标记的分词器会产生无效UTF-8序列，并揭示了增量解码与整体解码的不一致性，预测了实际系统中的bug。


<details>
  <summary>Details</summary>
Motivation: 解决子词分词中代码点与字节方法的权衡问题：代码点方法需要大量初始词汇表成员但保证UTF-8有效性，字节方法只需256个初始成员但会产生无效UTF-8序列，导致下游应用崩溃。

Method: 使用幺半群理论形式化分词过程，证明包含无效UTF-8标记的分词器必然产生无效UTF-8序列，并分析增量解码与整体解码的不一致性。

Result: 形式化证明预测了现实世界中的bug，评估了现有缓解措施，并对主要基础模型、服务引擎和约束生成系统进行了案例研究。

Conclusion: 字节级分词虽然避免了词汇表外错误，但引入了UTF-8有效性风险，需要应用层处理由此产生的破坏，形式化分析为理解和解决这一问题提供了理论基础。

Abstract: Subword tokenization segments input text according to a pre-defined vocabulary to feed it into a language model; the language model, in turn, generates a sequence made from this same vocabulary. The members of the vocabulary can be built of code points or bytes. Using code points means that all members of the vocabulary are valid UTF-8 characters. However, it also requires thousands of initial members to achieve acceptable coverage of inputs. Beginning with bytes, on the contrary, avoids out-of-vocabulary errors with only 256 initial members of the vocabulary, but the members of the vocabulary and sequences of them are not guaranteed to be valid UTF-8. Sequences that are not valid UTF-8 break code that assumes its input to be valid UTF-8. Applications of language models must account for the breakage thereby introduced. In this paper, we formalize tokenization using monoid theory and prove that tokenizers whose vocabularies contain tokens that are ill-formed UTF-8 can always produce sequences that are ill-formed UTF-8. We demonstrate formally that attempting to incrementally convert tokens back to a string and interpret the results as UTF-8 gives different results than converting the whole sequence of tokens at once. This formal result predicts real-world bugs: we evaluate mitigations for the problem identified and provide case studies of major foundation models, serving engines, and constrained generation systems.

</details>


### [87] [Optimizing Diversity and Quality through Base-Aligned Model Collaboration](https://arxiv.org/abs/2511.05650)
*Yichen Wang,Chenghao Yang,Tenghao Huang,Muhao Chen,Jonathan May,Mina Lee*

Main category: cs.CL

TL;DR: BACo是一个推理时令牌级模型协作框架，通过动态结合基础LLM和对齐LLM来优化多样性和质量，在单次推理中实现多样性和质量的联合提升。


<details>
  <summary>Details</summary>
Motivation: 对齐虽然提高了大语言模型的输出质量，但牺牲了多样性，导致生成内容高度相似。现有方法如重新训练、提示工程和多采样方法虽然能提升多样性，但往往降低质量或需要昂贵的解码或后训练成本。

Method: 提出Base-Aligned Model Collaboration (BACo)框架，采用路由策略在令牌级别动态决定从哪个模型解码，基于下一个令牌预测的不确定性和预测内容的语义角色。

Result: 在三个开放生成任务和13个指标上，BACo持续超越最先进的推理时基线方法，最佳路由器实现了多样性和质量21.3%的联合提升，人类评估也证实了这些改进。

Conclusion: 基础模型和对齐模型之间的协作可以有效优化和控制多样性与质量。

Abstract: Alignment has greatly improved large language models (LLMs)' output quality at the cost of diversity, yielding highly similar outputs across generations. We propose Base-Aligned Model Collaboration (BACo), an inference-time token-level model collaboration framework that dynamically combines a base LLM with its aligned counterpart to optimize diversity and quality. Inspired by prior work (Fei et al., 2025), BACo employs routing strategies that determine, at each token, from which model to decode based on next-token prediction uncertainty and predicted contents' semantic role. Prior diversity-promoting methods, such as retraining, prompt engineering, and multi-sampling methods, improve diversity but often degrade quality or require costly decoding or post-training. In contrast, BACo achieves both high diversity and quality post hoc within a single pass, while offering strong controllability. We explore a family of routing strategies, across three open-ended generation tasks and 13 metrics covering diversity and quality, BACo consistently surpasses state-of-the-art inference-time baselines. With our best router, BACo achieves a 21.3% joint improvement in diversity and quality. Human evaluations also mirror these improvements. The results suggest that collaboration between base and aligned models can optimize and control diversity and quality.

</details>


### [88] [OckBench: Measuring the Efficiency of LLM Reasoning](https://arxiv.org/abs/2511.05722)
*Zheng Du,Hao Kang,Song Han,Tushar Krishna,Ligeng Zhu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models such as GPT-4, Claude 3, and the Gemini series have improved automated reasoning and code generation. However, existing benchmarks mainly focus on accuracy and output quality, and they ignore an important factor: decoding token efficiency. In real systems, generating 10,000 tokens versus 100,000 tokens leads to large differences in latency, cost, and energy. In this work, we introduce OckBench, a model-agnostic and hardware-agnostic benchmark that evaluates both accuracy and token count for reasoning and coding tasks. Through experiments comparing multiple open- and closed-source models, we uncover that many models with comparable accuracy differ wildly in token consumption, revealing that efficiency variance is a neglected but significant axis of differentiation. We further demonstrate Pareto frontiers over the accuracy-efficiency plane and argue for an evaluation paradigm shift: we should no longer treat tokens as "free" to multiply. OckBench provides a unified platform for measuring, comparing, and guiding research in token-efficient reasoning. Our benchmarks are available at https://ockbench.github.io/ .

</details>


### [89] [In-Context Learning Without Copying](https://arxiv.org/abs/2511.05743)
*Kerem Sahin,Sheridan Feucht,Adam Belfki,Jannik Brinkmann,Aaron Mueller,David Bau,Chris Wendler*

Main category: cs.CL

TL;DR: 本文提出Hapax方法，通过抑制归纳复制来研究Transformer是否仍能获得上下文学习能力。实验表明即使减少归纳复制，模型在抽象上下文学习任务上表现仍然良好。


<details>
  <summary>Details</summary>
Motivation: 研究归纳复制是否是Transformer获得复杂上下文学习能力的先决条件，探索是否可以通过抑制归纳复制来训练模型。

Method: 提出Hapax设置，在训练中省略可由归纳头正确预测的token的损失贡献，从而抑制归纳复制。

Result: 尽管31.7%的token被省略损失，模型在21个任务中的13个上表现优于原始模型，且在归纳头无法正确预测的位置损失更低。

Conclusion: 归纳复制对于学习抽象上下文学习机制并非必需，模型可以在减少归纳复制的情况下仍保持上下文学习能力。

Abstract: Induction heads are attention heads that perform inductive copying by matching patterns from earlier context and copying their continuations verbatim. As models develop induction heads, they often experience a sharp drop in training loss, a phenomenon cited as evidence that induction heads may serve as a prerequisite for more complex in-context learning (ICL) capabilities. In this work, we ask whether transformers can still acquire ICL capabilities when inductive copying is suppressed. We propose Hapax, a setting where we omit the loss contribution of any token that can be correctly predicted by induction heads. Despite a significant reduction in inductive copying, performance on abstractive ICL tasks (i.e., tasks where the answer is not contained in the input context) remains comparable and surpasses the vanilla model on 13 of 21 tasks, even though 31.7\% of tokens are omitted from the loss. Furthermore, our model achieves lower loss values on token positions that cannot be predicted correctly by induction heads. Mechanistic analysis further shows that models trained with Hapax develop fewer and weaker induction heads but still preserve ICL capabilities. Taken together, our findings indicate that inductive copying is not essential for learning abstractive ICL mechanisms.

</details>


### [90] [Language Generation: Complexity Barriers and Implications for Learning](https://arxiv.org/abs/2511.05759)
*Marcelo Arenas,Pablo Barceló,Luis Cofré,Alexander Kozachinskiy*

Main category: cs.CL

TL;DR: 本文揭示了语言生成理论可能性与实际可行性之间的巨大差距，即使对于简单的正则语言和上下文无关语言，成功生成所需的示例数量可能极其庞大，甚至无法用可计算函数界定。


<details>
  <summary>Details</summary>
Motivation: 虽然Kleinberg和Mullainathan证明了语言生成在理论上是可能的，但这种理论保证并未涉及实际可行性。本文旨在探讨语言生成的实际效率问题。

Method: 通过分析简单且经过充分研究的语言家族（如正则语言和上下文无关语言），研究成功生成所需示例数量的界限。

Result: 研究发现，即使是简单的语言家族，成功生成所需的示例数量可能极其庞大，在某些情况下甚至无法用任何可计算函数界定。

Conclusion: 现代语言模型的经验成功需要更精细的视角，必须考虑自然语言的结构特性，这些特性使得有效的生成在实践中成为可能。

Abstract: Kleinberg and Mullainathan showed that, in principle, language generation is always possible: with sufficiently many positive examples, a learner can eventually produce sentences indistinguishable from those of a target language. However, the existence of such a guarantee does not speak to its practical feasibility. In this work, we show that even for simple and well-studied language families -- such as regular and context-free languages -- the number of examples required for successful generation can be extraordinarily large, and in some cases not bounded by any computable function. These results reveal a substantial gap between theoretical possibility and efficient learnability. They suggest that explaining the empirical success of modern language models requires a refined perspective -- one that takes into account structural properties of natural language that make effective generation possible in practice.

</details>


### [91] [DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning](https://arxiv.org/abs/2511.05784)
*Yaxuan Wang,Chris Yuhao Liu,Quan Liu,Jinglong Pang,Wei Wei,Yujia Bao,Yang Liu*

Main category: cs.CL

TL;DR: DRAGON是一个基于推理的大语言模型遗忘框架，通过上下文思维链指令来保护部署的LLM，无需修改基础模型或保留数据，在数据受限的实际场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法通常需要训练或访问保留数据，这在现实场景中往往不可用。需要开发在数据受限情况下仍能有效工作的实用遗忘方法。

Method: 提出DRAGON框架，利用LLM固有的指令遵循能力，引入轻量级检测模块识别需要遗忘的提示，然后通过专门的CoT防护模型进行安全准确的上下文干预。

Result: 在三个代表性遗忘任务上的广泛实验验证了DRAGON的有效性，展示了强大的遗忘能力、可扩展性和在实际场景中的适用性。

Conclusion: DRAGON提供了一种系统性的、基于推理的遗忘方法，能够在没有保留数据的情况下有效保护LLM，为实际部署提供了可行的解决方案。

Abstract: Unlearning in Large Language Models (LLMs) is crucial for protecting private data and removing harmful knowledge. Most existing approaches rely on fine-tuning to balance unlearning efficiency with general language capabilities. However, these methods typically require training or access to retain data, which is often unavailable in real world scenarios. Although these methods can perform well when both forget and retain data are available, few works have demonstrated equivalent capability in more practical, data-limited scenarios. To overcome these limitations, we propose Detect-Reasoning Augmented GeneratiON (DRAGON), a systematic, reasoning-based framework that utilizes in-context chain-of-thought (CoT) instructions to guard deployed LLMs before inference. Instead of modifying the base model, DRAGON leverages the inherent instruction-following ability of LLMs and introduces a lightweight detection module to identify forget-worthy prompts without any retain data. These are then routed through a dedicated CoT guard model to enforce safe and accurate in-context intervention. To robustly evaluate unlearning performance, we introduce novel metrics for unlearning performance and the continual unlearning setting. Extensive experiments across three representative unlearning tasks validate the effectiveness of DRAGON, demonstrating its strong unlearning capability, scalability, and applicability in practical scenarios.

</details>


### [92] [Quantifying Edits Decay in Fine-tuned LLMs](https://arxiv.org/abs/2511.05852)
*Yinjie Cheng,Paul Youssef,Christin Seifert,Jörg Schlötterer,Zhixue Zhao*

Main category: cs.CL

TL;DR: 本文研究了在大型语言模型中进行知识编辑后再进行微调时，编辑内容的保持情况。通过系统实验发现编辑内容在微调后会衰减，并提出选择性层微调策略来有效移除或保留编辑。


<details>
  <summary>Details</summary>
Motivation: 知识编辑和微调是LLMs后训练的两种常用操作，但它们在实践中被孤立研究。关键问题是：如果对编辑后的模型进行微调，编辑内容是否会保留？这涉及到移除恶意编辑和保留有益编辑两个实际场景。

Method: 系统评估两种最先进的编辑方法（MEMIT、AlphaEdit）和三种微调方法（全参数、LoRA、DoRA），在五个LLMs和三个数据集上进行232个实验配置。进一步提出选择性层微调策略。

Result: 编辑内容在微调后会衰减，不同配置下生存率不同（AlphaEdit比MEMIT衰减更多）。选择性层微调可以有效移除编辑，但会轻微影响下游性能。令人惊讶的是，仅微调非编辑层比全参数微调对编辑的损害更大。

Conclusion: 研究为知识编辑与微调的整合建立了经验基准和可行策略，强调评估模型编辑需要考虑完整的LLM应用流程。

Abstract: Knowledge editing has emerged as a lightweight alternative to retraining for correcting or injecting specific facts in large language models (LLMs). Meanwhile, fine-tuning remains the default operation for adapting LLMs to new domains and tasks. Despite their widespread adoption, these two post-training interventions have been studied in isolation, leaving open a crucial question: if we fine-tune an edited model, do the edits survive? This question is motivated by two practical scenarios: removing covert or malicious edits, and preserving beneficial edits. If fine-tuning impairs edits as shown in Figure 1, current KE methods become less useful, as every fine-tuned model would require re-editing, which significantly increases the cost; if edits persist, fine-tuned models risk propagating hidden malicious edits, raising serious safety concerns. To this end, we systematically quantify edits decay after fine-tuning, investigating how fine-tuning affects knowledge editing. We evaluate two state-of-the-art editing methods (MEMIT, AlphaEdit) and three fine-tuning approaches (full-parameter, LoRA, DoRA) across five LLMs and three datasets, yielding 232 experimental configurations. Our results show that edits decay after fine-tuning, with survival varying across configurations, e.g., AlphaEdit edits decay more than MEMIT edits. Further, we propose selective-layer fine-tuning and find that fine-tuning edited layers only can effectively remove edits, though at a slight cost to downstream performance. Surprisingly, fine-tuning non-edited layers impairs more edits than full fine-tuning. Overall, our study establishes empirical baselines and actionable strategies for integrating knowledge editing with fine-tuning, and underscores that evaluating model editing requires considering the full LLM application pipeline.

</details>


### [93] [NILC: Discovering New Intents with LLM-assisted Clustering](https://arxiv.org/abs/2511.05913)
*Hongtao Wang,Renchi Yang,Wenqing Lin*

Main category: cs.CL

TL;DR: 本文提出NILC框架，通过结合大语言模型迭代优化聚类过程，解决新意图发现中传统级联方法的局限性，在无监督和半监督设置下均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有新意图发现方法采用级联架构，无法利用两个步骤的反馈进行相互优化，且仅基于嵌入的聚类忽略了细微的文本语义，导致性能不佳。

Method: NILC采用迭代工作流程，利用LLMs创建语义质心丰富嵌入质心的上下文语义，并通过重写增强困难样本进行聚类校正，在半监督设置中引入种子和软必须链接注入监督信号。

Result: 在六个不同领域的基准数据集上，NILC相比多个最新基线方法在无监督和半监督设置下均实现了显著的性能改进。

Conclusion: NILC框架通过LLMs增强的迭代聚类方法有效解决了新意图发现中的语义理解问题，为对话系统提供了更准确的新意图识别能力。

Abstract: New intent discovery (NID) seeks to recognize both new and known intents from unlabeled user utterances, which finds prevalent use in practical dialogue systems. Existing works towards NID mainly adopt a cascaded architecture, wherein the first stage focuses on encoding the utterances into informative text embeddings beforehand, while the latter is to group similar embeddings into clusters (i.e., intents), typically by K-Means. However, such a cascaded pipeline fails to leverage the feedback from both steps for mutual refinement, and, meanwhile, the embedding-only clustering overlooks nuanced textual semantics, leading to suboptimal performance. To bridge this gap, this paper proposes NILC, a novel clustering framework specially catered for effective NID. Particularly, NILC follows an iterative workflow, in which clustering assignments are judiciously updated by carefully refining cluster centroids and text embeddings of uncertain utterances with the aid of large language models (LLMs). Specifically, NILC first taps into LLMs to create additional semantic centroids for clusters, thereby enriching the contextual semantics of the Euclidean centroids of embeddings. Moreover, LLMs are then harnessed to augment hard samples (ambiguous or terse utterances) identified from clusters via rewriting for subsequent cluster correction. Further, we inject supervision signals through non-trivial techniques seeding and soft must links for more accurate NID in the semi-supervised setting. Extensive experiments comparing NILC against multiple recent baselines under both unsupervised and semi-supervised settings showcase that NILC can achieve significant performance improvements over six benchmark datasets of diverse domains consistently.

</details>


### [94] [Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs](https://arxiv.org/abs/2511.05933)
*Renfei Zhang,Manasa Kaniselvan,Niloofar Mireshghallah*

Main category: cs.CL

TL;DR: 强化学习（RL）实际上能提升语言模型的知识回忆能力，特别是在需要遍历层次化结构化知识（如医学代码）的任务中，这归因于RL改进了模型在现有知识层次中导航和搜索的程序性技能。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，即强化学习以牺牲记忆知识为代价来提升语言模型的推理和泛化能力，发现RL增强的模型在纯知识回忆任务上表现更优。

Method: 通过结构化提示引导SFT模型进行层次遍历，比较RL和SFT模型在知识回忆任务上的表现，并进行层间内部激活分析。

Result: RL模型在知识回忆任务上优于基础和SFT模型，结构化提示能缩小性能差距（在MedConceptsQA上从24pp降至7pp），但RL模型在深度检索任务中仍保持更好的程序路径回忆能力。

Conclusion: RL主要改变模型如何遍历知识，而非知识表示本身，通过提升程序性技能来增强知识回忆能力。

Abstract: Reinforcement learning (RL) is often credited with improving language model reasoning and generalization at the expense of degrading memorized knowledge. We challenge this narrative by observing that RL-enhanced models consistently outperform their base and supervised fine-tuned (SFT) counterparts on pure knowledge recall tasks, particularly those requiring traversal of hierarchical, structured knowledge (e.g., medical codes). We hypothesize these gains stem not from newly acquired data, but from improved procedural skills in navigating and searching existing knowledge hierarchies within the model parameters. To support this hypothesis, we show that structured prompting, which explicitly guides SFTed models through hierarchical traversal, recovers most of the performance gap (reducing 24pp to 7pp on MedConceptsQA for DeepSeek-V3/R1). We further find that while prompting improves final-answer accuracy, RL-enhanced models retain superior ability to recall correct procedural paths on deep-retrieval tasks. Finally our layer-wise internal activation analysis reveals that while factual representations (e.g., activations for the statement "code 57.95 refers to urinary infection") maintain high cosine similarity between SFT and RL models, query representations (e.g., "what is code 57.95") diverge noticeably, indicating that RL primarily transforms how models traverse knowledge rather than the knowledge representation itself.

</details>


### [95] [Interpretable Recognition of Cognitive Distortions in Natural Language Texts](https://arxiv.org/abs/2511.05969)
*Anton Kolonin,Anna Arinicheva*

Main category: cs.CL

TL;DR: 提出了一种基于加权结构化模式的多因素文本分类方法，用于自动化检测心理护理中的认知扭曲问题。


<details>
  <summary>Details</summary>
Motivation: 解决心理护理中认知扭曲检测的社会影响问题，开发可解释、稳健且透明的人工智能模型。

Method: 基于N-gram等加权结构化模式，考虑模式间的异质层级关系，提出识别和学习算法。

Result: 在两个公开数据集上测试，相比现有文献的F1分数有显著提升，确定了最优超参数，代码和模型可供社区使用。

Conclusion: 所提出的方法在该领域改进了当前技术水平，为心理护理中的认知扭曲检测提供了有效解决方案。

Abstract: We propose a new approach to multi-factor classification of natural language texts based on weighted structured patterns such as N-grams, taking into account the heterarchical relationships between them, applied to solve such a socially impactful problem as the automation of detection of specific cognitive distortions in psychological care, relying on an interpretable, robust and transparent artificial intelligence model. The proposed recognition and learning algorithms improve the current state of the art in this field. The improvement is tested on two publicly available datasets, with significant improvements over literature-known F1 scores for the task, with optimal hyper-parameters determined, having code and models available for future use by the community.

</details>


### [96] [Revisiting Entropy in Reinforcement Learning for Large Reasoning Models](https://arxiv.org/abs/2511.05993)
*Renren Jin,Pengzhi Gao,Yuqi Ren,Zhuowen Han,Tongxuan Zhang,Wuwei Huang,Wei Liu,Jian Luan,Deyi Xiong*

Main category: cs.CL

TL;DR: 本文研究了强化学习与可验证奖励（RLVR）训练中大型语言模型的熵崩溃问题，分析了影响熵的关键因素，并提出通过调整正负优势token的相对损失权重来有效调控模型熵。


<details>
  <summary>Details</summary>
Motivation: RLVR已成为提升大型语言模型推理能力的主要方法，但在训练过程中模型熵通常会崩溃，导致过早收敛到次优局部极小值，阻碍性能进一步提升。尽管已有多种方法缓解熵崩溃，但对RLVR中熵的全面研究仍然缺乏。

Method: 通过大量实验研究RLVR训练中LLMs的熵动态，分析模型熵与响应多样性、校准和性能的关联；理论分析和实证证明正优势token是熵崩溃的主要贡献者；通过调整正负优势token的相对损失权重来调控模型熵。

Result: 研究发现离策略更新次数、训练数据多样性和优化目标中的裁剪阈值是影响RLVR训练中LLMs熵的关键因素；正优势token是熵崩溃的主要来源；通过调整相对损失权重可以有效调控模型熵。

Conclusion: RLVR训练中LLMs的熵崩溃问题可以通过理解熵动态和关键影响因素来有效管理，调整正负优势token的相对损失权重是调控模型熵的有效策略。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a predominant approach for enhancing the reasoning capabilities of large language models (LLMs). However, the entropy of LLMs usually collapses during RLVR training, causing premature convergence to suboptimal local minima and hinder further performance improvement. Although various approaches have been proposed to mitigate entropy collapse, a comprehensive study of entropy in RLVR remains lacking. To address this gap, we conduct extensive experiments to investigate the entropy dynamics of LLMs trained with RLVR and analyze how model entropy correlates with response diversity, calibration, and performance across various benchmarks. Our findings reveal that the number of off-policy updates, the diversity of training data, and the clipping thresholds in the optimization objective are critical factors influencing the entropy of LLMs trained with RLVR. Moreover, we theoretically and empirically demonstrate that tokens with positive advantages are the primary contributors to entropy collapse, and that model entropy can be effectively regulated by adjusting the relative loss weights of tokens with positive and negative advantages during training.

</details>


### [97] [LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis](https://arxiv.org/abs/2511.06000)
*Favour Yahdii Aghaebe,Tanefa Apekey,Elizabeth Williams,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 评估语言模型在生成生物医学研究摘要时保留年龄相关信息的能力，发现模型在不同年龄群体间存在系统性差异，成人群体摘要的年龄信息保留最差，少数群体更容易出现幻觉。


<details>
  <summary>Details</summary>
Motivation: 临床干预措施通常与年龄相关，但语言模型在生物医学证据合成中是否保留这些关键人口统计学差异尚不确定，需要评估模型在生成摘要时保持年龄相关信息的能力。

Method: 构建DemogSummary数据集，包含儿童、成人和老年人群体研究，评估Qwen、Longformer和GPT-4.1 Nano三种模型，使用标准指标和新提出的Demographic Salience Score来衡量年龄相关实体保留和幻觉。

Result: 模型在年龄群体间存在系统性差异：成人群体摘要的人口统计学保真度最低，代表性不足的群体更容易出现幻觉。

Conclusion: 当前语言模型在忠实和无偏见的生物医学摘要生成方面存在局限性，需要开发公平性评估框架和摘要生成流程。

Abstract: Clinical interventions often hinge on age: medications and procedures safe for adults may be harmful to children or ineffective for older adults. However, as language models are increasingly integrated into biomedical evidence synthesis workflows, it remains uncertain whether these systems preserve such crucial demographic distinctions. To address this gap, we evaluate how well state-of-the-art language models retain age-related information when generating abstractive summaries of biomedical studies. We construct DemogSummary, a novel age-stratified dataset of systematic review primary studies, covering child, adult, and older adult populations. We evaluate three prominent summarisation-capable LLMs, Qwen (open-source), Longformer (open-source) and GPT-4.1 Nano (proprietary), using both standard metrics and a newly proposed Demographic Salience Score (DSS), which quantifies age-related entity retention and hallucination. Our results reveal systematic disparities across models and age groups: demographic fidelity is lowest for adult-focused summaries, and under-represented populations are more prone to hallucinations. These findings highlight the limitations of current LLMs in faithful and bias-free summarisation and point to the need for fairness-aware evaluation frameworks and summarisation pipelines in biomedical NLP.

</details>


### [98] [Multi-Reward GRPO Fine-Tuning for De-biasing Large Language Models: A Study Based on Chinese-Context Discrimination Data](https://arxiv.org/abs/2511.06023)
*Deng Yixuan,Ji Xiaoqiang*

Main category: cs.CL

TL;DR: 本文提出了一个多奖励组相对策略优化（GRPO）框架，用于微调大型语言模型以实现无偏见行为。该方法构建了基于中文语境歧视类别的合成数据集，训练基于DeBERTa-v3的奖励模型，通过多维度奖励信号指导模型优化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在隐含偏见和歧视倾向，反映社会刻板印象。现有的对齐技术如RLHF和DPO在解决文化特定和多维度歧视方面存在局限性。

Method: 构建中文语境歧视类别的合成英文数据集，训练基于DeBERTa-v3的多维度奖励模型（公平性、中立性、语言质量），使用GRPO框架进行微调优化。

Result: 实验结果显示偏见强度显著降低，模型输出与非歧视标准更一致，同时保持了流畅性和信息量。

Conclusion: GRPO多奖励优化方法在消除LLM偏见方面有效，为文化语境伦理对齐提供了可复现框架。

Abstract: Large Language Models (LLMs) often exhibit implicit biases and discriminatory tendencies that reflect underlying social stereotypes. While recent alignment techniques such as RLHF and DPO have mitigated some of these issues, they remain limited in addressing culturally specific and multi-dimensional forms of discrimination. This paper proposes a Multi-Reward Group Relative Policy Optimization (GRPO) framework to fine-tune LLMs toward ethical and bias-free behavior. Our approach constructs a synthetic English-language dataset derived from Chinese-context discrimination categories, including regional, ethnic, and occupational biases. Each instance is paired with both neutral and biased responses to train a reward model based on DeBERTa-v3, which provides multi-dimensional reward signals capturing fairness, neutrality, and linguistic quality. The trained reward model then guides GRPO fine-tuning to optimize model outputs along these ethical dimensions. Experimental results demonstrate significant reductions in bias intensity and improved alignment with non-discriminatory standards without compromising fluency or informativeness. This study highlights the effectiveness of GRPO-based multi-reward optimization for de-biasing LLMs and offers a replicable framework for cultural-contextual ethical alignment.

</details>


### [99] [Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated Concepts](https://arxiv.org/abs/2511.06048)
*Xinyuan Yan,Shusen Liu,Kowshik Thopalli,Bei Wang*

Main category: cs.CL

TL;DR: 提出了一个聚焦探索框架，通过优先处理精选概念及其对应的稀疏自编码器特征，而不是同时可视化所有可用特征，来解决稀疏自编码器特征分析的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器已成为揭示大语言模型中可解释特征的有力工具，但提取的方向数量庞大使得全面探索变得不可行。传统嵌入技术如UMAP存在高维压缩伪影、过度绘图和误导性邻域失真等局限性。

Method: 提出结合拓扑可视化编码与降维的交互式可视化系统，忠实表示选定特征的局部和全局关系，使用户能够通过有针对性的、可解释的子集来研究稀疏自编码器行为。

Result: 该混合方法使用户能够更深入、更细致地分析潜在空间中的概念表示，解决了传统可视化方法的局限性。

Conclusion: 聚焦探索框架通过优先处理精选概念及其对应特征，结合拓扑可视化与降维技术，为稀疏自编码器特征分析提供了更有效的探索工具。

Abstract: Sparse autoencoders (SAEs) have emerged as a powerful tool for uncovering interpretable features in large language models (LLMs) through the sparse directions they learn. However, the sheer number of extracted directions makes comprehensive exploration intractable. While conventional embedding techniques such as UMAP can reveal global structure, they suffer from limitations including high-dimensional compression artifacts, overplotting, and misleading neighborhood distortions. In this work, we propose a focused exploration framework that prioritizes curated concepts and their corresponding SAE features over attempts to visualize all available features simultaneously. We present an interactive visualization system that combines topology-based visual encoding with dimensionality reduction to faithfully represent both local and global relationships among selected features. This hybrid approach enables users to investigate SAE behavior through targeted, interpretable subsets, facilitating deeper and more nuanced analysis of concept representation in latent space.

</details>


### [100] [Automating Hardware Design and Verification from Architectural Papers via a Neural-Symbolic Graph Framework](https://arxiv.org/abs/2511.06067)
*Haoyue Yang,Xuanle Zhao,Yujie Liu,Zhuojun Zou,Kailin Lyu,Changchun Zhou,Yao Zhu,Jie Hao*

Main category: cs.CL

TL;DR: ArchCraft是一个将学术论文中的硬件架构描述转换为可综合Verilog项目的框架，通过结构化工作流程和符号化功能规范实现RTL验证和PPA报告。


<details>
  <summary>Details</summary>
Motivation: 解决硬件架构复现的挑战，包括缺乏公开源代码和硬件描述语言的复杂性。

Method: 使用形式化图捕捉架构蓝图，符号定义功能规范，生成RTL和测试平台代码，并创建ArchSynthBench基准进行评估。

Result: 在ArchSynthBench上的实验表明，该方法在论文理解和代码完成方面优于直接生成方法和VerilogCoder框架，生成的RTL代码满足所有时序约束且性能指标与原始论文一致。

Conclusion: ArchCraft框架能够有效将学术论文中的硬件架构描述转换为可验证、可实现的硬件设计，解决了硬件复现的关键问题。

Abstract: The reproduction of hardware architectures from academic papers remains a significant challenge due to the lack of publicly available source code and the complexity of hardware description languages (HDLs). To this end, we propose \textbf{ArchCraft}, a Framework that converts abstract architectural descriptions from academic papers into synthesizable Verilog projects with register-transfer level (RTL) verification. ArchCraft introduces a structured workflow, which uses formal graphs to capture the Architectural Blueprint and symbols to define the Functional Specification, translating unstructured academic papers into verifiable, hardware-aware designs. The framework then generates RTL and testbench (TB) code decoupled via these symbols to facilitate verification and debugging, ultimately reporting the circuit's Power, Area, and Performance (PPA). Moreover, we propose the first benchmark, \textbf{ArchSynthBench}, for synthesizing hardware from architectural descriptions, with a complete set of evaluation indicators, 50 project-level circuits, and around 600 circuit blocks. We systematically assess ArchCraft on ArchSynthBench, where the experiment results demonstrate the superiority of our proposed method, surpassing direct generation methods and the VerilogCoder framework in both paper understanding and code completion. Furthermore, evaluation and physical implementation of the generated executable RTL code show that these implementations meet all timing constraints without violations, and their performance metrics are consistent with those reported in the original papers.

</details>


### [101] [Stemming Hallucination in Language Models Using a Licensing Oracle](https://arxiv.org/abs/2511.06073)
*Simeon Emanuilov,Richard Ackermann*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Licensing Oracle的架构解决方案，通过结构化知识图谱的形式验证来约束语言模型的生成，从而消除幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 语言模型在自然语言生成方面表现出色，但仍容易产生事实错误的幻觉信息，即使生成的回答在语法上是连贯的。

Method: Licensing Oracle在模型的生成过程中嵌入确定性验证步骤，通过形式化验证结构化知识图谱来强制执行真实性约束。

Result: Licensing Oracle实现了完美的弃权精度（AP = 1.0）和零错误答案（FAR-NE = 0.0），在事实回答中达到89.1%的准确率，优于RAG和微调方法。

Conclusion: Licensing Oracle为具有结构化知识表示的领域提供了必要且充分的幻觉解决方案，其框架为未来AI系统中的真实性约束生成奠定了基础。

Abstract: Language models exhibit remarkable natural language generation capabilities but remain prone to hallucinations, generating factually incorrect information despite producing syntactically coherent responses. This study introduces the Licensing Oracle, an architectural solution designed to stem hallucinations in LMs by enforcing truth constraints through formal validation against structured knowledge graphs. Unlike statistical approaches that rely on data scaling or fine-tuning, the Licensing Oracle embeds a deterministic validation step into the model's generative process, ensuring that only factually accurate claims are made. We evaluated the effectiveness of the Licensing Oracle through experiments comparing it with several state-of-the-art methods, including baseline language model generation, fine-tuning for factual recall, fine-tuning for abstention behavior, and retrieval-augmented generation (RAG). Our results demonstrate that although RAG and fine-tuning improve performance, they fail to eliminate hallucinations. In contrast, the Licensing Oracle achieved perfect abstention precision (AP = 1.0) and zero false answers (FAR-NE = 0.0), ensuring that only valid claims were generated with 89.1% accuracy in factual responses. This work shows that architectural innovations, such as the Licensing Oracle, offer a necessary and sufficient solution for hallucinations in domains with structured knowledge representations, offering guarantees that statistical methods cannot match. Although the Licensing Oracle is specifically designed to address hallucinations in fact-based domains, its framework lays the groundwork for truth-constrained generation in future AI systems, providing a new path toward reliable, epistemically grounded models.

</details>


### [102] [MuonAll: Muon Variant for Efficient Finetuning of Large Language Models](https://arxiv.org/abs/2511.06086)
*Saurabh Page,Advait Joshi,S. S. Sonawane*

Main category: cs.CL

TL;DR: 本文介绍了MuonAll优化器，它将所有参数整合到Muon中，通过转换为2D矩阵的方式。在微调实验中，Muon和MuonAll与AdamW在主要基准测试中表现相当。


<details>
  <summary>Details</summary>
Motivation: Muon优化器在语言模型预训练中表现出色，但在微调现有公开预训练模型方面的性能尚未探索。目前Muon与AdamW一起使用，存在将所有参数整合到Muon中的改进空间。

Method: 提出MuonAll方法，通过将参数转换为2D矩阵，将所有参数整合到Muon优化器中。在模型规模达5亿参数的公开语言模型上进行了广泛的微调实验。

Result: Muon和MuonAll在主要基准测试中与AdamW表现相当，证明了它们作为替代优化器的有效性。

Conclusion: Muon和MuonAll是有效的替代优化器选择，作者开源了它们的分布式实现。

Abstract: Muon optimizer has demonstrated robust results in pretraining of language models but its performance in finetuning of existing public pretrained models is not yet explored. Currently, Muon is used along with AdamW introducing a scope of improvement for adopting all parameters inside Muon. We introduce MuonAll, which incorporates all the parameters inside Muon by transforming into 2D matrices. We conduct extensive finetuning experiments across publicly available language models with model sizes upto half billion parameters. Muon and MuonAll perform at par with AdamW across major benchmarks, highlighting their effectiveness as alternative optimizers. We open-source the distributed implementations of Muon and MuonAll, available at https://github.com/Saurabh750/optimizer

</details>


### [103] [Evaluation of retrieval-based QA on QUEST-LOFT](https://arxiv.org/abs/2511.06125)
*Nathan Scales,Nathanael Schärli,Olivier Bousquet*

Main category: cs.CL

TL;DR: 本文分析了RAG在QUEST-LOFT基准上的表现不佳问题，通过结合结构化输出格式和答案重验证，优化后的RAG方法显著优于长上下文方法。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在处理需要跨多个文档检索信息或结合复杂推理的问题时表现不佳，长上下文语言模型也存在类似限制，特别是在QUEST基准上表现差距较大。

Method: 通过深入分析QUEST-LOFT表现不佳的因素，结合包含推理和证据的结构化输出格式，并可选地进行答案重验证来优化RAG方法。

Result: 优化后的RAG方法在QUEST-LOFT基准上显著优于长上下文方法，基于全面人工评估发布了更新数据。

Conclusion: RAG方法可以通过结构化输出和推理验证机制得到显著优化，在处理复杂检索和推理问题时能够超越长上下文方法。

Abstract: Despite the popularity of retrieval-augmented generation (RAG) as a solution for grounded QA in both academia and industry, current RAG methods struggle with questions where the necessary information is distributed across many documents or where retrieval needs to be combined with complex reasoning. Recently, the LOFT study has shown that this limitation also applies to approaches based on long-context language models, with the QUEST benchmark exhibiting particularly large headroom. In this paper, we provide an in-depth analysis of the factors contributing to the poor performance on QUEST-LOFT, publish updated numbers based on a thorough human evaluation, and demonstrate that RAG can be optimized to significantly outperform long-context approaches when combined with a structured output format containing reasoning and evidence, optionally followed by answer re-verification.

</details>


### [104] [Referring Expressions as a Lens into Spatial Language Grounding in Vision-Language Models](https://arxiv.org/abs/2511.06146)
*Akshar Tumu,Varad Shinde,Parisa Kordjamshidi*

Main category: cs.CL

TL;DR: 本文提出使用指代表达理解任务来评估视觉语言模型的空间推理能力，分析模型在目标检测模糊、复杂空间关系和否定表达等情况下的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在空间推理方面存在困难，现有分析主要基于图像描述和视觉问答任务，需要更深入评估模型的空间理解和基础能力。

Method: 使用指代表达理解任务作为评估平台，分析任务特定架构和大型视觉语言模型在目标检测模糊、复杂空间关系和否定表达等场景下的表现。

Result: 所有模型在该任务中都面临挑战，但相对表现取决于底层模型和具体空间语义类别（拓扑、方向、邻近等）。

Conclusion: 研究结果揭示了视觉语言模型在空间推理方面的挑战和不同行为模式，为未来研究方向提供了见解。

Abstract: Spatial Reasoning is an important component of human cognition and is an area in which the latest Vision-language models (VLMs) show signs of difficulty. The current analysis works use image captioning tasks and visual question answering. In this work, we propose using the Referring Expression Comprehension task instead as a platform for the evaluation of spatial reasoning by VLMs. This platform provides the opportunity for a deeper analysis of spatial comprehension and grounding abilities when there is 1) ambiguity in object detection, 2) complex spatial expressions with a longer sentence structure and multiple spatial relations, and 3) expressions with negation ('not'). In our analysis, we use task-specific architectures as well as large VLMs and highlight their strengths and weaknesses in dealing with these specific situations. While all these models face challenges with the task at hand, the relative behaviors depend on the underlying models and the specific categories of spatial semantics (topological, directional, proximal, etc.). Our results highlight these challenges and behaviors and provide insight into research gaps and future directions.

</details>


### [105] [BookAsSumQA: An Evaluation Framework for Aspect-Based Book Summarization via Question Answering](https://arxiv.org/abs/2511.06183)
*Ryuhei Miyazato,Ting-Ruen Wei,Xuyang Wu,Hsin-Tai Wu,Kei Harada*

Main category: cs.CL

TL;DR: 提出了BookAsSumQA框架，通过从叙事知识图谱自动生成特定方面的QA对来评估基于方面的书籍摘要质量，发现RAG方法在长文本上比LLM方法更有效。


<details>
  <summary>Details</summary>
Motivation: 基于方面的摘要能够生成突出文本特定方面的摘要，实现更个性化和有针对性的摘要，但在书籍领域的应用尚未探索，主要由于长文本参考摘要构建困难。

Method: 提出BookAsSumQA评估框架，通过从叙事知识图谱自动生成特定方面的QA对，基于摘要的问答性能来评估摘要质量。

Result: 实验显示，LLM方法在短文本上准确率更高，但随着文档长度增加，RAG方法变得更为有效，对于基于方面的书籍摘要更高效实用。

Conclusion: RAG方法在长文本的基于方面书籍摘要中比LLM方法更有效和实用，BookAsSumQA为评估此类摘要提供了可行框架。

Abstract: Aspect-based summarization aims to generate summaries that highlight specific aspects of a text, enabling more personalized and targeted summaries. However, its application to books remains unexplored due to the difficulty of constructing reference summaries for long text. To address this challenge, we propose BookAsSumQA, a QA-based evaluation framework for aspect-based book summarization. BookAsSumQA automatically generates aspect-specific QA pairs from a narrative knowledge graph to evaluate summary quality based on its question-answering performance. Our experiments using BookAsSumQA revealed that while LLM-based approaches showed higher accuracy on shorter texts, RAG-based methods become more effective as document length increases, making them more efficient and practical for aspect-based book summarization.

</details>


### [106] [Confidence-Guided Stepwise Model Routing for Cost-Efficient Reasoning](https://arxiv.org/abs/2511.06190)
*Sangmook Lee,Dohyung Kim,Hyukhun Koh,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: STEER是一个无需外部模型的细粒度路由框架，通过小模型置信度分数在推理步骤级别进行路由，仅在必要时调用大模型，显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有路由模型在领域迁移时缺乏鲁棒性，且需要昂贵的数据合成技术获取训练标签。STEER旨在开发无需外部模型、领域无关的细粒度路由方法，降低LLM推理成本。

Method: 利用小模型生成推理步骤前的置信度分数进行路由决策，仅在置信度不足时调用大模型，实现步骤级别的动态模型切换。

Result: 在数学推理、多跳问答和规划任务等多样化基准测试中，STEER在保持或提升准确率的同时显著降低推理成本（AIME上准确率提升20%，FLOPs减少48%），优于依赖外部模块的基线方法。

Conclusion: 模型内部置信度作为鲁棒、领域无关的路由信号，为高效LLM部署提供了可扩展的路径。

Abstract: Recent advances in Large Language Models (LLMs) - particularly model scaling and test-time techniques - have greatly enhanced the reasoning capabilities of language models at the expense of higher inference costs. To lower inference costs, prior works train router models or deferral mechanisms that allocate easy queries to a small, efficient model, while forwarding harder queries to larger, more expensive models. However, these trained router models often lack robustness under domain shifts and require expensive data synthesis techniques such as Monte Carlo rollouts to obtain sufficient ground-truth routing labels for training. In this work, we propose Confidence-Guided Stepwise Model Routing for Cost-Efficient Reasoning (STEER), a domain-agnostic framework that performs fine-grained, step-level routing between smaller and larger LLMs without utilizing external models. STEER leverages confidence scores from the smaller model's logits prior to generating a reasoning step, so that the large model is invoked only when necessary. Extensive evaluations using different LLMs on a diverse set of challenging benchmarks across multiple domains such as Mathematical Reasoning, Multi-Hop QA, and Planning tasks indicate that STEER achieves competitive or enhanced accuracy while reducing inference costs (up to +20% accuracy with 48% less FLOPs compared to solely using the larger model on AIME), outperforming baselines that rely on trained external modules. Our results establish model-internal confidence as a robust, domain-agnostic signal for model routing, offering a scalable pathway for efficient LLM deployment.

</details>


### [107] [Explicit Knowledge-Guided In-Context Learning for Early Detection of Alzheimer's Disease](https://arxiv.org/abs/2511.06215)
*Puzhen Su,Yongzhu Miao,Chunxi Guo,Jintao Tang,Shasha Li,Ting Wang*

Main category: cs.CL

TL;DR: 提出EK-ICL框架，通过整合结构化显性知识来增强上下文学习在阿尔茨海默病检测中的推理稳定性和任务对齐，在数据稀缺和分布外条件下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在阿尔茨海默病检测中面临的分布外泛化差、数据稀缺以及上下文学习中任务识别失败、演示选择次优、标签词与任务目标不对齐等问题。

Method: 提出EK-ICL框架，包含三个知识组件：基于小语言模型的置信度分数、解析特征分数用于改进演示选择、标签词替换解决语义不对齐，并采用基于解析的检索策略和集成预测。

Result: 在三个AD数据集上的广泛实验表明，EK-ICL显著优于最先进的微调和上下文学习基线方法。

Conclusion: AD检测中的上下文学习性能对标签语义和任务特定上下文的对齐高度敏感，强调了在低资源临床推理中显性知识的重要性。

Abstract: Detecting Alzheimer's Disease (AD) from narrative transcripts remains a challenging task for large language models (LLMs), particularly under out-of-distribution (OOD) and data-scarce conditions. While in-context learning (ICL) provides a parameter-efficient alternative to fine-tuning, existing ICL approaches often suffer from task recognition failure, suboptimal demonstration selection, and misalignment between label words and task objectives, issues that are amplified in clinical domains like AD detection. We propose Explicit Knowledge In-Context Learners (EK-ICL), a novel framework that integrates structured explicit knowledge to enhance reasoning stability and task alignment in ICL. EK-ICL incorporates three knowledge components: confidence scores derived from small language models (SLMs) to ground predictions in task-relevant patterns, parsing feature scores to capture structural differences and improve demo selection, and label word replacement to resolve semantic misalignment with LLM priors. In addition, EK-ICL employs a parsing-based retrieval strategy and ensemble prediction to mitigate the effects of semantic homogeneity in AD transcripts. Extensive experiments across three AD datasets demonstrate that EK-ICL significantly outperforms state-of-the-art fine-tuning and ICL baselines. Further analysis reveals that ICL performance in AD detection is highly sensitive to the alignment of label semantics and task-specific context, underscoring the importance of explicit knowledge in clinical reasoning under low-resource conditions.

</details>


### [108] [SPA: Achieving Consensus in LLM Alignment via Self-Priority Optimization](https://arxiv.org/abs/2511.06222)
*Yue Huang,Xiangqi Wang,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 本文提出优先级对齐（priority alignment）新范式，通过"可信优先于有用"的严格排序，在满足可信阈值的前提下优化有用性。


<details>
  <summary>Details</summary>
Motivation: 在高风险场景（如自残、法律或医疗查询）中，LLM需要同时具备可信性和有用性，但这两个目标常常冲突。

Method: 引入自优先级对齐（SPA）框架：生成多样化响应，通过自评估和自精炼，应用双重标准去噪消除不一致性并控制方差，构建词典序偏好对，使用不确定性加权对齐损失进行微调。

Result: 在多个基准测试中，SPA在保持安全性的同时提高了有用性，优于强基线方法并保持通用能力。

Conclusion: SPA为关键LLM应用提供了一种可扩展且可解释的对齐策略。

Abstract: In high-stakes scenarios-such as self-harm, legal, or medical queries-LLMs must be both trustworthy and helpful. However, these goals often conflict. We propose priority alignment, a new alignment paradigm that enforces a strict "trustworthy-before-helpful" ordering: optimization of helpfulness is conditioned on first meeting trustworthy thresholds (e.g., harmlessness or honesty). To realize this, we introduce Self-Priority Alignment (SPA)-a fully unsupervised framework that generates diverse responses, self-evaluates them and refines them by the model itself, and applies dual-criterion denoising to remove inconsistency and control variance. From this, SPA constructs lexicographically ordered preference pairs and fine-tunes the model using an uncertainty-weighted alignment loss that emphasizes high-confidence, high-gap decisions. Experiments across multiple benchmarks show that SPA improves helpfulness without compromising safety, outperforming strong baselines while preserving general capabilities. Our results demonstrate that SPA provides a scalable and interpretable alignment strategy for critical LLM applications.

</details>


### [109] [Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records](https://arxiv.org/abs/2511.06230)
*Juntao Li,Haobin Yuan,Ling Luo,Tengxiao Lv,Yan Jiang,Fan Wang,Ping Zhang,Huiyi Lv,Jian Wang,Yuanyuan Sun,Hongfei Lin*

Main category: cs.CL

TL;DR: 本文介绍了CHIP 2025共享任务2竞赛，旨在开发自动推荐出院药物的先进方法，使用真实世界的中文电子健康记录数据构建了CDrugRed数据集，包含5,894条住院记录。


<details>
  <summary>Details</summary>
Motivation: 出院药物推荐在确保治疗连续性、预防再入院和改善慢性代谢疾病患者长期管理方面发挥关键作用。

Method: 构建了CDrugRed高质量数据集，包含5,894条去标识化的住院记录，涉及3,190名中国患者。任务挑战包括药物推荐的多标签性质、异构临床文本和患者特异性治疗计划变异性。

Result: 共有526个团队注册，167个和95个团队分别向阶段A和阶段B排行榜提交了有效结果。表现最佳的团队在最终测试集上获得了最高整体性能，Jaccard得分为0.5102，F1得分为0.6267。

Conclusion: 结果展示了基于先进大语言模型的集成系统在中文电子健康记录药物推荐中的潜力，同时也凸显了应用大语言模型于药物推荐领域仍面临的挑战。

Abstract: Discharge medication recommendation plays a critical role in ensuring treatment continuity, preventing readmission, and improving long-term management for patients with chronic metabolic diseases. This paper present an overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-of-the-art approaches for automatically recommending appro-priate discharge medications using real-world Chinese EHR data. For this task, we constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitalization records from 3,190 patients in China. This task is challenging due to multi-label nature of medication recommendation, het-erogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, demonstrating the potential of advanced large language model (LLM)-based ensemble systems. These re-sults highlight both the promise and remaining challenges of applying LLMs to medication recommendation in Chinese EHRs. The post-evaluation phase remains open at https://tianchi.aliyun.com/competition/entrance/532411/.

</details>


### [110] [Analyzing and Mitigating Negation Artifacts using Data Augmentation for Improving ELECTRA-Small Model Accuracy](https://arxiv.org/abs/2511.06234)
*Mojtaba Noghabaei*

Main category: cs.CL

TL;DR: ELECTRA-small模型在SNLI数据集上微调后，对包含否定的样本分类效果不佳。通过添加强调否定的对比集和对抗样本进行数据增强，提高了模型处理否定样本的准确性，同时不影响整体性能。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在自然语言推理任务中往往通过利用虚假相关性而非真正理解语言现象（如否定）来获得高性能。本研究旨在解决ELECTRA-small模型在SNLI数据集上处理否定时的性能问题。

Method: 通过分析模型在否定样本上的表现，识别出分类困难问题。然后使用强调否定的对比集和对抗样本来增强训练数据。

Result: 针对性的数据增强显著提高了模型在包含否定的样本上的准确性，同时没有对整体性能产生负面影响。

Conclusion: 数据增强是缓解数据集伪影的有效方法，能够改善模型对语言现象（如否定）的理解能力，而不损害整体性能。

Abstract: Pre-trained models for natural language inference (NLI) often achieve high performance on benchmark datasets by using spurious correlations, or dataset artifacts, rather than understanding language touches such as negation. In this project, we investigate the performance of an ELECTRA-small model fine-tuned on the Stanford Natural Language Inference (SNLI) dataset, focusing on its handling of negation. Through analysis, we identify that the model struggles with correctly classifying examples containing negation. To address this, we augment the training data with contrast sets and adversarial examples emphasizing negation. Our results demonstrate that this targeted data augmentation improves the model's accuracy on negation-containing examples without adversely affecting overall performance, therefore mitigating the identified dataset artifact.

</details>


### [111] [HatePrototypes: Interpretable and Transferable Representations for Implicit and Explicit Hate Speech Detection](https://arxiv.org/abs/2511.06391)
*Irina Proskurina,Marc-Antoine Carpentier,Julien Velcin*

Main category: cs.CL

TL;DR: 本文质疑了通过持续预训练或微调来优化仇恨内容审核模型的必要性，提出使用HatePrototypes（从优化的语言模型中提取的类级向量表示）来实现显性和隐性仇恨检测之间的跨任务迁移，仅需每类50个示例即可构建原型，并支持参数无关的早期退出机制。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论基准主要关注针对受保护群体的显性仇恨，而忽视了隐性或间接仇恨（如贬低性比较、排斥或暴力呼吁、微妙歧视语言等）。显性仇恨可通过表面特征捕获，但隐性仇恨需要更深层次的语义处理。

Method: 提出HatePrototypes方法，从优化的仇恨言论检测语言模型中提取类级向量表示，仅需每类50个示例构建原型。使用参数无关的早期退出机制，并验证原型在不同仇恨类型检测任务间的可互换性。

Result: 研究发现这些原型能够在显性和隐性仇恨检测任务之间实现跨任务迁移，原型在不同基准间可互换。参数无关的早期退出机制对两种仇恨类型都有效。

Conclusion: HatePrototypes提供了一种高效且可迁移的仇恨言论检测方法，避免了重复微调的需要，为未来高效可迁移的仇恨言论检测研究提供了支持。

Abstract: Optimization of offensive content moderation models for different types of hateful messages is typically achieved through continued pre-training or fine-tuning on new hate speech benchmarks. However, existing benchmarks mainly address explicit hate toward protected groups and often overlook implicit or indirect hate, such as demeaning comparisons, calls for exclusion or violence, and subtle discriminatory language that still causes harm. While explicit hate can often be captured through surface features, implicit hate requires deeper, full-model semantic processing. In this work, we question the need for repeated fine-tuning and analyze the role of HatePrototypes, class-level vector representations derived from language models optimized for hate speech detection and safety moderation. We find that these prototypes, built from as few as 50 examples per class, enable cross-task transfer between explicit and implicit hate, with interchangeable prototypes across benchmarks. Moreover, we show that parameter-free early exiting with prototypes is effective for both hate types. We release the code, prototype resources, and evaluation scripts to support future research on efficient and transferable hate speech detection.

</details>


### [112] [SugarTextNet: A Transformer-Based Framework for Detecting Sugar Dating-Related Content on Social Media with Context-Aware Focal Loss](https://arxiv.org/abs/2511.06402)
*Lionel Z. Wang,Shihan Ben,Yulu Huang,Simeng Qing*

Main category: cs.CL

TL;DR: SugarTextNet是一个基于Transformer的框架，专门用于检测社交媒体上的糖约会相关内容，通过集成预训练编码器、注意力机制和上下文短语编码器来解决语言模糊和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 糖约会相关内容在主流社交媒体上迅速扩散，引发了严重的社会和监管问题，包括亲密关系的商业化和交易关系的正常化。检测此类内容具有挑战性，因为存在微妙的委婉语、模糊的语言线索以及现实数据中的极端类别不平衡。

Method: SugarTextNet集成了预训练Transformer编码器、基于注意力的线索提取器和上下文短语编码器，以捕捉用户生成文本中的显著和细微特征。为解决类别不平衡问题，引入了上下文感知焦点损失函数，结合焦点损失缩放和上下文加权。

Result: 在新构建的3,067条中文微博帖子数据集上评估，SugarTextNet在多个指标上显著优于传统机器学习模型、深度学习基线和大型语言模型。全面的消融研究证实了每个组件的不可或缺作用。

Conclusion: 研究结果强调了领域特定、上下文感知建模在敏感内容检测中的重要性，并为复杂现实场景中的内容审核提供了稳健解决方案。

Abstract: Sugar dating-related content has rapidly proliferated on mainstream social media platforms, giving rise to serious societal and regulatory concerns, including commercialization of intimate relationships and the normalization of transactional relationships.~Detecting such content is highly challenging due to the prevalence of subtle euphemisms, ambiguous linguistic cues, and extreme class imbalance in real-world data.~In this work, we present SugarTextNet, a novel transformer-based framework specifically designed to identify sugar dating-related posts on social media.~SugarTextNet integrates a pretrained transformer encoder, an attention-based cue extractor, and a contextual phrase encoder to capture both salient and nuanced features in user-generated text.~To address class imbalance and enhance minority-class detection, we introduce Context-Aware Focal Loss, a tailored loss function that combines focal loss scaling with contextual weighting.~We evaluate SugarTextNet on a newly curated, manually annotated dataset of 3,067 Chinese social media posts from Sina Weibo, demonstrating that our approach substantially outperforms traditional machine learning models, deep learning baselines, and large language models across multiple metrics.~Comprehensive ablation studies confirm the indispensable role of each component.~Our findings highlight the importance of domain-specific, context-aware modeling for sensitive content detection, and provide a robust solution for content moderation in complex, real-world scenarios.

</details>


### [113] [Dutch Metaphor Extraction from Cancer Patients' Interviews and Forum Data using LLMs and Human in the Loop](https://arxiv.org/abs/2511.06427)
*Lifeng Han,David Lindevelt,Sander Puts,Erik van Mulligen,Suzan Verberne*

Main category: cs.CL

TL;DR: 该研究从荷兰癌症患者的访谈和在线论坛数据中提取隐喻语言，使用大语言模型探索不同提示策略，并通过人工验证构建了HealthQuote.NL语料库，旨在改善医患沟通和患者护理。


<details>
  <summary>Details</summary>
Motivation: 隐喻语言在医患沟通中发挥重要作用，特别是在癌症患者护理中。研究旨在利用大语言模型从荷兰癌症患者数据中提取隐喻，以支持更好的患者护理、共享决策制定和医患沟通。

Method: 使用两种数据源：癌症患者访谈数据和在线论坛数据；探索大语言模型的不同提示策略，包括思维链推理、少样本学习和自我提示；采用人工参与循环设置验证提取的隐喻。

Result: 构建了名为HealthQuote.NL的语料库，包含经过验证的隐喻提取结果；分享了相关提示和资源。

Conclusion: 提取的隐喻可以支持更好的患者护理，包括改善医患沟通、共享决策制定和患者健康素养，同时为个性化护理路径设计提供信息。

Abstract: Metaphors and metaphorical language (MLs) play an important role in healthcare communication between clinicians, patients, and patients' family members. In this work, we focus on Dutch language data from cancer patients. We extract metaphors used by patients using two data sources: (1) cancer patient storytelling interview data and (2) online forum data, including patients' posts, comments, and questions to professionals. We investigate how current state-of-the-art large language models (LLMs) perform on this task by exploring different prompting strategies such as chain of thought reasoning, few-shot learning, and self-prompting. With a human-in-the-loop setup, we verify the extracted metaphors and compile the outputs into a corpus named HealthQuote.NL. We believe the extracted metaphors can support better patient care, for example shared decision making, improved communication between patients and clinicians, and enhanced patient health literacy. They can also inform the design of personalized care pathways. We share prompts and related resources at https://github.com/aaronlifenghan/HealthQuote.NL

</details>


### [114] [SR-KI: Scalable and Real-Time Knowledge Integration into LLMs via Supervised Attention](https://arxiv.org/abs/2511.06446)
*Bohan Yu,Wei Huang,Kang Liu*

Main category: cs.CL

TL;DR: SR-KI是一种将实时大规模结构化知识库集成到LLM中的新方法，通过编码知识库为键值对并注入KV缓存，采用两阶段训练范式实现端到端推理，支持高效知识压缩和动态更新。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成方法依赖外部检索器和多阶段流水线，性能受限。SR-KI旨在直接在模型潜在空间内完成检索，实现更高效的端到端知识集成。

Method: 使用预训练编码器将知识库编码为键值对并注入LLM的KV缓存；采用两阶段训练：首先定位专用检索层，然后在该层应用基于注意力的损失来监督对相关知识条目的关注。

Result: 在单张A100 40GB GPU上可将多达40K知识库集成到7B LLM中；检索性能强劲，最佳任务Recall@10超过98%，所有任务平均超过88%；问答和知识库ID生成任务表现良好，同时实现高达99.75%的知识压缩。

Conclusion: SR-KI成功实现了在LLM潜在空间内的高效知识检索和集成，支持大规模知识库的端到端处理，为知识增强语言模型提供了新的解决方案。

Abstract: This paper proposes SR-KI, a novel approach for integrating real-time and large-scale structured knowledge bases (KBs) into large language models (LLMs). SR-KI begins by encoding KBs into key-value pairs using a pretrained encoder, and injects them into LLMs' KV cache. Building on this representation, we employ a two-stage training paradigm: first locating a dedicated retrieval layer within the LLM, and then applying an attention-based loss at this layer to explicitly supervise attention toward relevant KB entries. Unlike traditional retrieval-augmented generation methods that rely heavily on the performance of external retrievers and multi-stage pipelines, SR-KI supports end-to-end inference by performing retrieval entirely within the models latent space. This design enables efficient compression of injected knowledge and facilitates dynamic knowledge updates. Comprehensive experiments demonstrate that SR-KI enables the integration of up to 40K KBs into a 7B LLM on a single A100 40GB GPU, and achieves strong retrieval performance, maintaining over 98% Recall@10 on the best-performing task and exceeding 88% on average across all tasks. Task performance on question answering and KB ID generation also demonstrates that SR-KI maintains strong performance while achieving up to 99.75% compression of the injected KBs.

</details>


### [115] [You Had One Job: Per-Task Quantization Using LLMs' Hidden Representations](https://arxiv.org/abs/2511.06516)
*Amit LeVi,Raz Lapid,Rom Himelstein,Yaniv Nemcovsky,Ravid Shwartz Ziv,Avi Mendelson*

Main category: cs.CL

TL;DR: 本文提出了两种任务感知的后训练量化方法TAQ和TAQO，通过分析隐藏表示中的任务相关信号来指导量化，在保持任务性能的同时显著降低模型大小和延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在许多应用中只需要有限能力，但现有量化方法多为任务无关的，忽略了任务特定信号在不同层的分布差异，导致效率低下。

Method: 提出了TAQ（使用隐藏激活的任务条件统计分配位宽）和TAQO（基于直接层敏感性测试分配精度）两种方法，通过小规模校准集识别任务相关层，保持其精度同时激进量化其他层。

Result: 在多个模型上表现优于基线方法，TAQ在Phi-4上领先，TAQO在Llama-3.1、Qwen3和Qwen2.5上领先。例如在Phi-4上达到42.33 EM/50.81 F1，远超AWQ方法，同时保持原始精度损失<1%。

Conclusion: 任务感知的量化方法能够有效识别任务相关层，在显著降低模型复杂度的同时保持任务性能，为高效部署提供了可行方案。

Abstract: Large Language Models (LLMs) excel across diverse tasks, yet many applications require only limited capabilities, making large variants inefficient in memory and latency. Existing approaches often combine distillation and quantization, but most post-training quantization (PTQ) methods are task-agnostic, ignoring how task-specific signals are distributed across layers. In this work, we propose to use hidden representations that encode task-salient signals as a guideline for quantization. In order to fully utilize our innovative idea, this paper compares two new task-aware PTQ methods: Task-Aware Quantization (TAQ), which allocates bitwidths using task-conditioned statistics from hidden activations, and TAQO, which allocates precision based on direct layer sensitivity tests. From a small calibration set, these approaches identify task-relevant layers, preserving their precision while aggressively quantizing the rest. This yields stable task sensitivity profiles and efficient task-specialized models. Across models, TAQ and TAQO outperform the baselines; TAQ leads on Phi-4, while TAQO leads on Llama-3.1, Qwen3, and Qwen2.5. For instances, on Phi-4 it achieves 42.33 EM / 50.81 F1, far surpassing Activation-aware Weight Quantization (AWQ) (2.25 / 7.07), while remaining within < 1.0% of the original accuracy at lower average precision.

</details>


### [116] [Ibom NLP: A Step Toward Inclusive Natural Language Processing for Nigeria's Minority Languages](https://arxiv.org/abs/2511.06531)
*Oluwadara Kalejaiye,Luel Hagos Beyene,David Ifeoluwa Adelani,Mmekut-Mfon Gabriel Edet,Aniefon Daniel Akpan,Eno-Abasi Urua,Anietie Andy*

Main category: cs.CL

TL;DR: 本文介绍了ibom数据集，用于支持尼日利亚四种沿海语言（Anaang、Efik、Ibibio、Oro）的机器翻译和主题分类研究，这些语言在现有主流基准中未被覆盖。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚拥有200多种语言，但NLP研究仅集中在少数几种语言上。由于缺乏文本数据，许多语言无法应用NLP算法，因此需要为未被充分代表的语言创建数据集。

Method: 扩展Flores-200基准到四种沿海尼日利亚语言，并将翻译文本与基于SIB-200分类数据集的主题标签对齐。

Result: 当前LLM在这些语言的机器翻译任务上表现不佳（零样本和少样本设置），但少样本样本能稳步提升主题分类性能。

Conclusion: 需要更多工作来支持尼日利亚未被充分代表的语言，ibom数据集为这些语言的NLP研究提供了基础资源。

Abstract: Nigeria is the most populous country in Africa with a population of more than 200 million people. More than 500 languages are spoken in Nigeria and it is one of the most linguistically diverse countries in the world. Despite this, natural language processing (NLP) research has mostly focused on the following four languages: Hausa, Igbo, Nigerian-Pidgin, and Yoruba (i.e <1% of the languages spoken in Nigeria). This is in part due to the unavailability of textual data in these languages to train and apply NLP algorithms. In this work, we introduce ibom -- a dataset for machine translation and topic classification in four Coastal Nigerian languages from the Akwa Ibom State region: Anaang, Efik, Ibibio, and Oro. These languages are not represented in Google Translate or in major benchmarks such as Flores-200 or SIB-200. We focus on extending Flores-200 benchmark to these languages, and further align the translated texts with topic labels based on SIB-200 classification dataset. Our evaluation shows that current LLMs perform poorly on machine translation for these languages in both zero-and-few shot settings. However, we find the few-shot samples to steadily improve topic classification with more shots.

</details>


### [117] [Rep2Text: Decoding Full Text from a Single LLM Token Representation](https://arxiv.org/abs/2511.06571)
*Haiyan Zhao,Zirui He,Fan Yang,Ali Payani,Mengnan Du*

Main category: cs.CL

TL;DR: Rep2Text框架能够从LLM的最后一个token表示中解码恢复原始输入文本，实验表明在16个token的序列中平均能恢复超过一半的信息，同时保持语义完整性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型取得了显著进展，但其内部机制仍然不透明，本研究旨在探索从单个最后一个token表示中恢复原始输入文本的可能性。

Method: 提出Rep2Text框架，使用可训练的适配器将目标模型的内部表示投影到解码语言模型的嵌入空间，然后自回归地重建输入文本。

Result: 在各种模型组合上的实验表明，平均能从压缩表示中恢复16个token序列中超过一半的信息，同时保持强语义完整性和连贯性。

Conclusion: 研究发现存在信息瓶颈效应：较长序列在token级恢复率下降但仍保持强语义完整性，且框架对分布外医疗数据具有鲁棒泛化能力。

Abstract: Large language models (LLMs) have achieved remarkable progress across diverse tasks, yet their internal mechanisms remain largely opaque. In this work, we address a fundamental question: to what extent can the original input text be recovered from a single last-token representation within an LLM? We propose Rep2Text, a novel framework for decoding full text from last-token representations. Rep2Text employs a trainable adapter that projects a target model's internal representations into the embedding space of a decoding language model, which then autoregressively reconstructs the input text. Experiments on various model combinations (Llama-3.1-8B, Gemma-7B, Mistral-7B-v0.1, Llama-3.2-3B) demonstrate that, on average, over half of the information in 16-token sequences can be recovered from this compressed representation while maintaining strong semantic integrity and coherence. Furthermore, our analysis reveals an information bottleneck effect: longer sequences exhibit decreased token-level recovery while preserving strong semantic integrity. Besides, our framework also demonstrates robust generalization to out-of-distribution medical data.

</details>


### [118] [TabRAG: Tabular Document Retrieval via Structured Language Representations](https://arxiv.org/abs/2511.06582)
*Jacob Si,Mike Qu,Michelle Lee,Yingzhen Li*

Main category: cs.CL

TL;DR: TabRAG是一个针对表格密集型文档的解析式RAG管道，通过结构化语言表示解决现有解析方法在表格数据提取上的性能不佳问题。


<details>
  <summary>Details</summary>
Motivation: 现有解析式RAG方法在提取表格数据时性能不佳，而直接微调嵌入模型的方法计算成本高，需要一种更好的处理表格密集型文档的解决方案。

Method: 提出TabRAG解析管道，使用结构化语言表示来处理表格密集型文档。

Result: TabRAG在生成和检索任务上优于现有的流行解析式方法。

Conclusion: TabRAG为处理表格密集型文档提供了一种有效的解析式RAG解决方案，代码已开源。

Abstract: Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.

</details>


### [119] [MedVoiceBias: A Controlled Study of Audio LLM Behavior in Clinical Decision-Making](https://arxiv.org/abs/2511.06592)
*Zhi Rui Tam,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 研究发现音频大语言模型存在严重的模态偏见，在临床决策中会基于患者声音特征而非医学证据做出判断，导致手术推荐差异高达35%，年龄差异达12%，可能加剧医疗不平等。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从文本界面转向音频交互，可能通过音频中的副语言线索引入新的漏洞，特别是在临床环境中。

Method: 评估了170个临床案例，每个案例合成为36种不同声音配置的语音，涵盖年龄、性别和情感变化，并与相同文本输入进行比较。

Result: 发现严重的模态偏见：音频输入的手术推荐比相同文本输入差异高达35%，一个模型减少了80%的推荐；年龄差异达12%；链式思维提示无法消除年龄偏见；显式推理成功消除了性别偏见；情感影响因识别性能差未被检测到。

Conclusion: 音频大语言模型容易基于患者声音特征而非医学证据做出临床决策，这种缺陷可能加剧医疗不平等，在临床部署前迫切需要开发偏见感知架构。

Abstract: As large language models transition from text-based interfaces to audio interactions in clinical settings, they might introduce new vulnerabilities through paralinguistic cues in audio. We evaluated these models on 170 clinical cases, each synthesized into speech from 36 distinct voice profiles spanning variations in age, gender, and emotion. Our findings reveal a severe modality bias: surgical recommendations for audio inputs varied by as much as 35% compared to identical text-based inputs, with one model providing 80% fewer recommendations. Further analysis uncovered age disparities of up to 12% between young and elderly voices, which persisted in most models despite chain-of-thought prompting. While explicit reasoning successfully eliminated gender bias, the impact of emotion was not detected due to poor recognition performance. These results demonstrate that audio LLMs are susceptible to making clinical decisions based on a patient's voice characteristics rather than medical evidence, a flaw that risks perpetuating healthcare disparities. We conclude that bias-aware architectures are essential and urgently needed before the clinical deployment of these models.

</details>


### [120] [Duality-based Mode Operations and Pyramid Multilayer Mapping for Rhetorical Modes](https://arxiv.org/abs/2511.06601)
*Zi-Niu Wu*

Main category: cs.CL

TL;DR: 本文提出基于对偶性的修辞模式操作和金字塔多层映射框架，通过量化表达多样性和复杂性减少，将静态修辞分类转化为动态可测量系统，为AI系统在修辞推理结构上操作提供路径。


<details>
  <summary>Details</summary>
Motivation: 建立语言学研究和计算建模之间的概念桥梁，使修辞模式在不同领域相互受益，增强多个应用中的认知多样性。

Method: 提出四种对偶性操作（分裂-联合、前向-后向、扩展-缩减、正交对偶）来扩展修辞模式集合，并构建金字塔多层映射框架（从修辞模型层到认知层再到认知层），通过二项式组合学和香农熵分析量化表达多样性和复杂性减少。

Result: 识别出边际修辞位（MRB），定义了衡量表达增长速度的修辞可扩展参数；层次选择相比平面选择显著减少选择不确定性；实现了从静态不可测量修辞分类到动态可测量系统的转变。

Conclusion: 这项工作为未来AI系统不仅操作语言标记，还能在分层修辞推理结构上操作提供了可能路径，连接了语言学、教育学、学术研究和计算研究领域。

Abstract: Rhetorical modes are useful in both academic and non-academic writing, and can be subjects to be studied within linguistic research and computational modeling. Establishing a conceptual bridge among these domains could enable each to benefit from the others. This paper proposes duality-based mode operations (split-unite, forward-backward, expansion-reduction and orthogonal dualities) to expand the set of rhetorical modes, introducing generated modes like combination and generalization, thereby enhancing epistemic diversity across multiple applications. It further presents a pyramid multilayer mapping framework (e.g., three layers from the rhetorical model layer, to cognitive layer, and to epistemic layers) that reduces the resulting cognitive complexity. The degrees of expressive diversity and complexity reduction are quantified through binomial combinatorics and Shannon entropy analysis. A Marginal Rhetorical Bit (MRB) is identified, permitting the definition of a rhetorical-scalable parameter that measures expressive growth speed in bits per stage. A direct entropy measure shows that hierarchical selection over smaller subsets markedly reduces choice uncertainty compared with flat selection across all modes. These considerations appear to transform static and non-measurable rhetorical taxonomies into more dynamic and more measurable systems for discourse design. From this work, it would be possible to identify a pathway for future AI systems to operate not only on language tokens but on layered rhetorical reasoning structures, bridging linguistic, pedagogical, academic, and computational research

</details>


### [121] [Steering LLMs toward Korean Local Speech: Iterative Refinement Framework for Faithful Dialect Translation](https://arxiv.org/abs/2511.06680)
*Keunhyeung Park,Seunguk Yu,Youngbin Kim*

Main category: cs.CL

TL;DR: 提出了方言精炼框架DIA-REFINE，通过翻译-验证-反馈的迭代循环，引导大语言模型生成忠实的目标方言输出，并引入方言保真度评分和目标方言比率来解决n-gram指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 标准语到方言的机器翻译面临挑战，因为大语言模型存在持续的方言差距，且n-gram指标存在评估失真，偏向源文本复制而非真实的方言翻译。

Method: 提出DIA-REFINE框架，使用外部方言分类器进行翻译、验证和反馈的迭代循环；引入方言保真度评分(DFS)量化语言转换，目标方言比率(TDR)衡量方言翻译成功度。

Result: 在韩语方言的实验中，DIA-REFINE持续提升方言保真度；新指标能区分虚假成功案例和真实尝试案例；模型对框架的响应程度不同，结合上下文示例能进一步改进方言表达翻译。

Conclusion: 建立了一个面向目标导向、包容性方言翻译的稳健框架，提供了严格的评估和对模型性能的关键见解。

Abstract: Standard-to-dialect machine translation remains challenging due to a persistent dialect gap in large language models and evaluation distortions inherent in n-gram metrics, which favor source copying over authentic dialect translation. In this paper, we propose the dialect refinement (DIA-REFINE) framework, which guides LLMs toward faithful target dialect outputs through an iterative loop of translation, verification, and feedback using external dialect classifiers. To address the limitations of n-gram-based metrics, we introduce the dialect fidelity score (DFS) to quantify linguistic shift and the target dialect ratio (TDR) to measure the success of dialect translation. Experiments on Korean dialects across zero-shot and in-context learning baselines demonstrate that DIA-REFINE consistently enhances dialect fidelity. The proposed metrics distinguish between False Success cases, where high n-gram scores obscure failures in dialectal translation, and True Attempt cases, where genuine attempts at dialectal translation yield low n-gram scores. We also observed that models exhibit varying degrees of responsiveness to the framework, and that integrating in-context examples further improves the translation of dialectal expressions. Our work establishes a robust framework for goal-directed, inclusive dialect translation, providing both rigorous evaluation and critical insights into model performance.

</details>


### [122] [Textual Self-attention Network: Test-Time Preference Optimization through Textual Gradient-based Attention](https://arxiv.org/abs/2511.06682)
*Shibing Mo,Haoyang Ruan,Kai Wu,Jing Liu*

Main category: cs.CL

TL;DR: TSAN是一种无需参数更新的测试时偏好优化新范式，通过纯自然语言模拟自注意力机制，分析多个候选回答并综合其优势来生成更优结果。


<details>
  <summary>Details</summary>
Motivation: 现有测试时方法通常只对单个候选回答进行评判和修订，缺乏系统分析、权衡和综合多个候选回答优势的机制，而不同回答可能在清晰度、事实准确性或语气等方面各有所长。

Method: TSAN将多个候选回答格式化为文本键和值，使用基于LLM的注意力模块评估其相关性，并在学习到的文本注意力指导下综合各候选回答的优势生成新的偏好对齐响应，整个过程在文本梯度空间中进行迭代优化。

Result: 实证评估表明，在基础SFT模型上仅进行三次测试时迭代，TSAN就超越了Llama-3.1-70B-Instruct等监督模型，并超越了当前最先进的测试时对齐方法。

Conclusion: TSAN提供了一种无需参数更新的有效测试时偏好优化方法，能够通过综合多个候选回答的优势生成更优的对齐响应，且过程具有可解释性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable generalization capabilities, but aligning their outputs with human preferences typically requires expensive supervised fine-tuning. Recent test-time methods leverage textual feedback to overcome this, but they often critique and revise a single candidate response, lacking a principled mechanism to systematically analyze, weigh, and synthesize the strengths of multiple promising candidates. Such a mechanism is crucial because different responses may excel in distinct aspects (e.g., clarity, factual accuracy, or tone), and combining their best elements may produce a far superior outcome. This paper proposes the Textual Self-Attention Network (TSAN), a new paradigm for test-time preference optimization that requires no parameter updates. TSAN emulates self-attention entirely in natural language to overcome this gap: it analyzes multiple candidates by formatting them into textual keys and values, weighs their relevance using an LLM-based attention module, and synthesizes their strengths into a new, preference-aligned response under the guidance of the learned textual attention. This entire process operates in a textual gradient space, enabling iterative and interpretable optimization. Empirical evaluations demonstrate that with just three test-time iterations on a base SFT model, TSAN outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the current state-of-the-art test-time alignment method by effectively leveraging multiple candidate solutions.

</details>


### [123] [Sensitivity of Small Language Models to Fine-tuning Data Contamination](https://arxiv.org/abs/2511.06763)
*Nicy Scaria,Silvester John Joseph Kennedy,Deepak Subramani*

Main category: cs.CL

TL;DR: 本文系统研究了23个小语言模型（270M到4B参数）在指令微调过程中对数据污染的敏感性，发现句法变换（如字符和单词反转）会导致灾难性性能下降，而语义变换（如无关和反事实响应）表现出不同的阈值行为和更强的语言能力韧性。


<details>
  <summary>Details</summary>
Motivation: 小语言模型越来越多地部署在资源受限环境中，但其在指令微调过程中对数据污染的行为鲁棒性仍知之甚少。需要系统研究SLMs对数据污染的敏感性。

Method: 通过测量23个SLMs对句法变换（字符和单词反转）和语义变换（无关和反事实响应）的敏感性，每种变换在25%、50%、75%和100%的污染水平下进行测试。

Result: 发现根本性的不对称脆弱性模式：句法变换导致灾难性性能下降，字符反转在所有模型中产生近乎完全失败；语义变换表现出不同的阈值行为和更强的核心语言能力韧性。发现"能力诅咒"现象，即更大、更有能力的模型更容易学习语义污染。

Conclusion: 研究建立了三个核心贡献：SLMs对句法模式污染的过度脆弱性实证证据、句法和语义变换之间不对称敏感性模式的识别，以及污染鲁棒性评估的系统评估协议。这些发现对当前部署具有直接意义，表明当前鲁棒性假设可能不适用于较小模型，并强调了污染感知训练协议的必要性。

Abstract: Small Language Models (SLMs) are increasingly being deployed in resource-constrained environments, yet their behavioral robustness to data contamination during instruction tuning remains poorly understood. We systematically investigate the contamination sensitivity of 23 SLMs (270M to 4B parameters) across multiple model families by measuring susceptibility to syntactic and semantic transformation types during instruction tuning: syntactic transformations (character and word reversal) and semantic transformations (irrelevant and counterfactual responses), each applied at contamination levels of 25\%, 50\%, 75\%, and 100\%. Our results reveal fundamental asymmetries in vulnerability patterns: syntactic transformations cause catastrophic performance degradation, with character reversal producing near-complete failure across all models regardless of size or family, while semantic transformations demonstrate distinct threshold behaviors and greater resilience in core linguistic capabilities. Critically, we discover a ``\textit{capability curse}" where larger, more capable models become more susceptible to learning semantic corruptions, effectively following harmful instructions more readily, while our analysis of base versus instruction-tuned variants reveals that alignment provides inconsistent robustness benefits, sometimes even reducing resilience. Our work establishes three core contributions: (1) empirical evidence of SLMs' disproportionate vulnerability to syntactic pattern contamination, (2) identification of asymmetric sensitivity patterns between syntactic and semantic transformations, and (3) systematic evaluation protocols for contamination robustness assessment. These findings have immediate deployment implications, suggesting that current robustness assumptions may not hold for smaller models and highlighting the need for contamination-aware training protocols.

</details>


### [124] [SAFENLIDB: A Privacy-Preserving Safety Alignment Framework for LLM-based Natural Language Database Interfaces](https://arxiv.org/abs/2511.06778)
*Ruiheng Liu,XiaoBing Chen,Jinyu Zhang,Qiongwen Zhang,Yu Zhang,Bailong Yang*

Main category: cs.CL

TL;DR: SafeNlidb是一个针对LLM数据库自然语言接口的隐私安全对齐框架，通过自动生成混合思维链数据和安全推理优化，解决LLM在数据库查询中可能泄露敏感信息的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在数据库自然语言接口中的广泛应用，出现了严重的隐私和安全问题，LLM可能在交互过程中无意泄露数据库机密内容或被攻击者利用来窃取数据。现有方法难以应对复杂的推理攻击，误报率高，且影响SQL查询可靠性。

Method: 提出SafeNlidb框架，包含自动生成混合思维链交互数据的管道，结合隐式安全推理和SQL生成；引入推理预热和交替偏好优化来克服DPO的多偏好振荡问题，使LLM能够通过细粒度推理生成安全感知的SQL，无需人工标注偏好数据。

Result: 大量实验表明，该方法优于更大规模的LLM和理想设置基线，在保持高实用性的同时实现了显著的安全改进。

Conclusion: SafeNlidb框架有效解决了LLM数据库自然语言接口中的隐私安全问题，通过自动化的安全推理优化实现了安全性和实用性的平衡。

Abstract: The rapid advancement of Large Language Models (LLMs) has driven significant progress in Natural Language Interface to Database (NLIDB). However, the widespread adoption of LLMs has raised critical privacy and security concerns. During interactions, LLMs may unintentionally expose confidential database contents or be manipulated by attackers to exfiltrate data through seemingly benign queries. While current efforts typically rely on rule-based heuristics or LLM agents to mitigate this leakage risk, these methods still struggle with complex inference-based attacks, suffer from high false positive rates, and often compromise the reliability of SQL queries. To address these challenges, we propose \textsc{SafeNlidb}, a novel privacy-security alignment framework for LLM-based NLIDB. The framework features an automated pipeline that generates hybrid chain-of-thought interaction data from scratch, seamlessly combining implicit security reasoning with SQL generation. Additionally, we introduce reasoning warm-up and alternating preference optimization to overcome the multi-preference oscillations of Direct Preference Optimization (DPO), enabling LLMs to produce security-aware SQL through fine-grained reasoning without the need for human-annotated preference data. Extensive experiments demonstrate that our method outperforms both larger-scale LLMs and ideal-setting baselines, achieving significant security improvements while preserving high utility.WARNING: This work may contain content that is offensive and harmful!

</details>


### [125] [Learning to Focus: Focal Attention for Selective and Scalable Transformers](https://arxiv.org/abs/2511.06818)
*Dhananjay Ram,Wei Xia,Stefano Soatto*

Main category: cs.CL

TL;DR: 提出Focal Attention方法，通过控制softmax温度来锐化注意力分布，使模型能更好地聚焦相关token，在模型规模、训练数据和上下文长度方面比标准transformer更具扩展性。


<details>
  <summary>Details</summary>
Motivation: 标准softmax注意力在长上下文中会产生噪声概率分布，影响各层特征选择的有效性。

Method: 通过控制softmax温度来锐化注意力分布，温度可以作为固定超参数或训练中的可学习参数。

Result: 在相同准确率下可减少42%参数或33%训练数据；在长上下文任务中获得17%到82%的相对改进。

Conclusion: Focal Attention是一种简单有效的注意力机制改进，在多种基准测试中表现出色，特别适用于长上下文场景。

Abstract: Attention is a core component of transformer architecture, whether encoder-only, decoder-only, or encoder-decoder model. However, the standard softmax attention often produces noisy probability distribution, which can impair effective feature selection at every layer of these models, particularly for long contexts. We propose Focal Attention, a simple yet effective modification that sharpens the attention distribution by controlling the softmax temperature, either as a fixed hyperparameter or as a learnable parameter during training. This sharpening enables the model to concentrate on the most relevant tokens while suppressing irrelevant ones. Empirically, Focal Attention scales more favorably than standard transformer with respect to model size, training data, and context length. Across diverse benchmarks, it achieves the same accuracy with up to 42% fewer parameters or 33% less training data. On long-context tasks, it delivers substantial relative improvements ranging from 17% to 82%, demonstrating its effectiveness in real world applications.

</details>


### [126] [Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection](https://arxiv.org/abs/2511.06826)
*Puzhen Su,Haoran Yin,Yongzhu Miao,Jintao Tang,Shasha Li,Ting Wang*

Main category: cs.CL

TL;DR: DA4ICL是一个用于阿尔茨海默病检测的演示中心锚定框架，通过多样化对比检索扩展上下文宽度，并通过投影向量锚定在每个Transformer层深化信号，显著提升了ICL和任务向量方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在阿尔茨海默病检测任务中面临挑战：预训练很少覆盖这种分布外任务，且所有转录演示描述相同场景，导致上下文高度同质化，限制了模型的任务认知和上下文感知能力。

Method: 提出DA4ICL框架，包含多样化对比检索(DCR)扩展上下文宽度，以及投影向量锚定(PVA)在每个Transformer层深化每个演示的信号。

Result: 在三个AD基准测试中，DA4ICL相比ICL和任务向量基线实现了大幅稳定的性能提升。

Conclusion: DA4ICL为细粒度、分布外和低资源LLM适应开辟了新范式，通过联合扩展上下文宽度和深化信号来改善上下文学习效果。

Abstract: Detecting Alzheimer's disease (AD) from narrative transcripts challenges large language models (LLMs): pre-training rarely covers this out-of-distribution task, and all transcript demos describe the same scene, producing highly homogeneous contexts. These factors cripple both the model's built-in task knowledge (\textbf{task cognition}) and its ability to surface subtle, class-discriminative cues (\textbf{contextual perception}). Because cognition is fixed after pre-training, improving in-context learning (ICL) for AD detection hinges on enriching perception through better demonstration (demo) sets. We demonstrate that standard ICL quickly saturates, its demos lack diversity (context width) and fail to convey fine-grained signals (context depth), and that recent task vector (TV) approaches improve broad task adaptation by injecting TV into the LLMs' hidden states (HSs), they are ill-suited for AD detection due to the mismatch of injection granularity, strength and position. To address these bottlenecks, we introduce \textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands context width via \emph{\textbf{Diverse and Contrastive Retrieval}} (DCR) and deepens each demo's signal via \emph{\textbf{Projected Vector Anchoring}} (PVA) at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large, stable gains over both ICL and TV baselines, charting a new paradigm for fine-grained, OOD and low-resource LLM adaptation.

</details>


### [127] [CLiFT-ASR: A Cross-Lingual Fine-Tuning Framework for Low-Resource Taiwanese Hokkien Speech Recognition](https://arxiv.org/abs/2511.06860)
*Hung-Yang Sung,Chien-Chun Wang,Kuan-Tang Huang,Tien-Hong Lo,Yu-Sheng Tsao,Yung-Chang Hsu,Berlin Chen*

Main category: cs.CL

TL;DR: CLiFT-ASR是一个针对低资源语言（如台湾闽南语）的跨语言语音识别框架，通过两阶段渐进式微调，结合拼音和汉字转录，显著降低了字符错误率。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言如台湾闽南语语音识别的困难，传统方法在汉字转录上无法捕捉详细语音和声调信息，而仅使用罗马化又缺乏词汇和句法覆盖。

Method: 基于普通话HuBERT模型，采用两阶段渐进式微调：第一阶段从Tai-lo拼音注释学习声学和声调表示，第二阶段从汉字转录捕获词汇和句法。

Result: 在TAT-MOE语料库上的实验表明，与强基线相比，CLiFT-ASR实现了24.88%的相对字符错误率降低。

Conclusion: CLiFT-ASR为台湾闽南语语音识别提供了有效且参数高效的解决方案，并具有扩展到其他低资源语言场景的潜力。

Abstract: Automatic speech recognition (ASR) for low-resource languages such as Taiwanese Hokkien is difficult due to the scarcity of annotated data. However, direct fine-tuning on Han-character transcriptions often fails to capture detailed phonetic and tonal cues, while training only on romanization lacks lexical and syntactic coverage. In addition, prior studies have rarely explored staged strategies that integrate both annotation types. To address this gap, we present CLiFT-ASR, a cross-lingual fine-tuning framework that builds on Mandarin HuBERT models and progressively adapts them to Taiwanese Hokkien. The framework employs a two-stage process in which it first learns acoustic and tonal representations from phonetic Tai-lo annotations and then captures vocabulary and syntax from Han-character transcriptions. This progressive adaptation enables effective alignment between speech sounds and orthographic structures. Experiments on the TAT-MOE corpus demonstrate that CLiFT-ASR achieves a 24.88\% relative reduction in character error rate (CER) compared with strong baselines. The results indicate that CLiFT-ASR provides an effective and parameter-efficient solution for Taiwanese Hokkien ASR and that it has potential to benefit other low-resource language scenarios.

</details>


### [128] [EduGuardBench: A Holistic Benchmark for Evaluating the Pedagogical Fidelity and Adversarial Safety of LLMs as Simulated Teachers](https://arxiv.org/abs/2511.06890)
*Yilin Jiang,Mingzi Zhang,Xuanyu Yin,Sheng Jin,Suyu Lu,Zuocan Ying,Zengyi Yu,Xiangjie Kong*

Main category: cs.CL

TL;DR: 提出了EduGuardBench基准，用于评估AI教师模型的专业保真度和教育场景中的伦理安全性，发现模型性能两极分化，推理导向模型保真度更高，但普遍存在能力不足问题，并揭示了教育转换效应和规模悖论等新发现。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法衡量AI教师模型在角色扮演保真度和教育特有危害方面的表现，需要开发综合评估专业能力和伦理安全性的新基准。

Method: 提出双组件基准EduGuardBench，使用角色扮演保真度分数评估专业能力，通过基于角色的对抗提示诊断教育特有危害和学术不端行为，采用攻击成功率、拒绝质量三级评估等指标。

Result: 对14个领先模型的测试显示性能两极分化，推理导向模型保真度更高但能力不足仍是主要失败模式，发现中规模模型最脆弱的反直觉规模悖论，识别出教育转换效应——最安全模型能将有害请求转化为教学机会。

Conclusion: EduGuardBench提供了可复现的框架，超越孤立知识测试，实现专业、伦理和教学对齐的全面评估，为教育领域可信AI部署揭示了关键动态机制。

Abstract: Large Language Models for Simulating Professions (SP-LLMs), particularly as teachers, are pivotal for personalized education. However, ensuring their professional competence and ethical safety is a critical challenge, as existing benchmarks fail to measure role-playing fidelity or address the unique teaching harms inherent in educational scenarios. To address this, we propose EduGuardBench, a dual-component benchmark. It assesses professional fidelity using a Role-playing Fidelity Score (RFS) while diagnosing harms specific to the teaching profession. It also probes safety vulnerabilities using persona-based adversarial prompts targeting both general harms and, particularly, academic misconduct, evaluated with metrics including Attack Success Rate (ASR) and a three-tier Refusal Quality assessment. Our extensive experiments on 14 leading models reveal a stark polarization in performance. While reasoning-oriented models generally show superior fidelity, incompetence remains the dominant failure mode across most models. The adversarial tests uncovered a counterintuitive scaling paradox, where mid-sized models can be the most vulnerable, challenging monotonic safety assumptions. Critically, we identified a powerful Educational Transformation Effect: the safest models excel at converting harmful requests into teachable moments by providing ideal Educational Refusals. This capacity is strongly negatively correlated with ASR, revealing a new dimension of advanced AI safety. EduGuardBench thus provides a reproducible framework that moves beyond siloed knowledge tests toward a holistic assessment of professional, ethical, and pedagogical alignment, uncovering complex dynamics essential for deploying trustworthy AI in education. See https://github.com/YL1N/EduGuardBench for Materials.

</details>


### [129] [RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation](https://arxiv.org/abs/2511.06899)
*Haofeng Wang,Yu Zhang*

Main category: cs.CL

TL;DR: 提出了RPTS评估指标和RPTS-Eval基准，用于评估大视觉语言模型的多模态推理过程，通过树形结构分析推理步骤的忠实度，并考察模态间关系对推理的影响。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注答案正确性而忽略推理过程评估，无法识别错误推理导致正确答案的情况，且未考虑模态间关系对推理的影响。

Method: 构建推理过程树结构，利用层次信息为每个推理步骤分配加权忠实度分数，动态调整权重来定位推理失败点；创建RPTS-Eval基准包含374张图像和390个推理实例。

Result: 评估了代表性LVLMs（如GPT4o、Llava-Next），揭示了它们在多模态推理中的局限性，并突出了开源与闭源商业模型之间的差异。

Conclusion: RPTS基准将促进多模态推理领域的研究进展，为模型推理过程提供更全面的评估框架。

Abstract: Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have shown impressive performance on various multimodal benchmarks. However, most of these benchmarks evaluate models primarily through multiple-choice or short-answer formats, which do not take the reasoning process into account. Although some benchmarks assess the reasoning process, their methods are often overly simplistic and only examine reasoning when answers are incorrect. This approach overlooks scenarios where flawed reasoning leads to correct answers. In addition, these benchmarks do not consider the impact of intermodal relationships on reasoning. To address this issue, we propose the Reasoning Process Tree Score (RPTS), a tree structure-based metric to assess reasoning processes. Specifically, we organize the reasoning steps into a reasoning tree and leverage its hierarchical information to assign weighted faithfulness scores to each reasoning step. By dynamically adjusting these weights, RPTS not only evaluates the overall correctness of the reasoning, but also pinpoints where the model fails in the reasoning. To validate RPTS in real-world multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374 images and 390 reasoning instances. Each instance includes reliable visual-textual clues that serve as leaf nodes of the reasoning tree. Furthermore, we define three types of intermodal relationships to investigate how intermodal interactions influence the reasoning process. We evaluated representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in multimodal reasoning and highlighting the differences between open-source and closed-source commercial LVLMs. We believe that this benchmark will contribute to the advancement of research in the field of multimodal reasoning.

</details>


### [130] [HLPD: Aligning LLMs to Human Language Preference for Machine-Revised Text Detection](https://arxiv.org/abs/2511.06942)
*Fangqi Dai,Xingjian Jiang,Zizhuang Deng*

Main category: cs.CL

TL;DR: 本文提出HLPD方法，通过奖励对齐优化使评分模型更偏向人类写作风格，从而在对抗性多任务场景中更有效地检测机器修订文本，相比现有方法有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLMs生成可信内容带来的错误信息和社会问题，需要开发高效可靠的方法识别文本来源。现有方法在面对先进LLM输出或对抗性多任务机器修订文本时表现不佳，特别是在黑盒设置下。

Method: 提出HLPD方法，基于人类写作具有独特风格模式的假设，采用基于奖励的对齐过程HLPO，将评分模型的token分布转向人类写作风格，使其对人类写作更敏感。

Result: 在检测GPT系列模型修订文本时，HLPD相比ImBD相对提升15.11% AUROC，比Fast-DetectGPT提升45.56%。在先进LLMs生成文本上，HLPD达到最高平均AUROC，分别超过ImBD 5.53%和Fast-DetectGPT 34.14%。

Conclusion: HLPD通过奖励对齐优化有效提升了机器修订文本的检测性能，在对抗性多任务场景中表现出色，为解决LLMs生成内容的溯源问题提供了有效方案。

Abstract: To prevent misinformation and social issues arising from trustworthy-looking content generated by LLMs, it is crucial to develop efficient and reliable methods for identifying the source of texts. Previous approaches have demonstrated exceptional performance in detecting texts fully generated by LLMs. However, these methods struggle when confronting more advanced LLM output or text with adversarial multi-task machine revision, especially in the black-box setting, where the generating model is unknown. To address this challenge, grounded in the hypothesis that human writing possesses distinctive stylistic patterns, we propose Human Language Preference Detection (HLPD). HLPD employs a reward-based alignment process, Human Language Preference Optimization (HLPO), to shift the scoring model's token distribution toward human-like writing, making the model more sensitive to human writing, therefore enhancing the identification of machine-revised text. We test HLPD in an adversarial multi-task evaluation framework that leverages a five-dimensional prompt generator and multiple advanced LLMs to create diverse revision scenarios. When detecting texts revised by GPT-series models, HLPD achieves a 15.11% relative improvement in AUROC over ImBD, surpassing Fast-DetectGPT by 45.56%. When evaluated on texts generated by advanced LLMs, HLPD achieves the highest average AUROC, exceeding ImBD by 5.53% and Fast-DetectGPT by 34.14%. Code will be made available at https://github.com/dfq2021/HLPD.

</details>


### [131] [SCOPE: Intrinsic Semantic Space Control for Mitigating Copyright Infringement in LLMs](https://arxiv.org/abs/2511.07001)
*Zhenliang Zhang,Xinyu Hu,Xiaojun Wan*

Main category: cs.CL

TL;DR: SCOPE是一种无需参数更新或外部过滤器的推理时方法，通过稀疏自编码器将隐藏状态投影到高维语义空间，识别版权敏感子空间并在解码时钳制其激活，有效减轻版权侵权而不影响模型通用性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型有时会无意中复制受版权保护的内容，给下游应用带来法律风险。现有推理时防御方法主要关注表层token匹配，依赖外部阻止列表或过滤器，增加了部署复杂性且可能忽略语义层面的泄露。

Method: 将版权侵权缓解重新定义为内在语义空间控制，使用稀疏自编码器将隐藏状态投影到高维近单语义空间，识别版权敏感子空间并在解码过程中钳制其激活。

Result: 在广泛认可的基准测试中，SCOPE有效减轻了版权侵权，同时不降低模型的通用效用。可解释性分析证实隔离的子空间捕获了高级语义信息。

Conclusion: SCOPE提供了一种无需外部过滤器的推理时版权保护方法，通过语义空间控制有效缓解版权侵权风险，同时保持模型性能。

Abstract: Large language models sometimes inadvertently reproduce passages that are copyrighted, exposing downstream applications to legal risk. Most existing studies for inference-time defences focus on surface-level token matching and rely on external blocklists or filters, which add deployment complexity and may overlook semantically paraphrased leakage. In this work, we reframe copyright infringement mitigation as intrinsic semantic-space control and introduce SCOPE, an inference-time method that requires no parameter updates or auxiliary filters. Specifically, the sparse autoencoder (SAE) projects hidden states into a high-dimensional, near-monosemantic space; benefiting from this representation, we identify a copyright-sensitive subspace and clamp its activations during decoding. Experiments on widely recognized benchmarks show that SCOPE mitigates copyright infringement without degrading general utility. Further interpretability analyses confirm that the isolated subspace captures high-level semantics.

</details>


### [132] [A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided Judge-Corrector System for Multimodal Machine Translation](https://arxiv.org/abs/2511.07010)
*Siddharth Betala,Kushan Raj,Vipul Betala,Rohan Saswade*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段方法，通过自动错误检测和修正来解决训练数据质量问题，然后进行参数高效微调，在英语到印度语言翻译任务中取得了BLEU分数的提升。


<details>
  <summary>Details</summary>
Motivation: 解决训练数据中的质量问题，包括翻译错误和视觉歧义问题，以提高英语到印度语言翻译的性能。

Method: 采用视觉增强的评判-修正管道，利用多模态语言模型系统识别和修正训练数据中的翻译错误。评判组件将翻译分为正确、视觉歧义或错误翻译三类，然后由专门的修正器处理：GPT-4o-mini重新生成需要视觉消歧的标题，IndicTrans2重新翻译纯翻译质量问题。随后使用LoRA对IndicTrans2模型进行参数高效微调。

Result: 自动化管道处理了28,928个跨四种语言的训练样本，平均修正了每种语言17.1%的标题。在修正数据上训练带来了持续改进：英语-孟加拉语在评估集上BLEU分数提升+1.30（42.00→43.30），挑战集+0.70（44.90→45.60）；英语-奥里亚语评估集+0.60（41.00→41.60）；英语-印地语挑战集+0.10（53.90→54.00）。

Conclusion: 提出的两阶段方法通过自动数据修正和参数高效微调，有效提升了英语到印度语言翻译的质量，证明了数据质量改进对翻译性能的重要性。

Abstract: In this paper, we describe our system under the team name BLEU Monday for the English-to-Indic Multimodal Translation Task at WAT 2025. We participate in the text-only translation tasks for English-Hindi, English-Bengali, English-Malayalam, and English-Odia language pairs. We present a two-stage approach that addresses quality issues in the training data through automated error detection and correction, followed by parameter-efficient model fine-tuning.
  Our methodology introduces a vision-augmented judge-corrector pipeline that leverages multimodal language models to systematically identify and correct translation errors in the training data. The judge component classifies translations into three categories: correct, visually ambiguous (requiring image context), or mistranslated (poor translation quality). Identified errors are routed to specialized correctors: GPT-4o-mini regenerates captions requiring visual disambiguation, while IndicTrans2 retranslates cases with pure translation quality issues. This automated pipeline processes 28,928 training examples across four languages, correcting an average of 17.1% of captions per language.
  We then apply Low-Rank Adaptation (LoRA) to fine-tune the IndicTrans2 en-indic 200M distilled model on both original and corrected datasets. Training on corrected data yields consistent improvements, with BLEU score gains of +1.30 for English-Bengali on the evaluation set (42.00 -> 43.30) and +0.70 on the challenge set (44.90 -> 45.60), +0.60 for English-Odia on the evaluation set (41.00 -> 41.60), and +0.10 for English-Hindi on the challenge set (53.90 -> 54.00).

</details>


### [133] [Multilingual Lexical Feature Analysis of Spoken Language for Predicting Major Depression Symptom Severity](https://arxiv.org/abs/2511.07011)
*Anastasiia Tokareva,Judith Dineley,Zoe Firth,Pauline Conde,Faith Matcham,Sara Siddi,Femke Lamers,Ewan Carr,Carolin Oetzmann,Daniel Leightley,Yuezhou Zhang,Amos A. Folarin,Josep Maria Haro,Brenda W. J. H. Penninx,Raquel Bailon,Srinivasan Vairavan,Til Wykes,Richard J. B. Dobson,Vaibhav A. Narayan,Matthew Hotopf,Nicholas Cummins,The RADAR-CNS Consortium*

Main category: cs.CL

TL;DR: 本研究分析了来自英国、荷兰和西班牙的5,836条语音记录，探索可解释的词汇特征与重度抑郁症症状严重程度的关系。研究发现英语数据中症状严重程度与词汇多样性、绝对主义语言等7个特征相关，但词汇特征和向量嵌入的预测能力接近随机水平。


<details>
  <summary>Details</summary>
Motivation: 利用移动设备采集的口语数据有潜力对重度抑郁症进行客观、定期的症状严重程度评估和早期复发检测，但现有研究主要在非临床横断面样本中使用复杂的机器学习方法，可解释性有限。

Method: 对RADAR-MDD研究中的纵向语音数据和PHQ-8评估进行探索性分析，使用线性混合效应模型识别与MDD症状严重程度相关的可解释词汇特征，并测试四种回归机器学习模型的预测性能。

Result: 在英语数据中，MDD症状严重程度与7个特征相关，包括词汇多样性测量和绝对主义语言；在荷兰语中，与句子词数和积极词频相关；在西班牙语记录中未观察到关联。词汇特征和向量嵌入在所有语言中的预测能力接近随机水平。

Conclusion: 为了理解词汇标记在临床研究和实践中的价值，需要在更大样本中使用改进的协议和能够解释个体内和个体间语言变异的机器学习模型进行跨语言研究。

Abstract: Background: Captured between clinical appointments using mobile devices, spoken language has potential for objective, more regular assessment of symptom severity and earlier detection of relapse in major depressive disorder. However, research to date has largely been in non-clinical cross-sectional samples of written language using complex machine learning (ML) approaches with limited interpretability.
  Methods: We describe an initial exploratory analysis of longitudinal speech data and PHQ-8 assessments from 5,836 recordings of 586 participants in the UK, Netherlands, and Spain, collected in the RADAR-MDD study. We sought to identify interpretable lexical features associated with MDD symptom severity with linear mixed-effects modelling. Interpretable features and high-dimensional vector embeddings were also used to test the prediction performance of four regressor ML models.
  Results: In English data, MDD symptom severity was associated with 7 features including lexical diversity measures and absolutist language. In Dutch, associations were observed with words per sentence and positive word frequency; no associations were observed in recordings collected in Spain. The predictive power of lexical features and vector embeddings was near chance level across all languages.
  Limitations: Smaller samples in non-English speech and methodological choices, such as the elicitation prompt, may have also limited the effect sizes observable. A lack of NLP tools in languages other than English restricted our feature choice.
  Conclusion: To understand the value of lexical markers in clinical research and practice, further research is needed in larger samples across several languages using improved protocols, and ML models that account for within- and between-individual variations in language.

</details>


### [134] [Llama-Embed-Nemotron-8B: A Universal Text Embedding Model for Multilingual and Cross-Lingual Tasks](https://arxiv.org/abs/2511.07025)
*Yauhen Babakhin,Radek Osmulski,Ronay Ak,Gabriel Moreira,Mengyao Xu,Benedikt Schifferer,Bo Liu,Even Oldridge*

Main category: cs.CL

TL;DR: llama-embed-nemotron-8b是一个开源的文本嵌入模型，在MMTEB基准测试中达到最先进性能，支持多语言和用户自定义指令。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型训练数据和方法不透明的问题，开发完全开源的嵌入模型并提供详细的消融研究。

Method: 使用包含1610万个查询-文档对的数据集（770万公开数据和840万合成数据），采用对比损失、合成数据生成和模型融合等技术。

Result: 在检索、分类和语义文本相似性等所有主要嵌入任务中表现优异，特别是在低资源语言和跨语言场景中。

Conclusion: 该模型结合了顶级性能、广泛适用性和用户驱动的灵活性，可作为通用文本嵌入解决方案。

Abstract: We introduce llama-embed-nemotron-8b, an open-weights text embedding model that achieves state-of-the-art performance on the Multilingual Massive Text Embedding Benchmark (MMTEB) leaderboard as of October 21, 2025. While recent models show strong performance, their training data or methodologies are often not fully disclosed. We aim to address this by developing a fully open-source model, publicly releasing its weights and detailed ablation studies, and planning to share the curated training datasets. Our model demonstrates superior performance across all major embedding tasks -- including retrieval, classification and semantic textual similarity (STS) -- and excels in challenging multilingual scenarios, such as low-resource languages and cross-lingual setups. This state-of-the-art performance is driven by a novel data mix of 16.1 million query-document pairs, split between 7.7 million samples from public datasets and 8.4 million synthetically generated examples from various open-weight LLMs. One of our key contributions is a detailed ablation study analyzing core design choices, including a comparison of contrastive loss implementations, an evaluation of synthetic data generation (SDG) strategies, and the impact of model merging. The llama-embed-nemotron-8b is an instruction-aware model, supporting user-defined instructions to enhance performance for specific use-cases. This combination of top-tier performance, broad applicability, and user-driven flexibility enables it to serve as a universal text embedding solution.

</details>


### [135] [Evaluating LLMs for Anxiety, Depression, and Stress Detection Evaluating Large Language Models for Anxiety, Depression, and Stress Detection: Insights into Prompting Strategies and Synthetic Data](https://arxiv.org/abs/2511.07044)
*Mihael Arcan,David-Paul Niland*

Main category: cs.CL

TL;DR: 本研究评估了多种心理健康检测方法，比较了Llama、GPT等大型语言模型与经典机器学习及基于Transformer的架构（BERT、XLNet、Distil-RoBERTa）。使用DAIC-WOZ临床访谈数据集，针对焦虑、抑郁和压力分类进行模型微调，并应用合成数据生成来解决类别不平衡问题。结果显示Distil-RoBERTa在GAD-2上获得最高F1分数（0.883），XLNet在PHQ任务上表现最佳（F1达0.891），而零样本合成方法在压力检测上达到F1 0.884和ROC AUC 0.886。


<details>
  <summary>Details</summary>
Motivation: 全球超过五分之一的成年人受到心理健康障碍影响，但由于症状表达的微妙性和多样性，从文本中检测这些状况仍然具有挑战性。本研究旨在评估不同方法在心理健康检测中的效果。

Method: 使用DAIC-WOZ临床访谈数据集，对焦虑、抑郁和压力分类任务进行模型微调。比较了大型语言模型（Llama、GPT）、经典机器学习方法和基于Transformer的架构（BERT、XLNet、Distil-RoBERTa）。应用合成数据生成来缓解类别不平衡问题。

Result: Distil-RoBERTa在GAD-2任务上获得最高F1分数0.883；XLNet在PHQ任务上表现最佳，F1分数达到0.891；对于压力检测，零样本合成方法（SD+Zero-Shot-Basic）达到F1 0.884和ROC AUC 0.886。

Conclusion: 研究证明了基于Transformer的模型的有效性，并强调了合成数据在提高召回率和泛化能力方面的价值。然而，需要仔细校准以防止精度损失。这项工作强调了结合先进语言模型和数据增强来改进基于文本的自动化心理健康评估的潜力。

Abstract: Mental health disorders affect over one-fifth of adults globally, yet detecting such conditions from text remains challenging due to the subtle and varied nature of symptom expression. This study evaluates multiple approaches for mental health detection, comparing Large Language Models (LLMs) such as Llama and GPT with classical machine learning and transformer-based architectures including BERT, XLNet, and Distil-RoBERTa. Using the DAIC-WOZ dataset of clinical interviews, we fine-tuned models for anxiety, depression, and stress classification and applied synthetic data generation to mitigate class imbalance. Results show that Distil-RoBERTa achieved the highest F1 score (0.883) for GAD-2, while XLNet outperformed others on PHQ tasks (F1 up to 0.891). For stress detection, a zero-shot synthetic approach (SD+Zero-Shot-Basic) reached an F1 of 0.884 and ROC AUC of 0.886. Findings demonstrate the effectiveness of transformer-based models and highlight the value of synthetic data in improving recall and generalization. However, careful calibration is required to prevent precision loss. Overall, this work emphasizes the potential of combining advanced language models and data augmentation to enhance automated mental health assessment from text.

</details>


### [136] [When Sufficient is not Enough: Utilizing the Rashomon Effect for Complete Evidence Extraction](https://arxiv.org/abs/2511.07055)
*Katharina Beckh,Stefan Rüping*

Main category: cs.CL

TL;DR: 该论文研究了在医学数据集中识别完整证据特征的问题，发现单个模型只能恢复部分证据，而通过模型集成可以将证据召回率从约0.60提升到约0.86。


<details>
  <summary>Details</summary>
Motivation: 传统的特征归因方法通常只提供最小充分证据，但在合规性和编目等应用中需要识别完整的贡献特征集。

Method: 在包含人工标注完整证据的医学数据集上进行案例研究，分析单个模型和集成模型在证据恢复方面的表现，研究召回率-精确度权衡、证据训练的作用以及带确定性阈值的动态集成。

Result: 单个模型通常只能恢复完整证据的子集，证据召回率约为0.60；通过集成多个模型，证据召回率可提升至约0.86。

Conclusion: 模型集成能显著提高完整证据的识别能力，在需要完整证据的应用中具有重要价值，同时需要权衡召回率与精确度的关系。

Abstract: Feature attribution methods typically provide minimal sufficient evidence justifying a model decision. However, in many applications this is inadequate. For compliance and cataloging, the full set of contributing features must be identified - complete evidence. We perform a case study on a medical dataset which contains human-annotated complete evidence. We show that individual models typically recover only subsets of complete evidence and that aggregating evidence from several models improves evidence recall from $\sim$0.60 (single best model) to $\sim$0.86 (ensemble). We analyze the recall-precision trade-off, the role of training with evidence, dynamic ensembles with certainty thresholds, and discuss implications.

</details>


### [137] [Aligning Attention with Human Rationales for Self-Explaining Hate Speech Detection](https://arxiv.org/abs/2511.07065)
*Brage Eilertsen,Røskva Bjørgfinsdóttir,Francielle Vargas,Ali Ramezani-Kebrya*

Main category: cs.CL

TL;DR: 提出了监督理性注意力(SRA)框架，通过将模型注意力与人类理性对齐，提升仇恨言论检测系统的可解释性和公平性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型的不透明性阻碍了仇恨言论检测系统的伦理部署，需要提高模型的可解释性和公平性。

Method: 在基于transformer的分类器中集成监督注意力机制，优化结合标准分类损失和对齐损失项的联合目标函数，最小化注意力权重与人类标注理性之间的差异。

Result: 在英语和葡萄牙语仇恨言论基准测试中，SRA实现了比当前基线方法2.4倍更好的可解释性，产生更忠实和人类对齐的token级解释，同时在公平性方面表现优异。

Conclusion: 将人类理性融入注意力机制可以在不损害公平性的前提下增强可解释性和忠实性。

Abstract: The opaque nature of deep learning models presents significant challenges for the ethical deployment of hate speech detection systems. To address this limitation, we introduce Supervised Rational Attention (SRA), a framework that explicitly aligns model attention with human rationales, improving both interpretability and fairness in hate speech classification. SRA integrates a supervised attention mechanism into transformer-based classifiers, optimizing a joint objective that combines standard classification loss with an alignment loss term that minimizes the discrepancy between attention weights and human-annotated rationales. We evaluated SRA on hate speech benchmarks in English (HateXplain) and Portuguese (HateBRXplain) with rationale annotations. Empirically, SRA achieves 2.4x better explainability compared to current baselines, and produces token-level explanations that are more faithful and human-aligned. In terms of fairness, SRA achieves competitive fairness across all measures, with second-best performance in detecting toxic posts targeting identity groups, while maintaining comparable results on other metrics. These findings demonstrate that incorporating human rationales into attention mechanisms can enhance interpretability and faithfulness without compromising fairness.

</details>


### [138] [Importance-Aware Data Selection for Efficient LLM Instruction Tuning](https://arxiv.org/abs/2511.07074)
*Tingyu Jiang,Shen Li,Yiyao Song,Lan Zhang,Hualei Zhu,Yuan Zhao,Xiaohang Xu,Kenjiro Taura,Hao Henry Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的指标MIWV（模型指令弱点值），用于量化指令数据在提升模型能力方面的重要性。实验表明，仅基于MIWV选择前1%的数据进行训练，就能超越使用完整数据集的训练效果。


<details>
  <summary>Details</summary>
Motivation: 指令调优的成功不仅取决于指令数据的质量，还取决于LLM本身的能力。现有研究主要关注计算数据质量分数来评估指令数据，但更需要选择能最大化提升特定LLM指令调优性能的高质量数据。

Method: 提出MIWV指标，通过模型在使用上下文学习（ICL）时的响应差异来量化指令数据的重要性，识别对增强指令调优性能最有益的数据。

Result: 实验结果显示，仅选择基于MIWV排名前1%的数据进行训练，就能在性能上超越使用完整数据集进行训练的效果。

Conclusion: MIWV方法超越了现有专注于数据质量评分的研究，为所提方法的有效性提供了强有力的实证证据。

Abstract: Instruction tuning plays a critical role in enhancing the performance and efficiency of Large Language Models (LLMs). Its success depends not only on the quality of the instruction data but also on the inherent capabilities of the LLM itself. Some studies suggest that even a small amount of high-quality data can achieve instruction fine-tuning results that are on par with, or even exceed, those from using a full-scale dataset. However, rather than focusing solely on calculating data quality scores to evaluate instruction data, there is a growing need to select high-quality data that maximally enhances the performance of instruction tuning for a given LLM. In this paper, we propose the Model Instruction Weakness Value (MIWV) as a novel metric to quantify the importance of instruction data in enhancing model's capabilities. The MIWV metric is derived from the discrepancies in the model's responses when using In-Context Learning (ICL), helping identify the most beneficial data for enhancing instruction tuning performance. Our experimental results demonstrate that selecting only the top 1\% of data based on MIWV can outperform training on the full dataset. Furthermore, this approach extends beyond existing research that focuses on data quality scoring for data selection, offering strong empirical evidence supporting the effectiveness of our proposed method.

</details>


### [139] [Wasm: A Pipeline for Constructing Structured Arabic Interleaved Multimodal Corpora](https://arxiv.org/abs/2511.07080)
*Khalil Hennara,Ahmad Bastati,Muhammad Hreden,Mohamed Motasim Hamed,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CL

TL;DR: 本文提出了Wasm处理流水线，从Common Crawl数据集创建阿拉伯语多模态数据集，提供markdown输出并保留网页结构完整性，填补了阿拉伯语高质量多模态数据集的空白。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语缺乏保留文档结构的高质量多模态数据集，限制了大型多模态模型的发展，需要创建能够同时支持纯文本和多模态预训练场景的数据集。

Method: 开发Wasm处理流水线处理Common Crawl数据集，生成阿拉伯语多模态数据集，独特提供markdown输出并保持网页结构完整性。

Result: 创建了新的阿拉伯语多模态数据集，提供了代表性数据集转储和多模态处理流水线，支持未来研究。

Conclusion: Wasm流水线成功填补了阿拉伯语多模态数据集的空白，为阿拉伯语大型多模态模型的发展提供了重要资源。

Abstract: The performance of large language models (LLMs) and large multimodal models (LMMs) depends heavily on the quality and scale of their pre-training datasets. Recent research shows that large multimodal models trained on natural documents where images and text are interleaved outperform those trained only on image-text pairs across a wide range of benchmarks, leveraging advanced pre-trained models to enforce semantic alignment, image-sequence consistency, and textual coherence. For Arabic, however, the lack of high-quality multimodal datasets that preserve document structure has limited progress. In this paper, we present our pipeline Wasm for processing the Common Crawl dataset to create a new Arabic multimodal dataset that uniquely provides markdown output. Unlike existing Arabic corpora that focus solely on text extraction, our approach preserves the structural integrity of web content while maintaining flexibility for both text-only and multimodal pre-training scenarios. We provide a comprehensive comparative analysis of our data processing pipeline against those used for major existing datasets, highlighting the convergences in filtering strategies and justifying our specific design choices. To support future research, we publicly release a representative dataset dump along with the multimodal processing pipeline for Arabic.

</details>


### [140] [Think Consistently, Reason Efficiently: Energy-Based Calibration for Implicit Chain-of-Thought](https://arxiv.org/abs/2511.07124)
*Zhikang Chen,Sen Cui,Deheng Ye,Yu Zhang,Yatao Bian,Tingting Zhu*

Main category: cs.CL

TL;DR: 提出EBM-CoT框架，通过基于能量的模型校准隐式推理轨迹，提升大语言模型多步推理的一致性和准确性


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在错误传播和词汇表达限制问题，而隐式推理方法缺乏一致性机制，导致推理路径发散和不稳定

Method: 使用基于能量的模型动态调整隐式推理轨迹，使其向低能量、高一致性区域移动，不改变基础语言模型

Result: 在数学、常识和符号推理基准测试中显著提高了推理一致性和效率

Conclusion: EBM-CoT框架有效解决了多步推理中的一致性问题，为LLM推理提供了新的校准方法

Abstract: Large Language Models (LLMs) have demonstrated strong reasoning capabilities through \emph{Chain-of-Thought} (CoT) prompting, which enables step-by-step intermediate reasoning. However, explicit CoT methods rely on discrete token-level reasoning processes that are prone to error propagation and limited by vocabulary expressiveness, often resulting in rigid and inconsistent reasoning trajectories. Recent research has explored implicit or continuous reasoning in latent spaces, allowing models to perform internal reasoning before generating explicit output. Although such approaches alleviate some limitations of discrete CoT, they generally lack explicit mechanisms to enforce consistency among reasoning steps, leading to divergent reasoning paths and unstable outcomes. To address this issue, we propose EBM-CoT, an Energy-Based Chain-of-Thought Calibration framework that refines latent thought representations through an energy-based model (EBM). Our method dynamically adjusts latent reasoning trajectories toward lower-energy, high-consistency regions in the embedding space, improving both reasoning accuracy and consistency without modifying the base language model. Extensive experiments across mathematical, commonsense, and symbolic reasoning benchmarks demonstrate that the proposed framework significantly enhances the consistency and efficiency of multi-step reasoning in LLMs.

</details>


### [141] [LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging](https://arxiv.org/abs/2511.07129)
*Seungeon Lee,Soumi Das,Manish Gupta,Krishna P. Gummadi*

Main category: cs.CL

TL;DR: LoRA on the Go (LoGo) 是一个无需训练的框架，能够在实例级别动态选择和合并 LoRA 适配器，无需额外数据或训练，在多个 NLP 基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的 LoRA 适配器通常针对单一任务训练，限制了在现实世界多样化输入场景中的应用。现有方法在推理时组合多个 LoRA 需要标记数据或额外训练，成本高昂。

Method: LoGo 通过单次前向传播提取 LoRA 适配器的信号，动态识别最相关的适配器并实时确定其贡献，无需额外训练。

Result: 在 5 个 NLP 基准测试、27 个数据集和 3 个模型系列上，LoGo 在某些任务上比基于训练的方法高出 3.6%，在其他任务上保持竞争力，同时维持推理吞吐量。

Conclusion: LoGo 展示了在多样化任务上无需训练动态选择和合并 LoRA 适配器的有效性和实用性。

Abstract: Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for fine-tuning large language models.However, conventional LoRA adapters are typically trained for a single task, limiting their applicability in real-world settings where inputs may span diverse and unpredictable domains. At inference time, existing approaches combine multiple LoRAs for improving performance on diverse tasks, while usually requiring labeled data or additional task-specific training, which is expensive at scale. In this work, we introduce LoRA on the Go (LoGo), a training-free framework that dynamically selects and merges adapters at the instance level without any additional requirements. LoGo leverages signals extracted from a single forward pass through LoRA adapters, to identify the most relevant adapters and determine their contributions on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo outperforms training-based baselines on some tasks upto a margin of 3.6% while remaining competitive on other tasks and maintaining inference throughput, highlighting its effectiveness and practicality.

</details>


### [142] [TCM-Eval: An Expert-Level Dynamic and Extensible Benchmark for Traditional Chinese Medicine](https://arxiv.org/abs/2511.07148)
*Zihao Cheng,Yuheng Lu,Huaiqian Ye,Zeming Liu,Minqi Wang,Jingjing Liu,Zihan Li,Wei Fan,Yuanfang Guo,Ruiji Fu,Shifeng She,Gang Wang,Yunhong Wang*

Main category: cs.CL

TL;DR: 该论文提出了TCM-Eval基准和ZhiMingTang模型，通过SI-CoTE方法自动增强中医问答数据，解决了中医领域缺乏标准化基准和高质量训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在现代医学中表现出色，但在中医领域的应用受到缺乏标准化基准和高质量训练数据的严重限制。

Method: 构建TCM-Eval动态可扩展基准，创建大规模训练语料库，提出自我迭代思维链增强(SI-CoTE)方法，通过拒绝采样自动丰富带验证推理链的问答对。

Result: 开发了ZhiMingTang(ZMT)模型，该模型显著超过了人类执业医师的通过阈值，成为中医领域的先进LLM。

Conclusion: 建立了数据和模型协同进化的良性循环，发布了公共排行榜以促进社区参与和持续改进。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in modern medicine, yet their application in Traditional Chinese Medicine (TCM) remains severely limited by the absence of standardized benchmarks and the scarcity of high-quality training data. To address these challenges, we introduce TCM-Eval, the first dynamic and extensible benchmark for TCM, meticulously curated from national medical licensing examinations and validated by TCM experts. Furthermore, we construct a large-scale training corpus and propose Self-Iterative Chain-of-Thought Enhancement (SI-CoTE) to autonomously enrich question-answer pairs with validated reasoning chains through rejection sampling, establishing a virtuous cycle of data and model co-evolution. Using this enriched training data, we develop ZhiMingTang (ZMT), a state-of-the-art LLM specifically designed for TCM, which significantly exceeds the passing threshold for human practitioners. To encourage future research and development, we release a public leaderboard, fostering community engagement and continuous improvement.

</details>


### [143] [AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and Dual-Channel Reasoning](https://arxiv.org/abs/2511.07166)
*Meiyun Wang,Charin Polpanumas*

Main category: cs.CL

TL;DR: AdaRec是一个基于大语言模型的少样本上下文学习框架，通过叙事化画像将用户-物品交互转化为自然语言表示，实现自适应个性化推荐。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐方法需要手动特征工程，且难以在少样本场景下实现跨任务快速适应。AdaRec旨在消除手动特征工程，通过语义表示支持快速跨任务适应。

Method: 采用双通道架构，结合水平行为对齐（发现同伴驱动模式）和垂直因果归因（突出用户偏好的决定性因素），通过叙事化画像统一处理任务。

Result: 在真实电商数据集上，AdaRec在少样本设置下比机器学习和LLM基线模型性能提升高达8%，在零样本场景下比专家构建的画像提升19%，在长尾个性化方面表现优异。

Conclusion: AdaRec通过轻量级微调在合成数据上能达到完全微调模型的性能，展示了其在多样化任务中的高效性和泛化能力。

Abstract: We propose AdaRec, a few-shot in-context learning framework that leverages large language models for an adaptive personalized recommendation. AdaRec introduces narrative profiling, transforming user-item interactions into natural language representations to enable unified task handling and enhance human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a dual-channel architecture that integrates horizontal behavioral alignment, discovering peer-driven patterns, with vertical causal attribution, highlighting decisive factors behind user preferences. Unlike existing LLM-based approaches, AdaRec eliminates manual feature engineering through semantic representations and supports rapid cross-task adaptation with minimal supervision. Experiments on real ecommerce datasets demonstrate that AdaRec outperforms both machine learning models and LLM-based baselines by up to eight percent in few-shot settings. In zero-shot scenarios, it achieves up to a nineteen percent improvement over expert-crafted profiling, showing effectiveness for long-tail personalization with minimal interaction data. Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec matches the performance of fully fine-tuned models, highlighting its efficiency and generalization across diverse tasks.

</details>


### [144] [EMODIS: A Benchmark for Context-Dependent Emoji Disambiguation in Large Language Models](https://arxiv.org/abs/2511.07193)
*Jiacheng Huang,Ning Yu,Xiaoyin Yi*

Main category: cs.CL

TL;DR: EMODIS是一个评估大语言模型在最小但对比性文本语境下解释模糊表情符号能力的新基准，发现即使最强模型在只有细微语境线索时也经常无法区分含义。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地部署在真实世界通信环境中，但其解决语境依赖模糊性的能力仍未充分探索。

Method: 创建EMODIS基准，每个实例包含一个带表情符号的模糊句子、两个导致不同解释的区分性语境，以及需要语境推理的具体问题。评估开源和API基础的大语言模型。

Result: 即使最强模型在只有细微语境线索时也经常无法区分含义。进一步分析显示存在系统性偏向主导解释和对语用对比的有限敏感性。

Conclusion: EMODIS为评估语境消歧提供了严格测试平台，突显了人类与大语言模型在语义推理方面的差距。

Abstract: Large language models (LLMs) are increasingly deployed in real-world communication settings, yet their ability to resolve context-dependent ambiguity remains underexplored. In this work, we present EMODIS, a new benchmark for evaluating LLMs' capacity to interpret ambiguous emoji expressions under minimal but contrastive textual contexts. Each instance in EMODIS comprises an ambiguous sentence containing an emoji, two distinct disambiguating contexts that lead to divergent interpretations, and a specific question that requires contextual reasoning. We evaluate both open-source and API-based LLMs, and find that even the strongest models frequently fail to distinguish meanings when only subtle contextual cues are present. Further analysis reveals systematic biases toward dominant interpretations and limited sensitivity to pragmatic contrast. EMODIS provides a rigorous testbed for assessing contextual disambiguation, and highlights the gap in semantic reasoning between humans and LLMs.

</details>


### [145] [Discourse Graph Guided Document Translation with Large Language Models](https://arxiv.org/abs/2511.07230)
*Viet-Thanh Pham,Minghan Wang,Hao-Han Liao,Thuy-Trang Vu*

Main category: cs.CL

TL;DR: TransGraph是一个基于话语图的文档翻译框架，通过显式建模块间关系来提升翻译质量和术语一致性，同时降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在文档翻译中难以捕捉长距离依赖和保持话语连贯性，而多智能体翻译系统虽然缓解了上下文窗口限制，但计算资源需求大且对记忆检索策略敏感。

Method: 引入TransGraph框架，通过结构化话语图显式建模块间关系，并选择性地基于相关图邻域条件化每个翻译片段，而非依赖顺序或穷尽上下文。

Result: 在三个文档级机器翻译基准测试中，涵盖六种语言和多个领域，TransGraph在翻译质量和术语一致性方面持续超越强基线，同时显著降低token开销。

Conclusion: TransGraph通过话语图引导的方法有效解决了文档翻译中的长距离依赖和连贯性问题，在保证翻译质量的同时显著减少了计算资源需求。

Abstract: Adapting large language models to full document translation remains challenging due to the difficulty of capturing long-range dependencies and preserving discourse coherence throughout extended texts. While recent agentic machine translation systems mitigate context window constraints through multi-agent orchestration and persistent memory, they require substantial computational resources and are sensitive to memory retrieval strategies. We introduce TransGraph, a discourse-guided framework that explicitly models inter-chunk relationships through structured discourse graphs and selectively conditions each translation segment on relevant graph neighbourhoods rather than relying on sequential or exhaustive context. Across three document-level MT benchmarks spanning six languages and diverse domains, TransGraph consistently surpasses strong baselines in translation quality and terminology consistency while incurring significantly lower token overhead.

</details>


### [146] [Who Is the Story About? Protagonist Entity Recognition in News](https://arxiv.org/abs/2511.07296)
*Jorge Gabín,M. Eduardo Ares,Javier Parapar*

Main category: cs.CL

TL;DR: 该论文提出了主角实体识别（PER）任务，用于识别新闻故事中的核心组织实体，而不是传统NER中平等对待所有实体。通过比较专家标注与LLM预测，验证了任务可行性，并展示了LLM能够在大规模新闻数据中近似人类对叙事重要性的判断。


<details>
  <summary>Details</summary>
Motivation: 传统NER将所有组织实体同等对待，无法区分真正驱动叙事的关键实体，限制了依赖事件显著性、影响力或叙事焦点的下游任务。

Method: 比较LLM预测与四位专家标注者的标注结果，建立标注者间一致性和人机一致性；使用NER引导提示来自动标注大规模新闻数据；评估LLM在有限上下文和无明确候选指导情况下推断正确主角的能力。

Result: 证明了PER是叙事中心信息提取的有意义扩展，引导的LLM能够在大规模上近似人类对叙事重要性的判断。

Conclusion: 主角实体识别是一个可行且有意义的任务扩展，LLM能够有效识别新闻叙事中的核心组织实体，为下游应用提供更好的实体重要性理解。

Abstract: News articles often reference numerous organizations, but traditional Named Entity Recognition (NER) treats all mentions equally, obscuring which entities genuinely drive the narrative. This limits downstream tasks that rely on understanding event salience, influence, or narrative focus. We introduce Protagonist Entity Recognition (PER), a task that identifies the organizations that anchor a news story and shape its main developments. To validate PER, we compare he predictions of Large Language Models (LLMs) against annotations from four expert annotators over a gold corpus, establishing both inter-annotator consistency and human-LLM agreement. Leveraging these findings, we use state-of-the-art LLMs to automatically label large-scale news collections through NER-guided prompting, generating scalable, high-quality supervision. We then evaluate whether other LLMs, given reduced context and without explicit candidate guidance, can still infer the correct protagonists. Our results demonstrate that PER is a feasible and meaningful extension to narrative-centered information extraction, and that guided LLMs can approximate human judgments of narrative importance at scale.

</details>


### [147] [Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task Learning Approach for Bangla Hate Speech Identification](https://arxiv.org/abs/2511.07304)
*Sourav Saha,K M Nafi Asib,Mohammed Moshiul Hoque*

Main category: cs.CL

TL;DR: 本文介绍了在IJCNLP-AACL 2025 BLP研讨会上参与孟加拉语仇恨言论识别共享任务的系统，使用transformer模型集成方法在三个子任务中取得了72%以上的微F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉语仇恨言论识别这一具有社会影响力但语言挑战性强的任务，特别是在低资源环境下推进孟加拉语仇恨言论检测。

Method: 对于子任务1A和1B使用transformer模型（BanglaBERT、MuRIL、IndicBERTv2）的软投票集成；对于子任务1C训练三个多任务变体并通过加权投票集成聚合预测。

Result: 系统在三个子任务中分别获得72.75%（1A）、72.69%（1B）和72.62%（1C）的微F1分数，在共享任务排行榜上分别排名第9、第10和第7位。

Conclusion: transformer集成和加权多任务框架在低资源环境下推进孟加拉语仇恨言论检测方面显示出良好前景。

Abstract: This paper addresses the problem of Bangla hate speech identification, a socially impactful yet linguistically challenging task. As part of the "Bangla Multi-task Hate Speech Identification" shared task at the BLP Workshop, IJCNLP-AACL 2025, our team "Retriv" participated in all three subtasks: (1A) hate type classification, (1B) target group identification, and (1C) joint detection of type, severity, and target. For subtasks 1A and 1B, we employed a soft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2). For subtask 1C, we trained three multitask variants and aggregated their predictions through a weighted voting ensemble. Our systems achieved micro-f1 scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62% (1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7th positions, respectively. These results highlight the promise of transformer ensembles and weighted multitask frameworks for advancing Bangla hate speech detection in low-resource contexts. We made experimental scripts publicly available for the community.

</details>


### [148] [ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding](https://arxiv.org/abs/2511.07311)
*Tuan-Dung Le,Shohreh Haddadan,Thanh Q. Thieu*

Main category: cs.CL

TL;DR: 提出了一种基于大语言模型的数据增强方法，通过扩展医疗缩写词来改进自动ICD编码任务，结合一致性训练提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注代码层次结构和同义词理解，但忽略了临床笔记中普遍使用的医疗缩写词对ICD代码推断的关键影响。

Method: 利用大语言模型扩展医疗缩写词，使模型能够在完整形式表示上训练，并引入一致性训练来正则化预测结果。

Result: 在MIMIC-III数据集上的广泛实验表明，该方法在常见代码、罕见代码和完整代码分配等多个设置下都达到了最先进的性能。

Conclusion: 提出的ACE-ICD方法通过有效处理医疗缩写词显著提升了自动ICD编码的性能，代码已公开可用。

Abstract: Automatic ICD coding, the task of assigning disease and procedure codes to electronic medical records, is crucial for clinical documentation and billing. While existing methods primarily enhance model understanding of code hierarchies and synonyms, they often overlook the pervasive use of medical acronyms in clinical notes, a key factor in ICD code inference. To address this gap, we propose a novel effective data augmentation technique that leverages large language models to expand medical acronyms, allowing models to be trained on their full form representations. Moreover, we incorporate consistency training to regularize predictions by enforcing agreement between the original and augmented documents. Extensive experiments on the MIMIC-III dataset demonstrate that our approach, ACE-ICD establishes new state-of-the-art performance across multiple settings, including common codes, rare codes, and full-code assignments. Our code is publicly available.

</details>


### [149] [RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments](https://arxiv.org/abs/2511.07317)
*Zhiyuan Zeng,Hamish Ivison,Yiping Wang,Lifan Yuan,Shuyue Stella Li,Zhuorui Ye,Siting Li,Jacqueline He,Runlong Zhou,Tong Chen,Chenyang Zhao,Yulia Tsvetkov,Simon Shaolei Du,Natasha Jaques,Hao Peng,Pang Wei Koh,Hannaneh Hajishirzi*

Main category: cs.CL

TL;DR: 提出了RLVE方法，使用可验证环境动态调整问题难度分布来扩展语言模型的强化学习，相比静态数据分布能避免学习信号消失问题


<details>
  <summary>Details</summary>
Motivation: 静态数据分布在训练过程中容易导致问题过于简单或困难，从而产生消失的学习信号，需要动态适应策略模型能力的训练环境

Method: 开发了RLVE-Gym套件，包含400个可验证环境，通过程序化生成问题和算法验证奖励，实现环境难度随训练进度动态调整

Result: 在6个推理基准测试中平均绝对提升3.37%，相比原始RL训练仅0.49%的提升，计算效率提升3倍以上

Conclusion: 环境扩展能持续提升通用推理能力，RLVE方法在保持计算效率的同时显著改善了语言模型的推理性能

Abstract: We introduce Reinforcement Learning (RL) with Adaptive Verifiable Environments (RLVE), an approach using verifiable environments that procedurally generate problems and provide algorithmically verifiable rewards, to scale up RL for language models (LMs). RLVE enables each verifiable environment to dynamically adapt its problem difficulty distribution to the policy model's capabilities as training progresses. In contrast, static data distributions often lead to vanishing learning signals when problems are either too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a large-scale suite of 400 verifiable environments carefully developed through manual environment engineering. Using RLVE-Gym, we show that environment scaling, i.e., expanding the collection of training environments, consistently improves generalizable reasoning capabilities. RLVE with joint training across all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement across six reasoning benchmarks, starting from one of the strongest 1.5B reasoning LMs. By comparison, continuing this LM's original RL training yields only a 0.49% average absolute gain despite using over 3x more compute. We release our code publicly.

</details>


### [150] [FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation](https://arxiv.org/abs/2511.07322)
*Song Jin,Shuqi Li,Shukun Zhang,Rui Yan*

Main category: cs.CL

TL;DR: 本文首次提出了股权研究报告生成任务，构建了开源评估基准FinRpt，包含数据集构建管道和11个评估指标，并提出了多智能体框架FinRpt-Gen，在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在股票预测和问答等金融任务中表现出色，但在完全自动化生成股权研究报告方面仍是未开发领域，需要解决数据稀缺和评估指标缺失的问题。

Method: 提出了数据集构建管道整合7种金融数据类型自动生成高质量ERR数据集，设计了包含11个指标的全面评估系统，并开发了多智能体框架FinRpt-Gen，使用监督微调和强化学习训练LLM智能体。

Result: 实验结果表明FinRpt基准的数据质量和指标有效性良好，FinRpt-Gen表现出强劲性能，展示了在ERR生成领域的创新潜力。

Conclusion: 该研究为股权研究报告生成领域提供了首个基准和多智能体解决方案，所有代码和数据集均已公开，有望推动该领域的创新发展。

Abstract: While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.

</details>


### [151] [Selecting Auxiliary Data via Neural Tangent Kernels for Low-Resource Domains](https://arxiv.org/abs/2511.07380)
*Pingjie Wang,Hongcheng Liu,Yusheng Liao,Ziqing Fan,Yaxin Du,Shuo Tang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出NTK-Selector框架，通过神经正切核选择通用领域辅助数据来增强低资源领域的LLM性能，在四个领域实验中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: LLM在低资源领域面临数据稀缺和过拟合风险，而大量通用领域数据可能作为辅助监督，但如何有效选择最有价值的辅助数据是关键问题。

Method: 提出NTK-Selector框架，通过实证发现LLM在LoRA微调中表现出稳定的类NTK行为，并提出无雅可比近似方法解决计算成本问题。

Result: 在医疗、金融、法律和心理四个低资源领域实验中，使用NTK-Selector选择的9000个辅助样本相比仅使用1000个领域样本，Llama3-8B-Instruct和Qwen3-8B分别获得+8.7和+5.1分的显著提升，相对改进达10.9倍和5.7倍。

Conclusion: NTK-Selector能够有效选择通用领域辅助数据，显著提升LLM在低资源领域的性能，为解决数据稀缺问题提供了有效方案。

Abstract: Large language models (LLMs) have achieved remarkable success across widespread tasks, yet their application in low-resource domains remains a significant challenge due to data scarcity and the high risk of overfitting. While in-domain data is limited, there exist vast amounts of similar general-domain data, and our initial findings reveal that they could potentially serve as auxiliary supervision for domain enhancement. This observation leads us to our central research question: \textbf{\textit{how to effectively select the most valuable auxiliary data to maximize domain-specific performance}}, particularly when traditional methods are inapplicable due to a lack of large in-domain data pools or validation sets. To address this, we propose \textbf{NTK-Selector}, a principled and efficient framework for selecting general-domain auxiliary data to enhance domain-specific performance via neural tangent kernels (NTK). Our method tackles two challenges of directly applying NTK to LLMs, theoretical assumptions and prohibitive computational cost, by empirically demonstrating a stable NTK-like behavior in LLMs during LoRA fine-tuning and proposing a Jacobian-free approximation method. Extensive experiments across four low-resource domains (medical, financial, legal, and psychological) demonstrate that NTK-Selector consistently improves downstream performance. Specifically, fine-tuning on 1,000 in-domain samples alone only yielded +0.8 points for Llama3-8B-Instruct and +0.9 points for Qwen3-8B. In contrast, enriching with 9,000 auxiliary samples selected by NTK-Selector led to substantial \textbf{gains of +8.7 and +5.1 points}, which corresponds to a \textbf{10.9x and 5.7x improvement} over the domain-only setting.

</details>


### [152] [Teaching Pretrained Language Models to Think Deeper with Retrofitted Recurrence](https://arxiv.org/abs/2511.07384)
*Sean McLeish,Ang Li,John Kirchenbauer,Dayal Singh Kalra,Brian R. Bartoldson,Bhavya Kailkhura,Avi Schwarzschild,Jonas Geiping,Tom Goldstein,Micah Goldblum*

Main category: cs.CL

TL;DR: 该研究探索如何将预训练的非循环语言模型转换为深度循环模型，通过使用循环课程来在训练过程中逐步增加模型的有效深度，从而在降低计算成本的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 深度循环语言模型的进展表明循环机制可以将训练时计算和参数量与测试时计算解耦，但如何将现有预训练的非循环模型转换为循环模型仍需研究。

Method: 使用循环课程策略，在训练过程中逐步增加模型的有效深度，将预训练的非循环语言模型转换为深度循环模型。

Result: 在数学任务上的实验表明，将预训练模型转换为循环模型在给定计算预算下比简单地对原始非循环模型进行后训练获得更好的性能。

Conclusion: 通过循环课程策略将预训练非循环模型转换为深度循环模型是一种有效的计算优化方法，能够在保持性能的同时显著降低计算成本。

Abstract: Recent advances in depth-recurrent language models show that recurrence can decouple train-time compute and parameter count from test-time compute. In this work, we study how to convert existing pretrained non-recurrent language models into depth-recurrent models. We find that using a curriculum of recurrences to increase the effective depth of the model over the course of training preserves performance while reducing total computational cost. In our experiments, on mathematics, we observe that converting pretrained models to recurrent ones results in better performance at a given compute budget than simply post-training the original non-recurrent language model.

</details>


### [153] [Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations](https://arxiv.org/abs/2511.05901)
*Rui Yang,Matthew Yu Heng Wong,Huitao Li,Xin Li,Wentao Zhu,Jingchi Liao,Kunyu Yu,Jonathan Chong Kai Liew,Weihao Xuan,Yingjian Chen,Yuhe Ke,Jasmine Chiat Ling Ong,Douglas Teodoro,Chuan Hong,Daniel Shi Wei Ting,Nan Liu*

Main category: cs.CL

TL;DR: 本文综述了检索增强生成（RAG）技术在医学领域的应用现状，发现该领域仍处于早期阶段，主要基于公开数据，使用通用LLM和英文嵌入模型，应用集中在问答、报告生成等任务，需要加强临床验证、跨语言适应和低资源环境支持。


<details>
  <summary>Details</summary>
Motivation: 医学知识的快速增长和临床实践的复杂性带来挑战，大型语言模型（LLMs）虽有价值但存在固有局限，RAG技术有望提升其在临床环境中的适用性。

Method: 通过文献综述方法，分析RAG在医学领域的应用情况，包括数据来源、检索方法、LLM类型和评估方式。

Result: 研究发现RAG应用主要依赖公开数据，检索多使用英文嵌入模型，LLM多为通用型，评估主要关注生成质量和任务性能，应用集中在问答、报告生成、文本摘要和信息提取等任务。

Conclusion: 医学RAG仍处于早期阶段，需要在临床验证、跨语言适应和低资源环境支持等方面取得进展，以实现可信赖和负责任的全球应用。

Abstract: The rapid growth of medical knowledge and increasing complexity of clinical practice pose challenges. In this context, large language models (LLMs) have demonstrated value; however, inherent limitations remain. Retrieval-augmented generation (RAG) technologies show potential to enhance their clinical applicability. This study reviewed RAG applications in medicine. We found that research primarily relied on publicly available data, with limited application in private data. For retrieval, approaches commonly relied on English-centric embedding models, while LLMs were mostly generic, with limited use of medical-specific LLMs. For evaluation, automated metrics evaluated generation quality and task performance, whereas human evaluation focused on accuracy, completeness, relevance, and fluency, with insufficient attention to bias and safety. RAG applications were concentrated on question answering, report generation, text summarization, and information extraction. Overall, medical RAG remains at an early stage, requiring advances in clinical validation, cross-linguistic adaptation, and support for low-resource settings to enable trustworthy and responsible global use.

</details>


### [154] [SPOT: An Annotated French Corpus and Benchmark for Detecting Critical Interventions in Online Conversations](https://arxiv.org/abs/2511.07405)
*Manon Berriche,Célia Nouri,Chloé Clavel,Jean-Philippe Cointet*

Main category: cs.CL

TL;DR: SPOT是首个将社会学概念"停止点"转化为可复现NLP任务的标注语料库，包含43,305个法语Facebook评论，用于二元分类任务，展示了微调编码器模型优于提示LLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 将社会学中的停止点概念转化为可操作的NLP任务，填补计数器言论或社会矫正框架中常被忽略的普通关键干预形式（如讽刺、微妙怀疑或片段化论证）的研究空白。

Method: 构建包含43,305个手动标注法语Facebook评论的语料库，配备上下文元数据，并对比微调编码器模型（CamemBERT）与指令调优LLMs在不同提示策略下的性能。

Result: 微调编码器模型在F1分数上比提示LLMs高出10多个百分点，加入上下文元数据后编码器模型的F1分数从0.75提升到0.78。

Conclusion: 监督学习对于新兴的非英语社交媒体任务至关重要，微调编码器模型在处理此类任务时优于提示LLMs，上下文元数据能进一步提升性能。

Abstract: We introduce SPOT (Stopping Points in Online Threads), the first annotated corpus translating the sociological concept of stopping point into a reproducible NLP task. Stopping points are ordinary critical interventions that pause or redirect online discussions through a range of forms (irony, subtle doubt or fragmentary arguments) that frameworks like counterspeech or social correction often overlook. We operationalize this concept as a binary classification task and provide reliable annotation guidelines. The corpus contains 43,305 manually annotated French Facebook comments linked to URLs flagged as false information by social media users, enriched with contextual metadata (article, post, parent comment, page or group, and source). We benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs under various prompting strategies. Results show that fine-tuned encoders outperform prompted LLMs in F1 score by more than 10 percentage points, confirming the importance of supervised learning for emerging non-English social media tasks. Incorporating contextual metadata further improves encoder models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along with the annotation guidelines and code in our code repository, to foster transparency and reproducible research.

</details>


### [155] [IDALC: A Semi-Supervised Framework for Intent Detection and Active Learning based Correction](https://arxiv.org/abs/2511.05921)
*Ankan Mullick,Sukannya Purkayastha,Saransh Sharma,Pawan Goyal,Niloy Ganguly*

Main category: cs.CL

TL;DR: IDALC是一个半监督框架，用于检测用户意图并修正系统拒绝的语音输入，同时最小化人工标注需求，在多个基准数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 语音对话系统存在局限性，当模型置信度低时会拒绝语音输入需要人工标注，且随着时间推移需要从系统拒绝的查询中训练新意图，但标注所有新意图和拒绝的语音输入成本过高。

Method: 提出IDALC（意图检测和主动学习校正）半监督框架，通过主动学习机制减少人工标注需求。

Result: 在多个基准数据集上超越基线方法，准确率提高5-10%，宏F1分数提高4-8%，仅需6-10%的未标注数据进行标注。

Conclusion: IDALC框架能有效检测用户意图并校正系统拒绝的语音输入，显著降低标注成本，同时保持高性能。

Abstract: Voice-controlled dialog systems have become immensely popular due to their ability to perform a wide range of actions in response to diverse user queries. These agents possess a predefined set of skills or intents to fulfill specific user tasks. But every system has its own limitations. There are instances where, even for known intents, if any model exhibits low confidence, it results in rejection of utterances that necessitate manual annotation. Additionally, as time progresses, there may be a need to retrain these agents with new intents from the system-rejected queries to carry out additional tasks. Labeling all these emerging intents and rejected utterances over time is impractical, thus calling for an efficient mechanism to reduce annotation costs. In this paper, we introduce IDALC (Intent Detection and Active Learning based Correction), a semi-supervised framework designed to detect user intents and rectify system-rejected utterances while minimizing the need for human annotation. Empirical findings on various benchmark datasets demonstrate that our system surpasses baseline methods, achieving a 5-10% higher accuracy and a 4-8% improvement in macro-F1. Remarkably, we maintain the overall annotation cost at just 6-10% of the unlabelled data available to the system. The overall framework of IDALC is shown in Fig. 1

</details>


### [156] [TimeSense:Making Large Language Models Proficient in Time-Series Analysis](https://arxiv.org/abs/2511.06344)
*Zhirui Zhang,Changhua Pei,Tianyi Gao,Zhe Xie,Yibo Hao,Zhaoyang Yu,Longlong Xu,Tong Xiao,Jing Han,Dan Pei*

Main category: cs.CL

TL;DR: 本文提出了TimeSense框架，通过平衡文本推理和保持时间感知来解决现有方法在时间序列分析中过度依赖文本标签的问题，并在EvalTS基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在结合文本和时间序列数据时过度依赖文本标签进行监督训练，导致模型偏向文本线索而忽视完整的时间特征，可能产生与时间序列上下文矛盾的输出。

Method: 提出了TimeSense多模态框架，包含时间感知模块来重构输入时间序列，确保文本推理基于时间序列动态；同时引入基于坐标的位置嵌入来增强空间理解。

Result: TimeSense在多个任务上实现了最先进的性能，特别是在复杂的多维时间序列推理任务上显著优于现有方法。

Conclusion: TimeSense通过平衡文本推理和保持时间感知，有效解决了现有方法的偏差问题，在时间序列分析中表现出色。

Abstract: In the time-series domain, an increasing number of works combine text with temporal data to leverage the reasoning capabilities of large language models (LLMs) for various downstream time-series understanding tasks. This enables a single model to flexibly perform tasks that previously required specialized models for each domain. However, these methods typically rely on text labels for supervision during training, biasing the model toward textual cues while potentially neglecting the full temporal features. Such a bias can lead to outputs that contradict the underlying time-series context. To address this issue, we construct the EvalTS benchmark, comprising 10 tasks across three difficulty levels, from fundamental temporal pattern recognition to complex real-world reasoning, to evaluate models under more challenging and realistic scenarios. We also propose TimeSense, a multimodal framework that makes LLMs proficient in time-series analysis by balancing textual reasoning with a preserved temporal sense. TimeSense incorporates a Temporal Sense module that reconstructs the input time-series within the model's context, ensuring that textual reasoning is grounded in the time-series dynamics. Moreover, to enhance spatial understanding of time-series data, we explicitly incorporate coordinate-based positional embeddings, which provide each time point with spatial context and enable the model to capture structural dependencies more effectively. Experimental results demonstrate that TimeSense achieves state-of-the-art performance across multiple tasks, and it particularly outperforms existing methods on complex multi-dimensional time-series reasoning tasks.

</details>


### [157] [Rethinking what Matters: Effective and Robust Multilingual Realignment for Low-Resource Languages](https://arxiv.org/abs/2511.06497)
*Quang Phuoc Nguyen,David Anugraha,Felix Gaschi,Jun Bin Cheng,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 研究表明，对于低资源语言，使用精心选择的语言子集进行词对齐可以匹配甚至优于完整多语言对齐的效果，表明有效对齐不需要覆盖所有语言。


<details>
  <summary>Details</summary>
Motivation: 词对齐是改善多语言模型跨语言迁移的有前景策略，但现有结果不稳定，特别是在与英语类型学差异大或低资源语言上。对齐工具通常依赖高质量平行数据，这对许多低资源语言来说稀缺或嘈杂。

Method: 进行广泛的实证研究，通过控制实验比较使用所有可用语言与策略性选择语言子集进行词对齐的效果，特别关注对低资源语言的影响。

Result: 实验显示词对齐对低资源语言特别有效，使用精心选择的语言多样性子集可以匹配完整多语言对齐效果，对于未见过的低资源语言甚至表现更优。

Conclusion: 有效词对齐不需要穷尽所有语言覆盖，通过明智的语言选择可以减少数据收集开销，同时保持效率和鲁棒性。

Abstract: Realignment is a promising strategy to improve cross-lingual transfer in multilingual language models. However, empirical results are mixed and often unreliable, particularly for typologically distant or low-resource languages (LRLs) compared to English. Moreover, word realignment tools often rely on high-quality parallel data, which can be scarce or noisy for many LRLs. In this work, we conduct an extensive empirical study to investigate whether realignment truly benefits from using all available languages, or if strategically selected subsets can offer comparable or even improved cross-lingual transfer, and study the impact on LRLs. Our controlled experiments show that realignment can be particularly effective for LRLs and that using carefully selected, linguistically diverse subsets can match full multilingual alignment, and even outperform it for unseen LRLs. This indicates that effective realignment does not require exhaustive language coverage and can reduce data collection overhead, while remaining both efficient and robust when guided by informed language selection.

</details>


### [158] [When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs](https://arxiv.org/abs/2511.07318)
*Shaowen Wang,Yiqi Dong,Ruinian Chang,Tansheng Zhu,Yuebo Sun,Kaifeng Lyu,Jian Li*

Main category: cs.CL

TL;DR: 本文研究发现，大语言模型中存在由伪相关驱动的幻觉问题，这类幻觉自信生成、不受模型规模影响、逃避现有检测方法，即使在拒绝微调后仍然存在。现有检测方法在伪相关存在时基本失效。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型取得显著进展，但仍持续产生幻觉，生成看似合理但错误的回答。本文关注由伪相关驱动的幻觉类别，即训练数据中特征与属性之间的表面但统计显著的关联。

Method: 通过系统控制的合成实验和对最先进开源及专有大语言模型的实证评估，包括GPT-5，测试现有幻觉检测方法在伪相关存在时的表现。

Result: 现有幻觉检测方法，如基于置信度的过滤和内部状态探测，在伪相关存在时基本失效。伪相关诱导的幻觉自信生成、不受模型规模影响、逃避检测，且在拒绝微调后仍然存在。

Conclusion: 研究结果强调了迫切需要专门设计的新方法来应对由伪相关引起的幻觉问题，因为统计偏差本质上破坏了基于置信度的检测技术。

Abstract: Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.

</details>
